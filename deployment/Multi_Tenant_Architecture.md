# å¤šç§Ÿæˆ·æ•°æ®éš”ç¦»æ¶æ„

## ğŸ¯ éš”ç¦»ç­–ç•¥é€‰æ‹©

### éš”ç¦»çº§åˆ«å¯¹æ¯”

| éš”ç¦»çº§åˆ« | å®‰å…¨æ€§ | æˆæœ¬ | å¤æ‚åº¦ | è¿ç»´éš¾åº¦ | é€‚ç”¨åœºæ™¯ |
|----------|--------|------|--------|----------|----------|
| **æ•°æ®åº“éš”ç¦»** | â­â­â­â­â­ | é«˜ | ä½ | ä½ | é‡‘è/åŒ»ç–— |
| **Schemaéš”ç¦»** | â­â­â­â­ | ä¸­ | ä¸­ | ä¸­ | ä¼ä¸šå®¢æˆ· |
| **è¡Œçº§éš”ç¦»** | â­â­â­ | ä½ | é«˜ | é«˜ | ä¸­å°ä¼ä¸š |
| **åº”ç”¨å±‚éš”ç¦»** | â­â­ | ä½ | é«˜ | é«˜ | å¼€å‘æµ‹è¯• |

**æ¨èæ–¹æ¡ˆï¼šSchemaçº§éš”ç¦»**
- å¹³è¡¡å®‰å…¨æ€§ä¸æˆæœ¬
- è¿ç»´ç›¸å¯¹ç®€å•
- æ•°æ®å¤‡ä»½æ¢å¤æ–¹ä¾¿

## ğŸ—ï¸ æ•°æ®æ¨¡å‹è®¾è®¡

### Neo4jå¤šç§Ÿæˆ·è®¾è®¡
```cypher
// 1. ç§Ÿæˆ·æ•°æ®åº“åˆ›å»º
CREATE DATABASE tenant_{tenant_id}_graph;

// 2. åŸºç¡€èŠ‚ç‚¹ç»“æ„
CREATE CONSTRAINT tenant_id FOR (n:BaseNode) REQUIRE n.tenant_id IS NOT NULL;
CREATE CONSTRAINT id FOR (n:BaseNode) REQUIRE n.id IS UNIQUE;

// 3. è®°å¿†åŸŸèŠ‚ç‚¹ç¤ºä¾‹
CREATE (m:Memory {
    id: 'mem_001',
    tenant_id: 'tenant_abc',
    domain: 'my_domain',
    content: '...',
    created_at: datetime(),
    metadata: { ... }
});

// 4. å›¾å…³ç³»ç¤ºä¾‹
MATCH (m1:Memory {tenant_id: 'tenant_abc', domain: 'd1'})
MATCH (m2:Memory {tenant_id: 'tenant_abc', domain: 'd2'})
CREATE (m1)-[:RELATED {
    tenant_id: 'tenant_abc',
    weight: 0.8,
    type: 'semantic_similarity'
}]->(m2);
```

### Qdrantå¤šç§Ÿæˆ·è®¾è®¡
```python
# Collectionå‘½åè§„åˆ™
COLLECTION_TEMPLATE = "{tenant_id}_{resource_type}"

# å®é™…ç¤ºä¾‹
COLLECTIONS = {
    "tenant_abc_videos": {
        "vector_size": 512,
        "distance": "Cosine",
        "shards": 3,
        "replicas": 2
    },
    "tenant_abc_memories": {
        "vector_size": 768,
        "distance": "Cosine",
        "shards": 2,
        "replicas": 2
    },
    "tenant_xyz_videos": {
        "vector_size": 512,
        "distance": "Cosine",
        "shards": 2,
        "replicas": 1
    }
}

# ç§Ÿæˆ·ä¸Šä¸‹æ–‡ç®¡ç†
class TenantContext:
    def __init__(self, tenant_id: str):
        self.tenant_id = tenant_id
        self.neo4j_db = f"tenant_{tenant_id}_graph"
        self.qdrant_collections = {
            "videos": f"{tenant_id}_videos",
            "memories": f"{tenant_id}_memories"
        }
```

## ğŸ” æ•°æ®è®¿é—®æ§åˆ¶

### ç§Ÿæˆ·ä¸­é—´ä»¶
```python
from fastapi import Request, Depends
from typing import Optional

async def tenant_context(request: Request) -> TenantContext:
    """ä»JWTä¸­æå–ç§Ÿæˆ·ä¿¡æ¯"""
    # ä»Authorization headerä¸­è·å–JWT
    token = request.headers.get("Authorization", "").replace("Bearer ", "")

    # è§£æJWTè·å–tenant_id
    payload = jwt.decode(token, SECRET_KEY, algorithms=["HS256"])
    tenant_id = payload.get("tenant_id")

    if not tenant_id:
        raise HTTPException(status_code=401, detail="ç¼ºå°‘ç§Ÿæˆ·ä¿¡æ¯")

    return TenantContext(tenant_id)

# å†…å­˜æœåŠ¡ä¸­çš„ç§Ÿæˆ·è¿‡æ»¤
class MemoryService:
    async def search_memory(
        self,
        query: str,
        tenant: TenantContext = Depends(tenant_context),
        limit: int = 10
    ):
        # Neo4jæŸ¥è¯¢è‡ªåŠ¨æ·»åŠ ç§Ÿæˆ·è¿‡æ»¤
        cypher = """
            MATCH (m:Memory)
            WHERE m.tenant_id = $tenant_id
            AND m.content CONTAINS $query
            RETURN m
            ORDER BY m.created_at DESC
            LIMIT $limit
        """
        result = await self.neo4j.run(
            cypher,
            tenant_id=tenant.tenant_id,
            query=query,
            limit=limit
        )
        return result

    async def store_memory(
        self,
        memory_data: dict,
        tenant: TenantContext = Depends(tenant_context)
    ):
        # è‡ªåŠ¨æ³¨å…¥ç§Ÿæˆ·ID
        memory_data["tenant_id"] = tenant.tenant_id
        # è®¾ç½®ç§Ÿæˆ·ä¸“ç”¨æ•°æ®åº“
        await self.neo4j.use_database(tenant.neo4j_db)
        return await self._create_memory(memory_data)
```

### æ•°æ®åº“è¿æ¥æ± 
```python
class MultiTenantDBPool:
    def __init__(self):
        self.pools: Dict[str, "neo4j.Driver"] = {}

    async def get_connection(self, tenant_id: str):
        """è·å–ç§Ÿæˆ·ä¸“ç”¨è¿æ¥"""
        if tenant_id not in self.pools:
            # ä¸ºæ–°ç§Ÿæˆ·åˆ›å»ºè¿æ¥æ± 
            self.pools[tenant_id] = neo4j.GraphDatabase.driver(
                f"bolt://neo4j-{tenant_id}.cluster.aws.com:7687",
                auth=("neo4j", os.getenv("NEO4J_PASSWORD")),
                max_connection_pool_size=50
            )
        return self.pools[tenant_id]

    async def close_tenant_connection(self, tenant_id: str):
        """å…³é—­ç§Ÿæˆ·è¿æ¥ï¼ˆç§Ÿæˆ·åˆ é™¤æ—¶ï¼‰"""
        if tenant_id in self.pools:
            await self.pools[tenant_id].close()
            del self.pools[tenant_id]
```

## ğŸ—ƒï¸ ç§Ÿæˆ·ç”Ÿå‘½å‘¨æœŸç®¡ç†

### ç§Ÿæˆ·åˆ›å»ºæµç¨‹
```python
async def create_tenant(tenant_config: TenantConfig):
    tenant_id = f"tenant_{uuid.uuid4().hex[:8]}"

    # 1. åˆ›å»ºNeo4jæ•°æ®åº“
    await create_neo4j_database(tenant_id)

    # 2. åˆ›å»ºQdrant Collections
    await create_qdrant_collections(tenant_id)

    # 3. åˆå§‹åŒ–é»˜è®¤æ•°æ®
    await initialize_tenant_data(tenant_id)

    # 4. è®¾ç½®é…é¢
    await set_tenant_quota(tenant_id, tenant_config.plan)

    # 5. å‘é€æ¬¢è¿é‚®ä»¶
    await send_welcome_email(tenant_config.admin_email)

    return TenantResponse(tenant_id=tenant_id, status="active")

async def create_neo4j_database(tenant_id: str):
    """åœ¨Neo4jä¸­åˆ›å»ºç§Ÿæˆ·æ•°æ®åº“"""
    db_name = f"tenant_{tenant_id}_graph"
    await neo4j_admin.run(f"CREATE DATABASE {db_name}")
    # åˆå§‹åŒ–æ•°æ®åº“schema
    await run_migration(db_name, f"migrations/tenant_{tenant_id}.cypher")
```

### ç§Ÿæˆ·åˆ é™¤æµç¨‹
```python
async def delete_tenant(tenant_id: str):
    # 1. è½¯åˆ é™¤ï¼ˆä¿ç•™30å¤©ï¼‰
    await soft_delete_tenant(tenant_id)

    # 2. é€šçŸ¥ç”¨æˆ·
    await send_deletion_warning_email(tenant_id)

    # 3. 30å¤©åç¡¬åˆ é™¤
    await schedule_hard_delete(tenant_id, delay_days=30)

async def hard_delete_tenant(tenant_id: str):
    """æ°¸ä¹…åˆ é™¤ç§Ÿæˆ·æ•°æ®"""
    # åˆ é™¤Neo4jæ•°æ®åº“
    await neo4j_admin.run(f"DROP DATABASE tenant_{tenant_id}_graph")

    # åˆ é™¤Qdrant Collections
    await qdrant.delete_collection(f"{tenant_id}_videos")
    await qdrant.delete_collection(f"{tenant_id}_memories")

    # åˆ é™¤S3æ•°æ®
    await s3.delete(f"s3://tenant-data/{tenant_id}/")

    # å…³é—­æ•°æ®åº“è¿æ¥
    await db_pool.close_tenant_connection(tenant_id)

    # ä»Redisåˆ é™¤ç¼“å­˜
    await redis.delete(f"quota:{tenant_id}")
    await redis.delete(f"config:{tenant_id}")
```

## ğŸ“Š æ•°æ®å¤‡ä»½ä¸æ¢å¤

### å¤‡ä»½ç­–ç•¥
```python
class TenantBackup:
    def __init__(self, tenant_id: str):
        self.tenant_id = tenant_id
        self.backup_prefix = f"backup/tenant_{tenant_id}"

    async def create_full_backup(self):
        """å…¨é‡å¤‡ä»½"""
        backup_id = f"{self.tenant_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        # 1. å¤‡ä»½Neo4j
        await self.backup_neo4j(backup_id)

        # 2. å¤‡ä»½Qdrant
        await self.backup_qdrant(backup_id)

        # 3. å¤‡ä»½å¯¹è±¡å­˜å‚¨
        await self.backup_s3(backup_id)

        return BackupResponse(backup_id=backup_id, status="completed")

    async def backup_neo4j(self, backup_id: str):
        """Neo4jå¤‡ä»½"""
        await neo4j_admin.run(
            f"DUMP DATABASE tenant_{self.tenant_id}_graph "
            f"TO s3://{self.backup_prefix}/neo4j/{backup_id}"
        )

    async def backup_qdrant(self, backup_id: str):
        """Qdrantå¤‡ä»½"""
        collections = [f"{self.tenant_id}_videos", f"{self.tenant_id}_memories"]
        for collection in collections:
            await qdrant.create_snapshot(collection)
            snapshot = await qdrant.list_snapshots(collection)
            await self.upload_snapshot_to_s3(snapshot[0], backup_id)

    async def restore_from_backup(self, backup_id: str):
        """ä»å¤‡ä»½æ¢å¤"""
        # 1. åœæ­¢åº”ç”¨
        await self.stop_application()

        # 2. æ¢å¤æ•°æ®åº“
        await self.restore_neo4j(backup_id)
        await self.restore_qdrant(backup_id)

        # 3. æ¢å¤S3æ•°æ®
        await self.restore_s3(backup_id)

        # 4. éªŒè¯æ•°æ®å®Œæ•´æ€§
        await self.verify_restore(backup_id)

        # 5. é‡å¯åº”ç”¨
        await self.start_application()
```

## ğŸ’° å­˜å‚¨æˆæœ¬ä¼˜åŒ–

### æ•°æ®ç”Ÿå‘½å‘¨æœŸç®¡ç†
```yaml
æ•°æ®å±‚çº§:
  çƒ­æ•°æ® (0-7å¤©):
    å­˜å‚¨: EBS SSD
    å¤‡ä»½: æ¯æ—¥3æ¬¡
    æˆæœ¬: $0.08/GB/æœˆ

  æ¸©æ•°æ® (8-30å¤©):
    å­˜å‚¨: S3 Standard-IA
    å¤‡ä»½: æ¯æ—¥1æ¬¡
    æˆæœ¬: $0.0125/GB/æœˆ

  å†·æ•°æ® (31-365å¤©):
    å­˜å‚¨: S3 Glacier
    å¤‡ä»½: æ¯å‘¨1æ¬¡
    æˆæœ¬: $0.004/GB/æœˆ

  å½’æ¡£æ•°æ® (1å¹´+):
    å­˜å‚¨: S3 Deep Archive
    å¤‡ä»½: æ¯æœˆ1æ¬¡
    æˆæœ¬: $0.00099/GB/æœˆ
```

### å‹ç¼©ä¸å»é‡
```python
class DataOptimization:
    @staticmethod
    async def compress_graph_data(tenant_id: str):
        """å‹ç¼©å›¾æ•°æ®"""
        # 1. è¯†åˆ«é‡å¤èŠ‚ç‚¹
        duplicates = await find_duplicate_memories(tenant_id)

        # 2. åˆå¹¶é‡å¤èŠ‚ç‚¹
        for dup_group in duplicates:
            await merge_memory_nodes(tenant_id, dup_group)

        # 3. å‹ç¼©å±æ€§
        await compress_memory_properties(tenant_id)

    @staticmethod
    async def deduplicate_vectors(tenant_id: str):
        """å‘é‡å»é‡"""
        threshold = 0.95  # ç›¸ä¼¼åº¦é˜ˆå€¼
        await qdrant.optimize_collection(
            collection_name=f"{tenant_id}_memories",
            optimizers_config={
                "default_segment_number": 2,
                "max_segment_size": null
            }
        )
```

## ğŸ” æ•°æ®éš”ç¦»éªŒè¯

### å®‰å…¨æµ‹è¯•ç”¨ä¾‹
```python
async def test_tenant_isolation():
    """æµ‹è¯•ç§Ÿæˆ·æ•°æ®éš”ç¦»"""
    # åˆ›å»ºä¸¤ä¸ªç§Ÿæˆ·
    tenant1 = await create_test_tenant("tenant_001")
    tenant2 = await create_test_tenant("tenant_002")

    # ç§Ÿæˆ·1å­˜å‚¨æ•°æ®
    await memory_service.store_memory(
        tenant_id=tenant1.id,
        data={"content": "private_data_1"}
    )

    # ç§Ÿæˆ·2å­˜å‚¨æ•°æ®
    await memory_service.store_memory(
        tenant_id=tenant2.id,
        data={"content": "private_data_2"}
    )

    # éªŒè¯ç§Ÿæˆ·1åªèƒ½è®¿é—®è‡ªå·±çš„æ•°æ®
    tenant1_data = await memory_service.get_all_memories(tenant1.id)
    assert "private_data_1" in tenant1_data
    assert "private_data_2" not in tenant1_data

    # éªŒè¯ç§Ÿæˆ·2åªèƒ½è®¿é—®è‡ªå·±çš„æ•°æ®
    tenant2_data = await memory_service.get_all_memories(tenant2.id)
    assert "private_data_2" in tenant2_data
    assert "private_data_1" not in tenant2_data

    print("âœ… ç§Ÿæˆ·æ•°æ®éš”ç¦»æµ‹è¯•é€šè¿‡")
```

## âœ… å®æ–½æ¸…å•

### Phase 1: åŸºç¡€éš”ç¦»
- [ ] è®¾è®¡ç§Ÿæˆ·æ•°æ®æ¨¡å‹
- [ ] å®ç°ç§Ÿæˆ·ä¸Šä¸‹æ–‡ä¸­é—´ä»¶
- [ ] æ”¹é€ ç°æœ‰æœåŠ¡æ”¯æŒå¤šç§Ÿæˆ·
- [ ] å•å…ƒæµ‹è¯•éªŒè¯

### Phase 2: éš”ç¦»éªŒè¯
- [ ] å®‰å…¨æµ‹è¯•ï¼ˆç§Ÿæˆ·è¶Šæƒï¼‰
- [ ] æ€§èƒ½æµ‹è¯•ï¼ˆéš”ç¦»å¼€é”€ï¼‰
- [ ] è¾¹ç•Œæµ‹è¯•ï¼ˆç§Ÿæˆ·åˆ é™¤/æ¢å¤ï¼‰
- [ ] å®¡è®¡æ—¥å¿—éªŒè¯

### Phase 3: ä¼˜åŒ–
- [ ] æ•°æ®å‹ç¼©ä¼˜åŒ–
- [ ] å­˜å‚¨æˆæœ¬ä¼˜åŒ–
- [ ] å¤‡ä»½ç­–ç•¥å®ç°
- [ ] ç›‘æ§å‘Šè­¦é…ç½®

---

**æ ¸å¿ƒç†å¿µ**ï¼šå®‰å…¨ã€é€æ˜ã€é«˜æ•ˆã€‚è®©æ•°æ®éš”ç¦»æˆä¸ºé»˜è®¤è¡Œä¸ºï¼Œè€Œéç‰¹æ®Šå¤„ç†ã€‚
