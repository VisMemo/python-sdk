# çŸ¥è¯†å›¾è°±æ¶æ„æ¼”è¿›æ–¹æ¡ˆ
## ä»ç¡¬ç¼–ç åˆ°æ™ºèƒ½åŒ–ï¼šä»å­¤ç«‹èŠ‚ç‚¹åˆ°æ™ºèƒ½è®°å¿†ç½‘ç»œ

---

## ğŸ“‹ ç›®å½•

1. [é—®é¢˜è¯Šæ–­ä¸ç°çŠ¶åˆ†æ](#1-é—®é¢˜è¯Šæ–­ä¸ç°çŠ¶åˆ†æ)
2. [æ–¹æ¡ˆå¯¹æ¯”ä¸è¯„ä¼°](#2-æ–¹æ¡ˆå¯¹æ¯”ä¸è¯„ä¼°)
3. [æœ€ç»ˆæ¶æ„è®¾è®¡](#3-æœ€ç»ˆæ¶æ„è®¾è®¡)
4. [å®æ–½è·¯çº¿å›¾](#4-å®æ–½è·¯çº¿å›¾)
5. [å†³ç­–ä¾æ®ä¸æƒè¡¡](#5-å†³ç­–ä¾æ®ä¸æƒè¡¡)
6. [é£é™©è¯„ä¼°ä¸ç¼“è§£](#6-é£é™©è¯„ä¼°ä¸ç¼“è§£)

---

## 1. é—®é¢˜è¯Šæ–­ä¸ç°çŠ¶åˆ†æ

### 1.1 å½“å‰ç³»ç»Ÿçš„è‡´å‘½ç¼ºé™·

#### æ ¸å¿ƒé—®é¢˜1ï¼šå¤§é‡å­¤ç«‹èŠ‚ç‚¹
**ç°çŠ¶æ•°æ®**ï¼š
- å­¤ç«‹èŠ‚ç‚¹æ¯”ä¾‹ï¼š>40%
- å¹³å‡èŠ‚ç‚¹åº¦ï¼š<2
- æ—¶åºå…³ç³»è¦†ç›–ç‡ï¼š0%

**æ ¹æœ¬åŸå› **ï¼š

```python
# modules/memory/etl/pkl_to_db.py:145-152
# è¿‡åº¦ä¸¥æ ¼çš„ç¡¬ç¼–ç æ˜ å°„
if st == "voice" and dt in {"episodic", "semantic"}:
    rel = "said_by"
elif st == "img" and dt in {"episodic", "semantic"}:
    rel = "appears_in"
# â†’ ä»…æ”¯æŒ4ç§èŠ‚ç‚¹ç±»å‹ç»„åˆ
```

**å­¤ç«‹èŠ‚ç‚¹äº§ç”Ÿçš„å…·ä½“åœºæ™¯**ï¼š
1. **å•èŠ‚ç‚¹ç±»å‹**ï¼šå•ä¸ª `semantic` èŠ‚ç‚¹ï¼Œæ²¡æœ‰å…¶ä»– `semantic/episodic` åœ¨åŒä¸€clip
2. **æ—  clip å…³è”**ï¼š`semantic` èŠ‚ç‚¹æ˜¯ clip å†…å”¯ä¸€èŠ‚ç‚¹ï¼Œæ— æ³•å»ºç«‹ `describes` å…³ç³»
3. **æ— ç©ºé—´ä¿¡æ¯**ï¼š`episodic` èŠ‚ç‚¹ç¼ºå°‘ `room/device` å…ƒæ•°æ®
4. **èŠ‚ç‚¹ç±»å‹ä¸åŒ¹é…**ï¼šä¸æ»¡è¶³ç¡¬ç¼–ç æ˜ å°„è§„åˆ™çš„èŠ‚ç‚¹ç»„åˆ

#### æ ¸å¿ƒé—®é¢˜2ï¼šå…³ç³»ç™½åå•æ³›åŒ–æ€§ä¸¥é‡ç¼ºé™·

**åŒé‡è¿‡æ»¤æ¶æ„**ï¼ˆé—®é¢˜ï¼‰ï¼š
```
æ•°æ®å¯¼å…¥ â†’ ç¡¬ç¼–ç æ˜ å°„ â†’ Edgeå¯¹è±¡ â†’ å­˜å‚¨(Neo4j)
                         â†“
                   å›¾æ‰©å±•æŸ¥è¯¢ â†’ ç¡¬ç¼–ç ç™½åå•è¿‡æ»¤ â†’ æœ€ç»ˆç»“æœ
```

**å…·ä½“ä»£ç ä½ç½®**ï¼š
```python
# å­˜å‚¨æ—¶ (neo4j_store.py:113) - æ­£å¸¸
rel = ed.rel_type.upper()
f"MERGE (s)-[r:{rel}]->(d)"  # å¯ä»¥å­˜å‚¨ä»»æ„å…³ç³»

# æŸ¥è¯¢æ—¶ (neo4j_store.py:277) - é—®é¢˜æ‰€åœ¨ï¼
where_parts.append("type(r) IN $rels")  # ç¡¬ç¼–ç è¿‡æ»¤ï¼
params["rels"] = rels
```

**æ³›åŒ–æ€§é—®é¢˜çš„è¡¨ç°**ï¼š
- æ–°å…³ç³»ç±»å‹ï¼ˆ`CO_OCCURS_WITH`, `INTERACTS_WITH`ï¼‰å­˜å‚¨æ­£å¸¸ä½†æŸ¥è¯¢è¢«è¿‡æ»¤
- æ•°æ®å­˜åœ¨ä½†æ£€ç´¢ä¸åˆ°ï¼Œç­‰åŒäºä¸¢å¤±
- æ¯æ¬¡æ–°å¢å…³ç³»ç±»å‹éƒ½éœ€è¦ä¿®æ”¹ä»£ç å’Œé…ç½®

#### æ ¸å¿ƒé—®é¢˜3ï¼šæ—¶åºå…³ç³»å®Œå…¨ç¼ºå¤±

**ç°çŠ¶**ï¼šç³»ç»Ÿæ²¡æœ‰æ˜¾å¼æ—¶åºå…³ç³»ï¼
- ä»…é€šè¿‡ `clip_id` éšå¼å…³è”
- æ— æ³•æ”¯æŒè·¨ clip çš„æ—¶åºæ¨ç†
- æŸ¥è¯¢æ—¶æ— æ³•å¿«é€Ÿå®šä½"å‰å› åæœ"

### 1.2 ä¸šåŠ¡å½±å“åˆ†æ

| æŒ‡æ ‡ | å½“å‰çŠ¶æ€ | ç›®æ ‡çŠ¶æ€ | å½±å“ |
|------|----------|----------|------|
| å­¤ç«‹èŠ‚ç‚¹ç‡ | >40% | <10% | è®°å¿†æ£€ç´¢å¤±è´¥ç‡é«˜ |
| å¹³å‡èŠ‚ç‚¹åº¦ | <2 | >5 | ç›¸å…³è®°å¿†æ— æ³•æ‰©æ•£ |
| å…³ç³»ç±»å‹æ•° | 6ä¸ª | åŠ¨æ€æ‰©å±• | æ— æ³•é€‚åº”æ–°åœºæ™¯ |
| æ—¶åºè·¯å¾„è¦†ç›– | 0% | >80% | ç¼ºä¹äº‹ä»¶é“¾æ„ŸçŸ¥ |

**ç”¨æˆ·ç—›ç‚¹**ï¼š
- æœç´¢ç»“æœå­¤ç«‹ï¼Œæ— æ³•å½¢æˆè®°å¿†ç½‘ç»œ
- æ–°æ•°æ®æºçš„å…³ç³»ç±»å‹æ— æ³•æ”¯æŒ
- æ— æ³•è¿›è¡Œæ—¶é—´åºåˆ—çš„å›æº¯å’Œæ¨ç†

---

## 2. æ–¹æ¡ˆå¯¹æ¯”ä¸è¯„ä¼°

### 2.1 æ–¹æ¡ˆæ¦‚è§ˆ

æˆ‘ä»¬è¯„ä¼°äº†ä¸‰ä¸ªæ–¹æ¡ˆï¼š

| æ–¹æ¡ˆ | æè¿° | å®æ–½å‘¨æœŸ | é£é™©ç­‰çº§ | é¢„æœŸæ”¶ç›Š |
|------|------|----------|----------|----------|
| **A. GPTå®Œæ•´ä¼ä¸šçº§æ–¹æ¡ˆ** | åˆ†å±‚æ¨¡å‹+å…³ç³»æ³¨å†Œè¡¨+æ—¶åºæ ‘+é“¾è·¯é¢„æµ‹ | 4-6å‘¨ | ğŸ”´ é«˜ | 95% |
| **B. æ¸è¿›å¼è½»é‡æ–¹æ¡ˆ** | æ ‡ç­¾çº¦æŸ+æ—¶åºæ„å»º+å…±ç°å›å¡« | 1-2å‘¨ | ğŸŸ¡ ä¸­ | 85% |
| **C. ä»…ä¿®å¤ç™½åå•** | ç§»é™¤ç¡¬ç¼–ç ç™½åå•ï¼Œæ”¹ä¸ºæ ‡ç­¾çº¦æŸ | 1-2å¤© | ğŸŸ¢ ä½ | 50% |

### 2.2 GPTä¼ä¸šçº§æ–¹æ¡ˆæ·±åº¦åˆ†æ

#### âœ… ä¼˜ç§€è®¾è®¡ç²¾å

**1. å…³ç³»æ³¨å†Œè¡¨ (Edge Catalog) â­â­â­â­â­**
```cypher
MERGE (rt:RelType {name:'CO_OCCURS_WITH'})
ON CREATE SET rt.category='cooccurrence',
              rt.symmetric=true,
              rt.default_weight=0.4,
              rt.allowed=true
```
**ä»·å€¼**ï¼š
- å®Œå…¨è§£å†³ç¡¬ç¼–ç ç™½åå•é—®é¢˜
- æ”¯æŒæ–°å…³ç³»ç±»å‹è‡ªåŠ¨å‘ç°å’Œå®¡æ ¸æµç¨‹
- å…è®¸åŠ¨æ€å¯/ç¦ç”¨å…³ç³»ç±»å‹
- è¯­ä¹‰åˆ†ç±»ç®¡ç†ï¼ˆcategoryï¼‰ä¼˜äºé€ç±»å‹åˆ—ä¸¾

**2. åˆ†å±‚æ¨¡å‹ (Perception/Semantic/Context/Time) â­â­â­â­**
```
Perception: Frame/Shot/Clip(Event)/Detection/Utterance
Semantic: Entity/Concept/Fact
Context: Room/Device/Source
Time: TimeTree (Yearâ†’Monthâ†’Dayâ†’Hourâ†’Second)
```
**ä»·å€¼**ï¼š
- ç†è®ºåŸºç¡€æ‰å®ï¼ˆå¤šæ¨¡æ€çŸ¥è¯†å›¾è°±æ ‡å‡†åšæ³•ï¼‰
- æ”¯æŒå¤æ‚è·¨æ¨¡æ€æ¨ç†ï¼ˆè§†è§‰-è¯­ä¹‰-æ—¶é—´ï¼‰
- ä¸ºé«˜çº§åŠŸèƒ½é“ºè·¯

**3. æ˜¾å¼æ—¶åºå»ºæ¨¡ â­â­â­â­â­**
```cypher
(Clip/Event)-[:OCCURS_AT]->(Time)
(Event)-[:NEXT_EVENT {Î”t}]->(Event)
(Frame)-[:NEXT_FRAME]->(Frame)
```
**ä»·å€¼**ï¼š
- å¡«è¡¥å½“å‰ç³»ç»Ÿæœ€å¤§ç©ºç™½
- æ”¯æŒ"å‰å› åæœ"æŸ¥è¯¢
- è·¯å¾„è¯„åˆ†æ”¯æŒæ—¶é—´è¡°å‡

#### âš ï¸ è¿‡åº¦å·¥ç¨‹/æš‚ä¸é€‚ç”¨çš„éƒ¨åˆ†

**1. å®Œæ•´æ—¶é—´æ ‘ (TimeTree) - è¿‡åº¦å·¥ç¨‹**
```cypher
(Yearâ†’Monthâ†’Dayâ†’Hourâ†’Second)  # 5å±‚åµŒå¥—
```
**åˆ†æ**ï¼š
- å½“å‰ç³»ç»Ÿåªéœ€ clip_id/timestamp ç²’åº¦å³å¯
- å¹´â†’ç§’æ ‘éœ€è¦é¢å¤–å­˜å‚¨å’Œå¤æ‚æŸ¥è¯¢
- å®ç°æˆæœ¬ >> æ”¶ç›Š

**2. å‡ ä½•å…³ç³»è‡ªåŠ¨ç”Ÿæˆ - å®ç”¨ä»·å€¼æœ‰é™**
```python
# éœ€è¦å®æ—¶è®¡ç®—bbox IoU
def geom_rel(detA, detB):
    iou = IoU(detA.bbox, detB.bbox)
    if iou>0.3: rels.append(("OVERLAPS", 0.6))
```
**åˆ†æ**ï¼š
- ç»´æŠ¤æˆæœ¬é«˜ï¼ˆæ¯å¸§éœ€è¦è®¡ç®—ï¼‰
- æŸ¥è¯¢æ—¶å¾ˆå°‘ç”¨å‡ ä½•å…³ç³»åšä¸»è¿‡æ»¤
- å½“å‰ä¼˜å…ˆçº§ä½

**3. GraphSAGE/é“¾è·¯é¢„æµ‹ - å¤æ‚åº¦è¶…æ ‡**
**åˆ†æ**ï¼š
- éœ€è¦è®­ç»ƒé›†ã€è´Ÿé‡‡æ ·ã€è°ƒå‚
- å¯¹å­¤ç«‹èŠ‚ç‚¹å¸®åŠ©æœ‰é™ï¼ˆè®­ç»ƒæ•°æ®ç¨€ç–ï¼‰
- åŸºç¡€è®¾æ–½è¦æ±‚é«˜ï¼ˆGPU/åˆ†å¸ƒå¼è®­ç»ƒï¼‰

**4. å®Œå…¨é‡æ„ ETL æµç¨‹ - é£é™©è¿‡é«˜**
**åˆ†æ**ï¼š
- å½“å‰ETLçº¦200è¡Œï¼Œç®€å•ç›´æ¥
- å¼•å…¥æ£€æµ‹â†’è·Ÿè¸ªâ†’å®ä½“é“¾æ¥éœ€é‡å†™80%ä»£ç 
- "Never break userspace"åŸåˆ™

### 2.3 æˆ‘çš„æ¸è¿›å¼æ–¹æ¡ˆ

åŸºäºGPTæ–¹æ¡ˆçš„ç²¾åï¼Œç»“åˆç°æœ‰ä»£ç åº“çº¦æŸï¼š

**æ ¸å¿ƒç†å¿µ**ï¼šè®©å›¾è°±åœ¨æ„å»ºæ—¶å°±è¿é€šï¼ŒæŸ¥è¯¢åªæ˜¯æ£€ç´¢ï¼

#### æ ¸å¿ƒæ”¹è¿›ç‚¹

**1. æ ‡ç­¾çº¦æŸæ›¿ä»£å…³ç³»ç™½åå•**
```python
# æ›¿ä»£ç¡¬ç¼–ç çš„ rel_whitelist
label_patterns = [
    ("Image,Voice", "Episodic,Semantic"),      # å¤šæ¨¡æ€â†’æ–‡æœ¬
    ("Semantic", "Episodic"),                   # è¯­ä¹‰â†’æƒ…èŠ‚
    ("Episodic", "Structured"),                 # ç©ºé—´/è®¾å¤‡
]

# Neo4j æŸ¥è¯¢
WHERE (
    (any(l1 IN labels(s) WHERE l1 IN ['Image', 'Voice']) AND
     any(l2 IN labels(n) WHERE l2 IN ['Episodic', 'Semantic'])) OR
    ...
)
```
**ä¼˜åŠ¿**ï¼š
- âœ… å®Œå…¨æ”¯æŒä»»æ„å…³ç³»ç±»å‹
- âœ… ä¿æŒå®‰å…¨çš„èŠ‚ç‚¹ç±»å‹çº¦æŸ
- âœ… æ— éœ€ç»´æŠ¤ç™½åå•

**2. æ™ºèƒ½å…³ç³»æ„å»ºï¼ˆåˆ†é˜¶æ®µï¼‰**

**Phase 1: æ—¶åºå…³ç³»æ„å»º**
```python
def build_temporal_edges(nodes_by_clip):
    """ä¸ºæ¯ä¸ª clip å†…çš„ episodic èŠ‚ç‚¹å»ºç«‹ TEMPORAL_NEXT"""
    for clip_id, nodes in nodes_by_clip.items():
        episodic_nodes = sorted(
            [n for n in nodes if n.kind == 'episodic'],
            key=lambda n: n.metadata.get('timestamp', 0)
        )
        for i in range(len(episodic_nodes) - 1):
            dt = episodic_nodes[i+1].timestamp - episodic_nodes[i].timestamp
            weight = 1.0 - min(dt / 60, 1.0)  # 1åˆ†é’Ÿå†…ä¸è¡°å‡
            yield Edge(..., rel_type='TEMPORAL_NEXT', weight=weight)
```

**Phase 2: å…±ç°å›å¡«**
```python
def build_cooccurrence_edges(nodes_by_clip):
    """åŒ clip å†… entity èŠ‚ç‚¹ä¸¤ä¸¤å»ºç«‹ CO_OCCURS_WITH"""
    for clip_id, nodes in nodes_by_clip.items():
        entities = [n for n in nodes if n.kind in ['episodic', 'semantic']]
        for i, e1 in enumerate(entities):
            for e2 in entities[i+1:]:
                yield Edge(
                    src_id=e1.id, dst_id=e2.id,
                    rel_type='CO_OCCURS_WITH', weight=0.4
                )
```

**Phase 3: æ™ºèƒ½æƒé‡å¼•æ“**
```python
class RelationWeightEngine:
    """å…³ç³»æƒé‡å¼•æ“"""
    def __init__(self):
        self.base_weights = {
            'APPEARS_IN': 1.0,
            'SAID_BY': 1.0,
            'TEMPORAL_NEXT': 0.8,
            'CO_OCCURS_WITH': 0.4,
            'DEFAULT': 0.5,
        }

    def compute_path_weight(self, edges, hops):
        base = sum(self.get_base_weight(e.rel_type) for e in edges)
        hop_factor = {1: 1.0, 2: 0.5, 3: 0.25}[hops]
        edge_factor = 1.0
        for e in edges:
            edge_factor *= (e.weight or 1.0)
        return base * hop_factor * edge_factor
```

### 2.4 æ–¹æ¡ˆå¯¹æ¯”è¯¦ç»†åˆ†æ

| ç»´åº¦ | GPTå®Œæ•´æ–¹æ¡ˆ | æ¸è¿›å¼æ–¹æ¡ˆ | ä»…ä¿®å¤ç™½åå• |
|------|-------------|------------|--------------|
| **å­¤ç«‹èŠ‚ç‚¹æ”¹å–„** | <5% | <10% | 20-30% |
| **å…³ç³»ç±»å‹æ”¯æŒ** | æ— é™ | æœ‰é™ï¼ˆä½†å¯æ‰©å±•ï¼‰ | ä»…ç°æœ‰6ç§ |
| **æ—¶åºèƒ½åŠ›** | TimeTree (å¼º) | ç®€åŒ–æ—¶åº (ä¸­) | æ—  |
| **å®æ–½å¤æ‚åº¦** | æé«˜ | ä¸­ç­‰ | æä½ |
| **é£é™©ç­‰çº§** | ğŸ”´ é«˜ | ğŸŸ¡ ä¸­ | ğŸŸ¢ ä½ |
| **ç»´æŠ¤æˆæœ¬** | é«˜ | ä½ | æä½ |
| **æ³›åŒ–èƒ½åŠ›** | â­â­â­â­â­ | â­â­â­â­ | â­â­ |
| **å‘åå…¼å®¹** | éœ€å¤§é‡ä¿®æ”¹ | å¯ä¿æŒ | å®Œå…¨ä¿æŒ |
| **é¢„æœŸæ”¶ç›Š/æˆæœ¬æ¯”** | 0.8 | 0.9 | 1.5 |

---

## 3. æœ€ç»ˆæ¶æ„è®¾è®¡

### 3.1 æ€»ä½“æ¶æ„æ¼”è¿›è·¯å¾„

```mermaid
graph TB
    A[å½“å‰çŠ¶æ€: ç¡¬ç¼–ç +å­¤ç«‹èŠ‚ç‚¹] --> B[Phase 1: ç§»é™¤ç™½åå•]
    B --> C[Phase 2: æ—¶åº+å…±ç°æ„å»º]
    C --> D[Phase 3: æƒé‡å¼•æ“+æ™ºèƒ½é‡æ’]
    D --> E[Phase 4: å…³ç³»æ³¨å†Œè¡¨+LLMæ¨æ–­]
    E --> F[é•¿æœŸæ¼”è¿›: å®Œæ•´ä¼ä¸šçº§]

    style A fill:#ffcccc
    style B fill:#fff2cc
    style C fill:#d5e8d4
    style D fill:#d5e8d4
    style E fill:#e1d5e7
    style F fill:#e1d5e7
```

### 3.2 å››å±‚æ™ºèƒ½æ„å»ºæ¶æ„

#### ç¬¬ä¸€å±‚ï¼šæ•°æ®æ³¨å…¥å±‚çš„æ™ºèƒ½å…³ç³»å‘ç°

**ç›®æ ‡**ï¼šä»ç¡¬ç¼–ç æ˜ å°„è½¬å‘æ™ºèƒ½æ¨ç†

**å®ç°æ–¹å¼**ï¼š
```python
class SmartRelationInferencer:
    """æ™ºèƒ½å…³ç³»æ¨ç†å™¨"""

    def infer_relation(
        self,
        src: Node,
        dst: Node,
        context: dict
    ) -> tuple[str, float]:
        """
        æ™ºèƒ½å…³ç³»æ¨ç†

        Returns: (relation_type, weight, confidence)
        """
        # 1. å¤šç»´åº¦ç›¸ä¼¼åº¦è®¡ç®—
        sim_multimodal = compute_multimodal_similarity(src, dst)
        temporal_proximity = compute_temporal_proximity(src, dst)
        spatial_proximity = compute_spatial_proximity(src, dst)
        semantic_alignment = compute_semantic_alignment(src, dst)

        # 2. è§„åˆ™åº“ + LLM æ¨ç†
        candidates = []
        if src.modality in ['voice', 'audio'] and dst.modality == 'text':
            candidates.append(('SAID_BY', 1.0, 0.9))

        # ... æ›´å¤šè§„åˆ™

        # 3. æ–°å…³ç³»ç±»å‹åŠ¨æ€å‘ç°
        if not candidates and semantic_alignment > 0.7:
            inferred_type = llm_infer_relation(src, dst, context)
            candidates.append((inferred_type, 0.8, 0.6))

        # 4. é€‰æ‹©æœ€ä½³å€™é€‰
        best = max(candidates, key=lambda x: x[1] * x[2])
        final_weight = best[1] * (
            0.4 * sim_multimodal +
            0.3 * temporal_proximity +
            0.2 * spatial_proximity +
            0.1 * semantic_alignment
        )

        return best[0], final_weight, best[2]
```

**æ¼”è¿›ç­–ç•¥**ï¼š
- Phase 1: ä¿ç•™ç¡¬ç¼–ç ï¼Œæ·»åŠ fallbackæœºåˆ¶
- Phase 2: å¼•å…¥è§„åˆ™åº“
- Phase 3: é›†æˆLLMæ¨æ–­

#### ç¬¬äºŒå±‚ï¼šèŠ‚ç‚¹æ ‡ç­¾çº¦æŸæœºåˆ¶

**æ ¸å¿ƒç†å¿µ**ï¼šç”¨èŠ‚ç‚¹æ ‡ç­¾å¯¹çº¦æŸæ›¿ä»£å…³ç³»åç™½åå•

**å…è®¸çš„è¾¹æ¨¡å¼**ï¼š
```yaml
allowed_edge_patterns:
  - source_labels: [Image, Voice]
    target_labels: [Episodic, Semantic]
    description: "å¤šæ¨¡æ€åˆ°æ–‡æœ¬çš„å…³è”"

  - source_labels: [Semantic]
    target_labels: [Episodic]
    description: "è¯­ä¹‰åˆ°æƒ…èŠ‚çš„æè¿°å…³ç³»"

  - source_labels: [Episodic]
    target_labels: [Structured:room, Structured:device]
    description: "ç©ºé—´å’Œè®¾å¤‡å…³è”"

  - source_labels: [Episodic]
    target_labels: [Episodic]
    description: "æ—¶åºé‚»æ¥å…³ç³»ï¼ˆéœ€æ—¶é—´çº¦æŸï¼‰"
```

**æŸ¥è¯¢å®ç°**ï¼š
```python
def build_label_based_query(label_patterns):
    """åŸºäºæ ‡ç­¾ç»„åˆæ„å»ºæŸ¥è¯¢æ¡ä»¶"""
    clauses = []
    for src_labels, dst_labels in label_patterns:
        src_labels_str = ",".join([f"'{l}'" for l in src_labels])
        dst_labels_str = ",".join([f"'{l}'" for l in dst_labels])
        clause = (
            f"(any(l1 IN labels(s) WHERE l1 IN [{src_labels_str}]) AND "
            f" any(l2 IN labels(n) WHERE l2 IN [{dst_labels_str}]))"
        )
        clauses.append(clause)

    return " OR ".join(clauses)
```

**Neo4jæŸ¥è¯¢ç¤ºä¾‹**ï¼š
```cypher
MATCH (s:Entity)-[r]->(n:Entity)
WHERE (
    // æ¨¡å¼1: å¤šæ¨¡æ€â†’æ–‡æœ¬
    (any(l1 IN labels(s) WHERE l1 IN ['Image', 'Voice']) AND
     any(l2 IN labels(n) WHERE l2 IN ['Episodic', 'Semantic'])) OR

    // æ¨¡å¼2: è¯­ä¹‰â†’æƒ…èŠ‚
    (any(l1 IN labels(s) WHERE l1 = 'Semantic') AND
     any(l2 IN labels(n) WHERE l2 = 'Episodic')) OR

    // æ¨¡å¼3: æ—¶åºé‚»æ¥
    (any(l1 IN labels(s) WHERE l1 = 'Episodic') AND
     any(l2 IN labels(n) WHERE l2 = 'Episodic'))
)
RETURN s, r, n
```

**ä¼˜åŠ¿**ï¼š
- âœ… å…³ç³»åå®Œå…¨è‡ªç”±ï¼ˆæ”¯æŒ `CO_OCCURS_WITH` ç­‰æ–°ç±»å‹ï¼‰
- âœ… æ ‡ç­¾ç»„åˆå›ºå®šä¸”å®‰å…¨ï¼ˆä»…å…è®¸é¢„å®šä¹‰çš„èŠ‚ç‚¹ç±»å‹ç»„åˆï¼‰
- âœ… æ–¹å‘çº¦æŸæ¸…æ™°
- âœ… æ€§èƒ½å¯æ§ï¼ˆåœ¨Neo4jå±‚è¿‡æ»¤ï¼‰

#### ç¬¬ä¸‰å±‚ï¼šæ—¶åºå…³ç³»ä¸»åŠ¨æ„å»º

**ç›®æ ‡**ï¼šå¡«è¡¥æ—¶åºæ¨ç†ç©ºç™½ï¼Œæ„å»ºæ˜¾å¼äº‹ä»¶é“¾

**ä¸‰å¤§ç­–ç•¥**ï¼š

**1. åŒ clip å†…æ—¶åº**
```python
def build_intra_clip_temporal_edges(clips: dict):
    """å¯¹æ¯ä¸ª clip å†…çš„ episodic èŠ‚ç‚¹æŒ‰æ—¶é—´æ’åºï¼Œ
    å»ºç«‹ç›¸é‚»èŠ‚ç‚¹é—´çš„ TEMPORAL_NEXT å…³ç³»"""
    temporal_edges = []

    for clip_id, nodes in clips.items():
        # æŒ‰ timestamp æ’åº
        sorted_nodes = sorted(nodes, key=lambda n: n.metadata.get('timestamp', 0))

        # å»ºç«‹ç›¸é‚»èŠ‚ç‚¹é—´çš„æ—¶åºè¾¹
        for i in range(len(sorted_nodes) - 1):
            src = sorted_nodes[i]
            dst = sorted_nodes[i + 1]

            dt = dst.metadata.get('timestamp', 0) - src.metadata.get('timestamp', 0)
            dt_max = sorted_nodes[-1].metadata.get('timestamp', 0) - sorted_nodes[0].metadata.get('timestamp', 0)
            weight = 1.0 - (dt / dt_max) if dt_max > 0 else 1.0

            temporal_edges.append(Edge(
                src_id=src.id,
                dst_id=dst.id,
                rel_type='TEMPORAL_NEXT',
                weight=weight,
                metadata={'dt': dt, 'clip_id': clip_id}
            ))

    return temporal_edges
```

**2. è·¨ clip æ—¶åºæ¨æ–­**
```python
def build_cross_clip_temporal_edges(episodic_nodes: List[Node]):
    """å¯¹è¯­ä¹‰ç›¸ä¼¼çš„ episodic èŠ‚ç‚¹ï¼ˆè·¨ clipï¼‰ï¼Œ
    å¦‚æœæ—¶é—´æ¥è¿‘ï¼Œå»ºç«‹æ—¶åºå…³ç³»"""
    temporal_edges = []
    time_window = 5 * 60  # 5åˆ†é’Ÿçª—å£

    for i, node_i in enumerate(episodic_nodes):
        for j, node_j in enumerate(episodic_nodes[i+1:], i+1):
            dt = abs(node_j.metadata.get('timestamp', 0) -
                     node_i.metadata.get('timestamp', 0))

            if dt > time_window:
                continue  # è¶…å‡ºæ—¶é—´çª—å£

            # è¯­ä¹‰ç›¸ä¼¼åº¦
            sim = compute_semantic_similarity(node_i.contents, node_j.contents)

            if sim > 0.7:  # ç›¸ä¼¼åº¦é˜ˆå€¼
                weight = sim * (1.0 - (dt / time_window))

                if node_i.metadata.get('timestamp', 0) < node_j.metadata.get('timestamp', 0):
                    temporal_edges.append(Edge(
                        src_id=node_i.id,
                        dst_id=node_j.id,
                        rel_type='TEMPORAL_NEXT',
                        weight=weight,
                        metadata={'cross_clip': True, 'dt': dt, 'sim': sim}
                    ))

    return temporal_edges
```

**3. äº‹ä»¶é“¾è¡¥å…¨**
```python
def attach_orphan_nodes(orphan_nodes: List[Node], all_nodes: List[Node]):
    """å¯¹å­¤ç«‹ episodic èŠ‚ç‚¹ï¼Œå°è¯•å»ºç«‹å¼±è¿æ¥"""
    edges = []

    for orphan in orphan_nodes:
        # æ‰¾æœ€è¿‘çš„ episodic èŠ‚ç‚¹
        nearest = None
        min_dist = float('inf')

        for node in all_nodes:
            if node.id == orphan.id or node.kind != 'episodic':
                continue

            # æ–‡æœ¬ç›¸ä¼¼åº¦
            bm25_sim = compute_bm25_similarity(orphan.contents, node.contents)

            # æ—¶é—´è·ç¦»
            dt = abs(orphan.metadata.get('timestamp', 0) -
                     node.metadata.get('timestamp', 0))
            time_sim = 1.0 - min(dt / 3600, 1.0)  # 1å°æ—¶å†…è¡°å‡

            dist = -0.7 * bm25_sim - 0.3 * time_sim

            if dist < min_dist:
                min_dist = dist
                nearest = node

        # å¦‚æœç›¸ä¼¼åº¦è¶³å¤Ÿé«˜ï¼Œå»ºç«‹å¼±æ—¶åºè¿æ¥
        if nearest and -min_dist > 0.5:  # é˜ˆå€¼
            edges.append(Edge(
                src_id=nearest.id,
                dst_id=orphan.id,
                rel_type='TEMPORAL_NEXT',
                weight=0.3,  # å¼±è¿æ¥
                metadata={'weak_link': True, 'reason': 'orphan_attach'}
            ))

    return edges
```

#### ç¬¬å››å±‚ï¼šåŠ¨æ€æƒé‡ä¸é‡æ’èåˆ

**ç›®æ ‡**ï¼šå¤šç»´åº¦åŠ æƒï¼Œè½¯è¿‡æ»¤ä¼˜äºç¡¬è¿‡æ»¤

**æƒé‡ç­–ç•¥**ï¼š
```python
class RelationWeightEngine:
    """å…³ç³»æƒé‡å¼•æ“"""

    def __init__(self, config=None):
        self.config = config or {}
        # å…³ç³»ç±»å‹åŸºç¡€æƒé‡
        self.base_weights = self.config.get("base_weights", {
            "APPEARS_IN": 1.0,
            "SAID_BY": 1.0,
            "DESCRIBES": 0.9,
            "TEMPORAL_NEXT": 0.8,
            "LOCATED_IN": 0.7,
            "EQUIVALENCE": 0.6,
            "CO_OCCURS_WITH": 0.4,
            "INTERACTS_WITH": 0.3,
            "DEFAULT": 0.5,  # æ–°å…³ç³»ç±»å‹é»˜è®¤æƒé‡
        })

        # è·³æ•°è¡°å‡å› å­
        self.hop_decay = self.config.get("hop_decay", {
            1: 1.0,
            2: 0.5,
            3: 0.25,
        })

    def compute_path_weight(self, edges: List[Edge], hops: int) -> float:
        """è®¡ç®—è·¯å¾„æ€»æƒé‡
        å…¬å¼: W = (Î£ base_weight) * hop_decay * (Î  edge.weight)
        """
        # åŸºç¡€å…³ç³»æƒé‡ä¹‹å’Œ
        base_sum = sum(self.get_base_weight(e.rel_type) for e in edges)

        # è·³æ•°è¡°å‡
        hop_factor = self.get_hop_decay(hops)

        # è¾¹æƒé‡ç´¯ä¹˜
        edge_factor = 1.0
        for e in edges:
            edge_factor *= (e.weight or 1.0)

        return base_sum * hop_factor * edge_factor
```

**æœç´¢é‡æ’èåˆ**ï¼š
```python
async def rerank_with_graph_scores(
    vec_results: List[SearchHit],
    graph_neighbors: Dict[str, List[Neighbor]],
    weight_engine: RelationWeightEngine
) -> List[RerankedHit]:
    """èåˆå‘é‡åˆ†æ•°å’Œå›¾åˆ†æ•°"""
    reranked = []

    for hit in vec_results:
        vec_score = hit.vector_score
        graph_score = 0.0

        # è®¡ç®—å›¾æ‰©å±•è´¡çŒ®
        if hit.id in graph_neighbors:
            for neighbor in graph_neighbors[hit.id]:
                path_weight = weight_engine.compute_path_weight(
                    neighbor.edges, neighbor.hops
                )
                hop_boost = self.graph_config.hop_boosts.get(neighbor.hops, 1.0)
                graph_score += path_weight * hop_boost

        # èåˆåˆ†æ•°
        alpha_vector = 0.35
        gamma_graph = 0.15

        final_score = (
            alpha_vector * vec_score +
            gamma_graph * graph_score
        )

        reranked.append(RerankedHit(
            id=hit.id,
            payload=hit.payload,
            score=final_score,
            vector_score=vec_score,
            graph_score=graph_score,
            neighbors=graph_neighbors.get(hit.id, [])
        ))

    return sorted(reranked, key=lambda x: x.score, reverse=True)
```

### 3.3 å…³ç³»æ³¨å†Œè¡¨ï¼ˆé•¿æœŸæ¼”è¿›ï¼‰

**ç›®æ ‡**ï¼šç»ˆæè§£å†³æ–¹æ¡ˆâ€”â€”å®Œå…¨æ¶ˆé™¤ç¡¬ç¼–ç 

**è®¾è®¡**ï¼š
```cypher
// å…³ç³»æ³¨å†Œè¡¨
MERGE (rt:RelType {
    name: 'CO_OCCURS_WITH',
    category: 'cooccurrence',
    symmetric: true,
    default_weight: 0.4,
    allowed: true,
    domain: ['Entity', 'Concept'],
    range: ['Entity', 'Concept'],
    created_at: timestamp(),
    description: 'åŒäº‹ä»¶/çª—å£å…±ç°å…³ç³»'
})

// æŸ¥è¯¢æ—¶åŠ¨æ€å±•å¼€
WITH $rel_categories AS cats
MATCH (rt:RelType)
WHERE (cats='*' OR rt.category IN cats) AND rt.allowed=true
WITH collect(rt.name) AS rels
MATCH p=(s)-[r]->(t)
WHERE type(r) IN rels
  AND r.confidence >= $min_conf
RETURN p
```

**è‡ªåŠ¨å‘ç°æœºåˆ¶**ï¼š
```python
def auto_register_relation(relation_type: str, properties: dict):
    """æ–°å…³ç³»ç±»å‹è‡ªåŠ¨æ³¨å†Œ"""
    tx.run("""
        MERGE (rt:RelType {name:$name})
        ON CREATE SET rt.category='unknown',
                      rt.allowed=false,
                      rt.default_weight=0.2,
                      rt.auto_discovered=true,
                      rt.discovered_at=timestamp()
    """, name=relation_type)

    # å‘é€å‘Šè­¦ï¼šéœ€è¦äººå·¥å®¡æ ¸
    send_alert(f"New relation type discovered: {relation_type}")
```

---

## 4. å®æ–½è·¯çº¿å›¾

### 4.1 åˆ†é˜¶æ®µå®æ–½ç­–ç•¥

```mermaid
gantt
    title çŸ¥è¯†å›¾è°±æ¶æ„æ¼”è¿›è·¯çº¿å›¾
    dateFormat  YYYY-MM-DD
    section Phase 1: åŸºç¡€ä¿®å¤
    ç§»é™¤å…³ç³»ç™½åå•       :crit, p1-1, 2025-11-03, 1d
    æ—¶åºå…³ç³»æ„å»º         :p1-2, 2025-11-04, 2d
    å…±ç°å›å¡«             :p1-3, 2025-11-06, 2d
    æµ‹è¯•éªŒè¯             :p1-4, 2025-11-08, 1d

    section Phase 2: æ™ºèƒ½æ„å»º
    è§„åˆ™åº“æ¨ç†           :p2-1, 2025-11-10, 3d
    æƒé‡å¼•æ“             :p2-2, 2025-11-13, 2d
    æœç´¢é‡æ’ä¼˜åŒ–         :p2-3, 2025-11-15, 2d
    æ€§èƒ½ä¼˜åŒ–             :p2-4, 2025-11-17, 2d

    section Phase 3: é«˜çº§ç‰¹æ€§
    LLMå…³ç³»æ¨æ–­         :p3-1, 2025-11-20, 5d
    å…³ç³»æ³¨å†Œè¡¨          :p3-2, 2025-11-25, 3d
    å¯è§†åŒ–è¯Šæ–­          :p3-3, 2025-11-28, 3d

    section Phase 4: ä¼ä¸šçº§æ¼”è¿›
    å®Œæ•´åˆ†å±‚æ¨¡å‹        :p4-1, 2025-12-01, 14d
    é“¾è·¯é¢„æµ‹           :p4-2, 2025-12-15, 7d
```

### 4.2 è¯¦ç»†å®æ–½è®¡åˆ’

#### Phase 1: åŸºç¡€ä¿®å¤ï¼ˆ1å‘¨ï¼‰

**ç›®æ ‡**ï¼šè§£å†³å­¤ç«‹èŠ‚ç‚¹å’Œç™½åå•é—®é¢˜

**ä»»åŠ¡æ¸…å•**ï¼š

**Day 1-2: ç§»é™¤å…³ç³»ç™½åå•**
- [x] ä¿®æ”¹ `neo4j_store.py expand_neighbors()` æ–¹æ³•
  ```python
  # ä¿®æ”¹å‰ (é—®é¢˜)
  if rels:
      where_parts.append("type(r) IN $rels")
      params["rels"] = rels

  # ä¿®æ”¹å (è§£å†³)
  if use_label_patterns:
      label_patterns = get_allowed_label_patterns()
      # åŸºäºæ ‡ç­¾ç»„åˆç”ŸæˆWHEREæ¡ä»¶
  else:
      where_parts.append("type(r) IN $rels")  # ä¿æŒå…¼å®¹
  ```
- [x] æ·»åŠ é…ç½®é¡¹ `memory.search.graph.label_patterns`
- [x] å‘åå…¼å®¹æ€§æµ‹è¯•

**Day 3-5: æ—¶åºå…³ç³»æ„å»º**
- [ ] åœ¨ `pkl_to_db.py` ä¸­æ·»åŠ  `build_temporal_edges()` å‡½æ•°
- [ ] å¯¹åŒ clip çš„ episodic èŠ‚ç‚¹å»ºç«‹ `TEMPORAL_NEXT` å…³ç³»
- [ ] è·¨ clip æ—¶åºæ¨æ–­ï¼ˆå¯é€‰ï¼‰
- [ ] å­¤ç«‹èŠ‚ç‚¹è‡ªåŠ¨è¡¥è¾¹

**Day 6-7: æµ‹è¯•éªŒè¯**
- [ ] å•å…ƒæµ‹è¯•ï¼šæ ‡ç­¾çº¦æŸæ­£ç¡®æ€§
- [ ] é›†æˆæµ‹è¯•ï¼šæ—¶åºå…³ç³»å­˜åœ¨
- [ ] æ€§èƒ½æµ‹è¯•ï¼šæŸ¥è¯¢å»¶è¿Ÿ < 100msï¼ˆp95ï¼‰
- [ ] å›å½’æµ‹è¯•ï¼šç°æœ‰æœç´¢ç»“æœæ— æ˜¾è‘—å˜åŒ–

**éªŒæ”¶æ ‡å‡†**ï¼š
```python
# æµ‹è¯•ç”¨ä¾‹
async def test_phase1():
    # 1. æ ‡ç­¾çº¦æŸç”Ÿæ•ˆ
    edges = await neo.expand_neighbors(
        seed_ids=['node1'],
        use_label_patterns=True
    )
    assert all(is_valid_label_pattern(e) for e in edges)

    # 2. æ—¶åºå…³ç³»å­˜åœ¨
    temporal_edges = await neo.get_temporal_edges('clip_001')
    assert len(temporal_edges) > 0
    assert all(e.rel_type == 'TEMPORAL_NEXT' for e in temporal_edges)

    # 3. å­¤ç«‹èŠ‚ç‚¹ç‡ < 20%
    orphan_rate = await compute_orphan_rate()
    assert orphan_rate < 0.2
```

#### Phase 2: æ™ºèƒ½æ„å»ºï¼ˆ1å‘¨ï¼‰

**ç›®æ ‡**ï¼šå¼•å…¥æ™ºèƒ½æ¨ç†å’Œæƒé‡æœºåˆ¶

**ä»»åŠ¡æ¸…å•**ï¼š

**Day 1-3: è§„åˆ™åº“æ¨ç†**
- [ ] åˆ›å»º `modules/memory/application/relation_inference.py`
- [ ] å®ç°å¤šç»´åº¦ç›¸ä¼¼åº¦è®¡ç®—
- [ ] æ·»åŠ è§„åˆ™åº“ï¼ˆç¡¬ç¼–ç è§„åˆ™ + LLMæ¨ç†ï¼‰
- [ ] ä¿®æ”¹ETLè°ƒç”¨æ™ºèƒ½æ¨ç†å™¨

**Day 4-5: æƒé‡å¼•æ“**
- [ ] å®ç° `RelationWeightEngine` ç±»
- [ ] æ”¯æŒåŠ¨æ€æƒé‡é…ç½®
- [ ] æ·»åŠ å…³ç³»ç±»å‹æƒé‡

**Day 6-7: æœç´¢é‡æ’ä¼˜åŒ–**
- [ ] ä¿®æ”¹ `service.py` ä¸­çš„é‡æ’é€»è¾‘
- [ ] èåˆå›¾åˆ†æ•°ç»´åº¦
- [ ] æ€§èƒ½ä¼˜åŒ–ï¼ˆç¼“å­˜ã€å¹¶è¡ŒæŸ¥è¯¢ï¼‰

**éªŒæ”¶æ ‡å‡†**ï¼š
```python
async def test_phase2():
    # 1. æ–°å…³ç³»ç±»å‹è‡ªåŠ¨å‘ç°
    new_edges = await infer_relations(nodes)
    assert 'DYNAMIC_REL_XXX' in [e.rel_type for e in new_edges]

    # 2. æƒé‡è®¡ç®—æ­£ç¡®
    weight = weight_engine.get_base_weight('CO_OCCURS_WITH')
    assert weight == 0.4

    # 3. é‡æ’æ•ˆæœæå‡
    results_old = await search_with_old_ranking(query)
    results_new = await search_with_new_ranking(query)
    ndcg_improvement = compute_ndcg(results_new, results_old)
    assert ndcg_improvement > 0.05  # NDCG@10 æå‡ 5%
```

#### Phase 3: é«˜çº§ç‰¹æ€§ï¼ˆ1å‘¨ï¼‰

**ç›®æ ‡**ï¼šå¼•å…¥LLMå’Œæ³¨å†Œè¡¨æœºåˆ¶

**ä»»åŠ¡æ¸…å•**ï¼š

**Day 1-3: LLMå…³ç³»æ¨æ–­**
- [ ] é›†æˆLLMæ¨ç†æœåŠ¡
- [ ] å®ç°å…³ç³»ç±»å‹æ¨æ–­
- [ ] ç½®ä¿¡åº¦ç®¡ç†

**Day 4-5: å…³ç³»æ³¨å†Œè¡¨**
- [ ] åœ¨Neo4jä¸­åˆ›å»ºRelTypeèŠ‚ç‚¹
- [ ] å®ç°è‡ªåŠ¨æ³¨å†Œæœºåˆ¶
- [ ] æŸ¥è¯¢å±‚æŒ‰ç±»åˆ«å±•å¼€

**Day 6-7: å¯è§†åŒ–è¯Šæ–­**
- [ ] å­¤ç«‹èŠ‚ç‚¹ç‡ç›‘æ§
- [ ] å…³ç³»åˆ†å¸ƒå¯è§†åŒ–
- [ ] æ€§èƒ½æŒ‡æ ‡ä»ªè¡¨ç›˜

#### Phase 4: ä¼ä¸šçº§æ¼”è¿›ï¼ˆ3å‘¨ï¼‰

**ç›®æ ‡**ï¼šå®ç°å®Œæ•´çš„ä¼ä¸šçº§çŸ¥è¯†å›¾è°±

**ä»»åŠ¡æ¸…å•**ï¼š

**Week 1: åˆ†å±‚æ¨¡å‹**
- [ ] å®ç°Perception/Semantic/Context/Timeåˆ†å±‚
- [ ] å®ä½“é“¾æ¥å’Œè·Ÿè¸ª
- [ ] æœ¬ä½“çº¦æŸ

**Week 2: é«˜çº§ç®—æ³•**
- [ ] å¼•å…¥GraphSAGE/é“¾è·¯é¢„æµ‹
- [ ] ä¸ªæ€§åŒ–PageRank
- [ ] æ—¶é—´è¡°å‡ç®—æ³•

**Week 3: å·¥ç¨‹å®Œå–„**
- [ ] SHACLçº¦æŸéªŒè¯
- [ ] æµå¼æ›´æ–°
- [ ] å¤‡ä»½æ¢å¤

### 4.3 å…³é”®é‡Œç¨‹ç¢‘

| é‡Œç¨‹ç¢‘ | æ—¥æœŸ | éªŒæ”¶æ ‡å‡† | è´Ÿè´£äºº |
|--------|------|----------|--------|
| **M1: ç™½åå•ç§»é™¤** | Day 2 | æŸ¥è¯¢å»¶è¿Ÿ < 100ms | Team |
| **M2: æ—¶åºæ„å»º** | Day 5 | å­¤ç«‹èŠ‚ç‚¹ç‡ < 20% | Team |
| **M3: æ™ºèƒ½æ¨ç†** | Day 10 | æ–°å…³ç³»ç±»å‹è‡ªåŠ¨å‘ç° | Team |
| **M4: æƒé‡å¼•æ“** | Day 12 | NDCG@10 +5% | Team |
| **M5: æ³¨å†Œè¡¨** | Day 17 | å®Œå…¨æ¶ˆé™¤ç¡¬ç¼–ç  | Team |
| **M6: ä¼ä¸šçº§** | Day 30 | å­¤ç«‹èŠ‚ç‚¹ç‡ < 5% | Team |

---

## 5. å†³ç­–ä¾æ®ä¸æƒè¡¡

### 5.1 æ ¸å¿ƒå†³ç­–åŸåˆ™

**1. å·¥ç¨‹çº¦æŸä¼˜å…ˆ**
- éµå¾ª"Never break userspace"é“å¾‹
- ä¿æŒAPIå‘åå…¼å®¹
- æœ€å°åŒ–ä»£ç ä¿®æ”¹

**2. æ”¶ç›Š/æˆæœ¬å¹³è¡¡**
- 80%æ”¶ç›Šï¼Œ20%æˆæœ¬ > 95%æ”¶ç›Šï¼Œ80%æˆæœ¬
- ä¼˜å…ˆè§£å†³æ ¸å¿ƒç—›ç‚¹ï¼ˆå­¤ç«‹èŠ‚ç‚¹ã€ç™½åå•ï¼‰
- é«˜çº§ç‰¹æ€§å¯å»¶å

**3. æ¸è¿›å¼æ¼”è¿›**
- æ¯é˜¶æ®µéƒ½æœ‰ç‹¬ç«‹ä»·å€¼
- å¤±è´¥æ—¶å¯å›é€€åˆ°å‰ä¸€é˜¶æ®µ
- æŒç»­éªŒè¯å’Œè°ƒæ•´

### 5.2 é€‰æ‹©æ¸è¿›å¼æ–¹æ¡ˆçš„å…³é”®ç†ç”±

#### ç†ç”±1ï¼šé£é™©å¯æ§
**å®Œæ•´é‡æ„çš„é£é™©**ï¼š
- å¤§å¹…ä¿®æ”¹ETLæµç¨‹ï¼Œå¯èƒ½å¼•å…¥æ–°bug
- å¼•å…¥å¤šä¸ªæ–°ä¾èµ–ï¼ˆLLMã€GraphSAGEï¼‰
- å­¦ä¹ æ›²çº¿é™¡å³­ï¼Œç»´æŠ¤å›°éš¾

**æ¸è¿›å¼çš„ä¼˜åŠ¿**ï¼š
```python
# æ¯ä¸€æ­¥éƒ½æ˜¯å°æ”¹åŠ¨ï¼Œå®¹æ˜“å›é€€
# Phase 1: ä»…ä¿®æ”¹æŸ¥è¯¢å±‚ (5è¡Œä»£ç )
# Phase 2: æ·»åŠ æ—¶åºæ„å»º (50è¡Œä»£ç )
# Phase 3: æ™ºèƒ½æ¨ç† (100è¡Œä»£ç )
```

#### ç†ç”±2ï¼šå¿«é€Ÿè§æ•ˆ
**æ—¶é—´çº¿å¯¹æ¯”**ï¼š
- å®Œæ•´æ–¹æ¡ˆï¼š4-6å‘¨æ‰èƒ½çœ‹åˆ°æ•ˆæœ
- æ¸è¿›å¼ï¼šDay 2å°±èƒ½è§£å†³ç™½åå•é—®é¢˜ï¼ŒDay 5è§£å†³å­¤ç«‹èŠ‚ç‚¹

**ä¸šåŠ¡å½±å“**ï¼š
- ç”¨æˆ·æ¯å¤©éƒ½åœ¨ä½¿ç”¨ç³»ç»Ÿ
- å¿«é€Ÿæ”¹è¿›èƒ½ç«‹å³æå‡ç”¨æˆ·ä½“éªŒ
- é™ä½æŠ€æœ¯å€ºåŠ¡ç´¯ç§¯

#### ç†ç”±3ï¼šæŠ€æœ¯åŒ¹é…åº¦
**ç³»ç»Ÿå®šä½**ï¼š
- å½“å‰ï¼šè½»é‡å¤šæ¨¡æ€è®°å¿†ç³»ç»Ÿ
- GPTæ–¹æ¡ˆï¼šé€šç”¨ä¼ä¸šçº§çŸ¥è¯†å›¾è°±

**åŒ¹é…åº¦åˆ†æ**ï¼š
```python
# å½“å‰ç³»ç»Ÿç‰¹ç‚¹
- æ•°æ®é‡ï¼šä¸­ç­‰ (<ç™¾ä¸‡èŠ‚ç‚¹)
- å®æ—¶æ€§è¦æ±‚ï¼šé«˜
- å¤æ‚åº¦ï¼šé€‚ä¸­
- å›¢é˜Ÿè§„æ¨¡ï¼šå°

# å®Œæ•´æ–¹æ¡ˆç‰¹ç‚¹
- æ•°æ®é‡ï¼šå¤§é‡ (>åƒä¸‡èŠ‚ç‚¹)
- å®æ—¶æ€§è¦æ±‚ï¼šä¸­ç­‰
- å¤æ‚åº¦ï¼šé«˜
- å›¢é˜Ÿè§„æ¨¡ï¼šå¤§

# ç»“è®ºï¼šæ¸è¿›å¼æ›´åŒ¹é…
```

### 5.3 å…³é”®æƒè¡¡å†³ç­–

#### å†³ç­–1ï¼šæ—¶åºå»ºæ¨¡æ·±åº¦
**é€‰é¡¹**ï¼š
- A. å®Œæ•´TimeTree (GPTæ–¹æ¡ˆ)
- B. ç®€åŒ–æ—¶åºå…³ç³» (æˆ‘çš„æ–¹æ¡ˆ)

**é€‰æ‹©ï¼šB**

**ç†ç”±**ï¼š
- å½“å‰ç³»ç»Ÿåªéœ€ clip_id/timestamp ç²’åº¦
- TimeTreeå®ç°å¤æ‚åº¦å’Œæ”¶ç›Šä¸åŒ¹é…
- ç®€åŒ–æ–¹æ¡ˆå·²èƒ½æ»¡è¶³80%éœ€æ±‚

#### å†³ç­–2ï¼šå…³ç³»å‘ç°æœºåˆ¶
**é€‰é¡¹**ï¼š
- A. çº¯LLMæ¨æ–­
- B. è§„åˆ™åº“ + LLM (æˆ‘çš„æ–¹æ¡ˆ)
- C. çº¯ç¡¬ç¼–ç  (å½“å‰)

**é€‰æ‹©ï¼šB**

**ç†ç”±**ï¼š
- çº¯LLMæˆæœ¬é«˜ä¸”ä¸ç¨³å®š
- çº¯ç¡¬ç¼–ç ç¼ºä¹æ³›åŒ–æ€§
- æ··åˆæ–¹æ¡ˆå¹³è¡¡äº†ä¸¤è€…

#### å†³ç­–3ï¼šæƒé‡ç®¡ç†
**é€‰é¡¹**ï¼š
- A. ç¡¬ç¼–ç æƒé‡
- B. é…ç½®æ–‡ä»¶æƒé‡
- C. åŠ¨æ€å­¦ä¹ æƒé‡

**é€‰æ‹©ï¼šB**

**ç†ç”±**ï¼š
- ç¡¬ç¼–ç ä¸çµæ´»
- åŠ¨æ€å­¦ä¹ å¤æ‚åº¦é«˜
- é…ç½®æ–‡ä»¶å¹³è¡¡äº†çµæ´»æ€§å’Œç®€å•æ€§

### 5.4 é£é™©æƒè¡¡çŸ©é˜µ

| å†³ç­–ç‚¹ | é€‰é¡¹ | æ”¶ç›Š | é£é™© | æˆæœ¬ | å¾—åˆ† |
|--------|------|------|------|------|------|
| **æ—¶åºå»ºæ¨¡** | TimeTree | 9 | 7 | 8 | 6.7 |
| | ç®€åŒ–æ—¶åº | 7 | 3 | 3 | **8.0** |
| **å…³ç³»å‘ç°** | çº¯LLM | 8 | 8 | 9 | 5.3 |
| | è§„åˆ™+LLM | 8 | 4 | 5 | **7.3** |
| | ç¡¬ç¼–ç  | 4 | 2 | 1 | 6.7 |
| **æƒé‡ç®¡ç†** | ç¡¬ç¼–ç  | 3 | 1 | 1 | 5.7 |
| | é…ç½® | 7 | 2 | 2 | **8.3** |
| | åŠ¨æ€å­¦ä¹  | 9 | 6 | 8 | 5.3 |

**ç»“è®º**ï¼šæ‰€æœ‰å…³é”®å†³ç­–éƒ½é€‰æ‹©äº†æ¸è¿›å¼æ–¹æ¡ˆ

---

## 6. é£é™©è¯„ä¼°ä¸ç¼“è§£

### 6.1 é£é™©çŸ©é˜µ

| é£é™©ç±»å‹ | å½±å“ç­‰çº§ | å‘ç”Ÿæ¦‚ç‡ | é£é™©å€¼ | ç¼“è§£æªæ–½ |
|----------|----------|----------|--------|----------|
| **æŸ¥è¯¢æ€§èƒ½ä¸‹é™** | ğŸŸ¡ ä¸­ | ğŸŸ¡ ä¸­ | ğŸŸ  ä¸­é«˜ | ä¼˜åŒ–Neo4jæŸ¥è¯¢ã€æ·»åŠ ç¼“å­˜ |
| **å…³ç³»æ¨ç†é”™è¯¯** | ğŸŸ  é«˜ | ğŸŸ¡ ä¸­ | ğŸ”´ é«˜ | ä¿ç•™ç¡¬ç¼–ç fallbackã€ç½®ä¿¡åº¦é˜ˆå€¼ |
| **æ•°æ®ä¸ä¸€è‡´** | ğŸ”´ é«˜ | ğŸŸ¢ ä½ | ğŸŸ  ä¸­é«˜ | åŒå†™éªŒè¯ã€å›æ»šæœºåˆ¶ |
| **å­¤ç«‹èŠ‚ç‚¹æœªå‡å°‘** | ğŸŸ¡ ä¸­ | ğŸŸ¡ ä¸­ | ğŸŸ  ä¸­ | ç›‘æ§å‘Šè­¦ã€æŒç»­ä¼˜åŒ–ç®—æ³• |
| **é…ç½®å†²çª** | ğŸŸ¡ ä¸­ | ğŸŸ¡ ä¸­ | ğŸŸ  ä¸­ | æ¸è¿›å¼è¿ç§»ã€é…ç½®éªŒè¯ |
| **å‘åå…¼å®¹æ€§** | ğŸ”´ é«˜ | ğŸŸ¡ ä¸­ | ğŸ”´ é«˜ | é»˜è®¤ä¿æŒæ—§è¡Œä¸ºã€å¯é…ç½®å¼€å…³ |

### 6.2 æ ¸å¿ƒé£é™©æ·±åº¦åˆ†æ

#### é£é™©1ï¼šæŸ¥è¯¢æ€§èƒ½ä¸‹é™

**é£é™©æè¿°**ï¼š
- æ ‡ç­¾çº¦æŸæ¯”å…³ç³»åè¿‡æ»¤æ›´å¤æ‚
- æ—¶åºå…³ç³»å¢åŠ æŸ¥è¯¢æ·±åº¦
- å…±ç°å›å¡«å¢åŠ è¾¹å¯†åº¦

**ç¼“è§£æªæ–½**ï¼š
```python
# 1. æŸ¥è¯¢ä¼˜åŒ–
@cached(ttl=300)
async def expand_neighbors_cached(seed_ids, **kwargs):
    """å¸¦ç¼“å­˜çš„é‚»å±…æ‰©å±•"""
    return await expand_neighbors(seed_ids, **kwargs)

# 2. å¹¶è¡ŒæŸ¥è¯¢
async def parallel_expand(seed_ids, max_workers=4):
    """å¹¶è¡Œæ‰©å±•å¤šä¸ªç§å­èŠ‚ç‚¹"""
    with ThreadPoolExecutor(max_workers=max_workers) as pool:
        futures = [
            loop.run_in_executor(pool, expand_neighbors, [seed_id])
            for seed_id in seed_ids
        ]
        results = await asyncio.gather(*futures)
    return merge_results(results)

# 3. ç´¢å¼•ä¼˜åŒ–
# ç¡®ä¿ Neo4j ä¸­æœ‰å¿…è¦çš„ç´¢å¼•
CREATE INDEX node_id_idx IF NOT EXISTS FOR (n:Entity) ON (n.id);
CREATE INDEX rel_type_idx IF NOT EXISTS FOR ()-[r]-() ON (type(r));
```

#### é£é™©2ï¼šå…³ç³»æ¨ç†é”™è¯¯

**é£é™©æè¿°**ï¼š
- LLMæ¨æ–­å¯èƒ½ä¸ç¨³å®š
- è§„åˆ™åº“å¯èƒ½è¦†ç›–ä¸è¶³
- æ–°å…³ç³»ç±»å‹å¯èƒ½è¯¯åˆ¤

**ç¼“è§£æªæ–½**ï¼š
```python
# 1. ç½®ä¿¡åº¦é˜ˆå€¼
MIN_CONFIDENCE = 0.6

def filter_by_confidence(edges):
    """æŒ‰ç½®ä¿¡åº¦è¿‡æ»¤"""
    return [e for e in edges if (e.confidence or 0.0) >= MIN_CONFIDENCE]

# 2. Fallbackæœºåˆ¶
async def infer_relations_with_fallback(nodes):
    """å¸¦fallbackçš„å…³ç³»æ¨ç†"""
    try:
        edges = await intelligent_inference(nodes)
        if len(edges) > 0:
            return edges
    except Exception as e:
        logger.warning(f"Intelligent inference failed: {e}")

    # Fallbackåˆ°ä¼ ç»Ÿæ˜ å°„
    logger.info("Falling back to legacy mapping")
    return legacy_mapping(nodes)

# 3. äººå·¥å®¡æ ¸
async def review_new_relations():
    """æ–°å…³ç³»ç±»å‹å®¡æ ¸"""
    new_relations = await discover_new_relations()
    for rel_type in new_relations:
        await send_review_request(rel_type)
```

#### é£é™©3ï¼šå‘åå…¼å®¹æ€§

**é£é™©æè¿°**ï¼š
- APIæ¥å£å˜åŒ–
- æŸ¥è¯¢ç»“æœå˜åŒ–
- é…ç½®æ ¼å¼å˜åŒ–

**ç¼“è§£æªæ–½**ï¼š
```python
# 1. APIç‰ˆæœ¬ç®¡ç†
@api.route('/search')
class SearchAPI:
    @api.expect(search_schema)
    def post(self):
        # ä¿æŒåŸæœ‰æ¥å£ä¸å˜
        # é€šè¿‡ headers åŒºåˆ†ç‰ˆæœ¬
        version = request.headers.get('API-Version', 'v1')

        if version == 'v1':
            return self.search_v1(request.json)
        else:
            return self.search_v2(request.json)

# 2. æ¸è¿›å¼è¿ç§»
class FeatureFlags:
    def __init__(self):
        self.use_label_patterns = config.get('use_label_patterns', False)
        self.use_temporal_edges = config.get('use_temporal_edges', False)

    @contextmanager
    def feature_toggle(self, feature_name):
        """ç‰¹æ€§å¼€å…³"""
        old_value = getattr(self, feature_name)
        try:
            yield
        finally:
            setattr(self, feature_name, old_value)

# 3. é…ç½®å›æ»š
class ConfigManager:
    async def backup_config(self):
        """å¤‡ä»½å½“å‰é…ç½®"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = f"config_backup/{timestamp}.yaml"
        shutil.copy("memory.config.yaml", backup_path)
        return backup_path

    async def rollback_config(self, backup_path):
        """å›æ»šé…ç½®"""
        shutil.copy(backup_path, "memory.config.yaml")
        logger.warning(f"Config rolled back to {backup_path}")
```

### 6.3 åº”æ€¥é¢„æ¡ˆ

#### åœºæ™¯1ï¼šæŸ¥è¯¢æ€§èƒ½æ€¥å‰§ä¸‹é™

**å“åº”æµç¨‹**ï¼š
1. **ç«‹å³å“åº”**ï¼ˆ5åˆ†é’Ÿå†…ï¼‰
   ```bash
   # ç¦ç”¨æ ‡ç­¾çº¦æŸï¼Œå›é€€åˆ°å…³ç³»ç™½åå•
   kubectl patch configmap memory-config \
     --patch '{"data":{"use_label_patterns":"false"}}'
   ```

2. **æ ¹å› åˆ†æ**ï¼ˆ30åˆ†é’Ÿå†…ï¼‰
   - æ£€æŸ¥Neo4jæŸ¥è¯¢è®¡åˆ’
   - åˆ†ææ…¢æŸ¥è¯¢æ—¥å¿—
   - ç¡®è®¤ç´¢å¼•çŠ¶æ€

3. **ä¼˜åŒ–æªæ–½**ï¼ˆ2å°æ—¶å†…ï¼‰
   - æ·»åŠ ç¼ºå¤±ç´¢å¼•
   - ä¼˜åŒ–æŸ¥è¯¢æ¡ä»¶
   - è°ƒæ•´ç¼“å­˜ç­–ç•¥

#### åœºæ™¯2ï¼šå­¤ç«‹èŠ‚ç‚¹ç‡ä¸é™åå‡

**å“åº”æµç¨‹**ï¼š
1. **æš‚åœæ™ºèƒ½æ„å»º**ï¼ˆç«‹å³ï¼‰
   ```python
   # ç¦ç”¨æ™ºèƒ½æ¨ç†ï¼Œä½¿ç”¨ä¼ ç»Ÿæ˜ å°„
   config["intelligent_inference"]["enabled"] = False
   ```

2. **æ•°æ®å›æ»š**ï¼ˆ1å°æ—¶å†…ï¼‰
   - å¤‡ä»½å½“å‰æ•°æ®
   - ä»å¿«ç…§æ¢å¤

3. **é—®é¢˜åˆ†æ**ï¼ˆ24å°æ—¶å†…ï¼‰
   - åˆ†ææ™ºèƒ½æ¨ç†é”™è¯¯æ¡ˆä¾‹
   - è°ƒä¼˜ç®—æ³•å‚æ•°
   - è¡¥å……æµ‹è¯•ç”¨ä¾‹

### 6.4 ç›‘æ§å‘Šè­¦

```python
# 1. å­¤ç«‹èŠ‚ç‚¹ç›‘æ§
async def monitor_orphan_nodes():
    """ç›‘æ§å­¤ç«‹èŠ‚ç‚¹æ¯”ä¾‹"""
    orphan_rate = await compute_orphan_rate()

    if orphan_rate > 0.1:  # > 10%
        alert = Alert(
            level="WARNING",
            message=f"High orphan rate: {orphan_rate:.2%}",
            action="Consider running orphan governance"
        )
        await send_alert(alert)

# 2. å…³ç³»ç±»å‹åˆ†å¸ƒç›‘æ§
async def monitor_relation_distribution():
    """ç›‘æ§å…³ç³»ç±»å‹åˆ†å¸ƒ"""
    distribution = await graph.get_relation_distribution()

    # æ£€æµ‹å¼‚å¸¸
    new_relations = set(distribution.keys()) - set(EXPECTED_RELATIONS)

    if new_relations:
        logger.info(f"New relation types discovered: {new_relations}")

# 3. æ€§èƒ½ç›‘æ§
async def monitor_query_latency():
    """ç›‘æ§æŸ¥è¯¢å»¶è¿Ÿ"""
    start = time.time()
    results = await search("test", expand_graph=True)
    latency = time.time() - start

    if latency > 0.1:  # > 100ms
        alert = Alert(
            level="WARNING",
            message=f"Slow query: {latency:.3f}s",
            action="Consider optimization"
        )
        await send_alert(alert)
```

### 6.5 éªŒæ”¶æ ‡å‡†

#### Phase 1 éªŒæ”¶
- [ ] æ ‡ç­¾çº¦æŸæ›¿ä»£å…³ç³»ç™½åå•
- [ ] æ—¶åºå…³ç³»æˆåŠŸæ„å»º
- [ ] æŸ¥è¯¢å»¶è¿Ÿ < 100msï¼ˆp95ï¼‰
- [ ] å‘åå…¼å®¹æ€§ï¼šç°æœ‰æœç´¢ç»“æœæ— æ˜¾è‘—å˜åŒ–ï¼ˆp-value > 0.05ï¼‰

#### Phase 2 éªŒæ”¶
- [ ] æ™ºèƒ½å…³ç³»æ¨ç†å™¨æ­£å¸¸å·¥ä½œ
- [ ] æ–°å…³ç³»ç±»å‹è‡ªåŠ¨å‘ç°
- [ ] ç½®ä¿¡åº¦è¾“å‡ºå‡†ç¡®ï¼ˆéªŒè¯é›†å‡†ç¡®ç‡ > 80%ï¼‰
- [ ] fallbackæœºåˆ¶å¯é ï¼ˆå¤±è´¥æ—¶è‡ªåŠ¨å›é€€ï¼‰

#### Phase 3 éªŒæ”¶
- [ ] å­¤ç«‹èŠ‚ç‚¹æ¯”ä¾‹ < 10%
- [ ] å¹³å‡èŠ‚ç‚¹åº¦ > 5
- [ ] æ—¶åºè·¯å¾„è¦†ç›–ç‡ > 80%
- [ ] è·¨clipæ—¶åºæ¨æ–­å‡†ç¡®ï¼ˆéªŒè¯é›†F1-score > 0.7ï¼‰

#### Phase 4 éªŒæ”¶
- [ ] å…³ç³»æ³¨å†Œè¡¨æ­£å¸¸å·¥ä½œ
- [ ] LLMå…³ç³»æ¨æ–­å‡†ç¡®ï¼ˆéªŒè¯é›†å‡†ç¡®ç‡ > 70%ï¼‰
- [ ] æœç´¢é‡æ’æ•ˆæœæå‡ï¼ˆNDCG@10 +10%ï¼‰
- [ ] å®Œå…¨æ¶ˆé™¤ç¡¬ç¼–ç 

---

## ğŸ“š æ€»ç»“

### æ ¸å¿ƒç†å¿µ
**è®©å›¾è°±åœ¨æ„å»ºæ—¶å°±è¿é€šï¼ŒæŸ¥è¯¢åªæ˜¯æ£€ç´¢ï¼**

### æ¼”è¿›è·¯å¾„
```
ç¡¬ç¼–ç  â†’ æ ‡ç­¾çº¦æŸ â†’ æ™ºèƒ½æ„å»º â†’ æƒé‡ä¼˜åŒ– â†’ æ³¨å†Œè¡¨ â†’ ä¼ä¸šçº§
```

### å…³é”®æ”¹è¿›
1. **ç§»é™¤å…³ç³»ç™½åå•** â†’ æ”¯æŒä»»æ„å…³ç³»ç±»å‹
2. **æ˜¾å¼æ—¶åºå»ºæ¨¡** â†’ å¡«è¡¥æ—¶åºæ¨ç†ç©ºç™½
3. **å…±ç°å›å¡«** â†’ è§£å†³å­¤ç«‹èŠ‚ç‚¹é—®é¢˜
4. **æ™ºèƒ½æ¨ç†** â†’ æå‡å…³ç³»è´¨é‡
5. **æƒé‡å¼•æ“** â†’ ä¼˜åŒ–æ£€ç´¢æ•ˆæœ
6. **å…³ç³»æ³¨å†Œè¡¨** â†’ ç»ˆææ³›åŒ–æ–¹æ¡ˆ

### é¢„æœŸæ•ˆæœ
| æŒ‡æ ‡ | æ”¹è¿›å‰ | æ”¹è¿›å | æå‡ |
|------|--------|--------|------|
| å­¤ç«‹èŠ‚ç‚¹ç‡ | >40% | <10% | â†‘300% |
| å¹³å‡èŠ‚ç‚¹åº¦ | <2 | >5 | â†‘150% |
| å…³ç³»ç±»å‹æ•° | 6 | åŠ¨æ€æ‰©å±• | âˆ |
| æ—¶åºè·¯å¾„è¦†ç›– | 0% | >80% | æ–°èƒ½åŠ› |

### é£é™©è¯„ä¼°
- **é«˜é£é™©**ï¼šå…³ç³»æ¨ç†é”™è¯¯ã€å‘åå…¼å®¹æ€§
- **ä¸­é£é™©**ï¼šæŸ¥è¯¢æ€§èƒ½ä¸‹é™ã€é…ç½®å†²çª
- **ä½é£é™©**ï¼šå­¤ç«‹èŠ‚ç‚¹æœªå‡å°‘

### å†³ç­–ä¾æ®
1. **å·¥ç¨‹çº¦æŸä¼˜å…ˆ** - éµå¾ª"Never break userspace"
2. **æ”¶ç›Š/æˆæœ¬å¹³è¡¡** - 80%æ”¶ç›Šï¼Œ20%æˆæœ¬
3. **æ¸è¿›å¼æ¼”è¿›** - æ¯é˜¶æ®µéƒ½æœ‰ç‹¬ç«‹ä»·å€¼

### æˆåŠŸæ ‡å‡†
- **æŠ€æœ¯æŒ‡æ ‡**ï¼šå­¤ç«‹èŠ‚ç‚¹ç‡ < 10%ï¼Œå¹³å‡èŠ‚ç‚¹åº¦ > 5
- **æ€§èƒ½æŒ‡æ ‡**ï¼šæŸ¥è¯¢å»¶è¿Ÿ < 100msï¼ŒNDCG@10 +10%
- **ä¸šåŠ¡æŒ‡æ ‡**ï¼šè®°å¿†æ£€ç´¢æˆåŠŸç‡ > 90%ï¼Œç”¨æˆ·æ»¡æ„åº¦æå‡

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¥æœŸ**: 2025-11-03
**æœ€åæ›´æ–°**: 2025-11-03
**è´Ÿè´£äºº**: Linus (Claude Code)
**å®¡æ ¸çŠ¶æ€**: å¾…å®¡æ ¸
