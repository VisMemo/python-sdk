# Gemini æ‰¹å¤„ç†å¹¶å‘ä¼˜åŒ–æ–¹æ¡ˆ

## é—®é¢˜è¯Šæ–­

### å½“å‰æ€§èƒ½ç“¶é¢ˆ
- **ä¸²è¡Œæ‰¹å¤„ç†**ï¼š10ä¸ªæ‰¹æ¬¡é€ä¸ªå¤„ç†ï¼Œæ€»æ—¶é—´400ç§’+
- **å•æ‰¹æ¬¡å»¶è¿Ÿ**ï¼šæ¯ä¸ªæ‰¹æ¬¡çº¦40ç§’APIå“åº”æ—¶é—´
- **å¹¶å‘ä¸Šä¼ ç¼ºå¤±**ï¼šæ— æ³•åˆ©ç”¨å¹¶è¡Œå¤„ç†åŠ é€Ÿ

### æ ¸å¿ƒé—®é¢˜ä»£ç ä½ç½®
**æ–‡ä»¶**ï¼š`modules/memorization_agent/application/llm_provider.py:927-1000`

```python
# å½“å‰ä¸²è¡Œå¤„ç†ä»£ç 
for bi in range(win_count):  # â† ä¸²è¡Œå¾ªç¯ï¼
    # æ¯ä¸ªæ‰¹æ¬¡éœ€è¦ç­‰å¾…å‰ä¸€ä¸ªå®Œæˆ
    # æ‰¹æ¬¡0 â†’ æ‰¹æ¬¡1 â†’ æ‰¹æ¬¡2 â†’ ... â†’ æ‰¹æ¬¡9
```

## å¹¶å‘ä¼˜åŒ–æ–¹æ¡ˆ

### æ–¹æ¡ˆ1ï¼šasyncio å¹¶å‘å¤„ç†ï¼ˆæ¨èï¼‰â­

```python
import asyncio
from typing import List, Dict, Any

async def _process_batch_concurrent(
    self,
    batches: List[List[int]],
    prompt: str,
    frames: List[Any],
    ctx: Dict[str, Any],
    max_concurrent: int = 3  # é™åˆ¶å¹¶å‘æ•°é¿å…APIé™æµ
) -> List[Dict[str, Any]]:
    """å¹¶å‘å¤„ç†æ‰¹æ¬¡ï¼Œæ§åˆ¶å¹¶å‘æ•°é¿å…APIé™åˆ¶"""

    semaphore = asyncio.Semaphore(max_concurrent)

    async def process_single_batch(batch_indices: List[int]) -> Dict[str, Any]:
        async with semaphore:
            try:
                # æ„å»ºæ‰¹æ¬¡æ¶ˆæ¯
                user_mapping = self._build_mapping_text(batch_indices)

                # ä¸´æ—¶æ›¿æ¢framesä¸Šä¸‹æ–‡
                _ctx_saved_frames = (ctx.get("slice") or {}).get("frames")
                (ctx.get("slice") or {})["frames"] = [frames[i] for i in batch_indices]

                u = self._build_user_with_prompt(prompt, attach_frames_override=len(batch_indices))
                u2 = {"role": "user", "content": list(u.get("content") or []) +
                       [{"type": "text", "text": f"images_map: {user_mapping}"}]}

                # è°ƒç”¨API
                raw = await self._adapter.generate_async([u2], response_format=None)
                data = self._enhanced_parse_llm_response(raw) if isinstance(raw, str) else {}

                # æ¢å¤ä¸Šä¸‹æ–‡
                (ctx.get("slice") or {})["frames"] = _ctx_saved_frames

                return {
                    "batch_id": batch_indices[0] if batch_indices else 0,
                    "success": bool(data.get("semantic_timeline")),
                    "data": data,
                    "error": None
                }
            except Exception as e:
                return {
                    "batch_id": batch_indices[0] if batch_indices else 0,
                    "success": False,
                    "data": {},
                    "error": str(e)
                }

    # å¹¶å‘æ‰§è¡Œæ‰€æœ‰æ‰¹æ¬¡
    tasks = [process_single_batch(batch_indices) for batch_indices in batches]
    results = await asyncio.gather(*tasks, return_exceptions=True)

    return results

# ä½¿ç”¨ç¤ºä¾‹
if batch_mode == "multi" and total > images_per_batch:
    # å‡†å¤‡æ‰¹æ¬¡æ•°æ®
    batches = [...]  # 10ä¸ªæ‰¹æ¬¡çš„ç´¢å¼•åˆ—è¡¨

    # ğŸ”¥ å¹¶å‘å¤„ç†
    results = await self._process_batch_concurrent(
        batches=batches,
        prompt=prompt,
        frames=frames,
        ctx=ctx,
        max_concurrent=3  # é™åˆ¶3ä¸ªå¹¶å‘ï¼Œé¿å…APIé™æµ
    )
```

### æ–¹æ¡ˆ2ï¼šçº¿ç¨‹æ± å¹¶å‘ï¼ˆç®€å•å®ç°ï¼‰

```python
import concurrent.futures
from threading import Lock

def _process_batch_threaded(
    self,
    batches: List[List[int]],
    prompt: str,
    frames: List[Any],
    ctx: Dict[str, Any],
    max_workers: int = 3
) -> List[Dict[str, Any]]:
    """ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†æ‰¹æ¬¡"""

    results = [None] * len(batches)
    results_lock = Lock()

    def process_batch_worker(batch_indices: List[int], batch_idx: int):
        try:
            # æ„å»ºæ‰¹æ¬¡æ¶ˆæ¯ï¼ˆåŒä¸²è¡Œç‰ˆæœ¬ï¼‰
            user_mapping = self._build_mapping_text(batch_indices)
            _ctx_saved_frames = (ctx.get("slice") or {}).get("frames")
            (ctx.get("slice") or {})["frames"] = [frames[i] for i in batch_indices]

            u = self._build_user_with_prompt(prompt, attach_frames_override=len(batch_indices))
            u2 = {"role": "user", "content": list(u.get("content") or []) +
                   [{"type": "text", "text": f"images_map: {user_mapping}"}]}

            # è°ƒç”¨API
            raw = self._adapter.generate([u2], response_format=None)
            data = self._enhanced_parse_llm_response(raw) if isinstance(raw, str) else {}

            # æ¢å¤ä¸Šä¸‹æ–‡
            (ctx.get("slice") or {})["frames"] = _ctx_saved_frames

            result = {
                "batch_id": batch_idx,
                "success": bool(data.get("semantic_timeline")),
                "data": data,
                "error": None
            }
        except Exception as e:
            result = {
                "batch_id": batch_idx,
                "success": False,
                "data": {},
                "error": str(e)
            }

        with results_lock:
            results[batch_idx] = result

    # æäº¤æ‰€æœ‰ä»»åŠ¡åˆ°çº¿ç¨‹æ± 
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = [
            executor.submit(process_batch_worker, batch_indices, i)
            for i, batch_indices in enumerate(batches)
        ]
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        concurrent.futures.wait(futures)

    return results
```

### æ–¹æ¡ˆ3ï¼šæ··åˆç­–ç•¥ï¼ˆæœ€ä¼˜ï¼‰

```python
async def _process_batch_hybrid(
    self,
    batches: List[List[int]],
    prompt: str,
    frames: List[Any],
    ctx: Dict[str, Any],
) -> List[Dict[str, Any]]:
    """æ··åˆç­–ç•¥ï¼šé¢„ä¸Šä¼ å›¾ç‰‡ + å¹¶å‘APIè°ƒç”¨"""

    # é˜¶æ®µ1ï¼šå¹¶å‘é¢„ä¸Šä¼ å›¾ç‰‡åˆ°Gemini Files API
    print("[Perf] å¹¶å‘ä¸Šä¼ å›¾ç‰‡åˆ°Gemini Files API...")
    uploaded_files = await self._upload_frames_concurrent(frames)

    # é˜¶æ®µ2ï¼šä½¿ç”¨æ–‡ä»¶å¼•ç”¨å¹¶å‘è°ƒç”¨è¯­ä¹‰API
    print("[Perf] å¹¶å‘è°ƒç”¨è¯­ä¹‰API...")
    semaphore = asyncio.Semaphore(3)  # é™åˆ¶å¹¶å‘æ•°

    async def process_batch_with_files(batch_indices: List[int]) -> Dict[str, Any]:
        async with semaphore:
            try:
                # ä½¿ç”¨æ–‡ä»¶å¼•ç”¨æ›¿ä»£Base64
                file_refs = [uploaded_files[i] for i in batch_indices]

                # æ„å»ºæ¶ˆæ¯ï¼ˆä½¿ç”¨æ–‡ä»¶å¼•ç”¨ï¼‰
                user_mapping = self._build_mapping_text(batch_indices)
                u = self._build_user_with_prompt(prompt, attach_frames_override=len(batch_indices))

                # æ›¿æ¢å†…å®¹ä¸ºæ–‡ä»¶å¼•ç”¨
                u["content"] = [{"type": "text", "text": prompt}] + file_refs + [
                    {"type": "text", "text": f"images_map: {user_mapping}"}
                ]

                # è°ƒç”¨API
                raw = await self._adapter.generate_async([u], response_format=None)
                data = self._enhanced_parse_llm_response(raw) if isinstance(raw, str) else {}

                return {
                    "batch_id": batch_indices[0] if batch_indices else 0,
                    "success": bool(data.get("semantic_timeline")),
                    "data": data,
                    "error": None
                }
            except Exception as e:
                return {
                    "batch_id": batch_indices[0] if batch_indices else 0,
                    "success": False,
                    "data": {},
                    "error": str(e)
                }

    # å¹¶å‘æ‰§è¡Œ
    tasks = [process_batch_with_files(batch_indices) for batch_indices in batches]
    results = await asyncio.gather(*tasks, return_exceptions=True)

    return results

async def _upload_frames_concurrent(self, frames: List[str]) -> List[Any]:
    """å¹¶å‘ä¸Šä¼ å›¾ç‰‡åˆ°Gemini Files API"""
    try:
        from google import genai
        client = genai.Client()

        async def upload_single_frame(frame_path: str):
            try:
                # ä¸Šä¼ å¹¶è¿”å›æ–‡ä»¶å¼•ç”¨
                file_ref = client.files.upload(file=frame_path)
                return file_ref
            except Exception as e:
                print(f"Failed to upload {frame_path}: {e}")
                # å›é€€åˆ°Base64
                return await self._convert_to_data_url_async(frame_path)

        # å¹¶å‘ä¸Šä¼ æ‰€æœ‰å¸§
        tasks = [upload_single_frame(frame) for frame in frames]
        uploaded_files = await asyncio.gather(*tasks, return_exceptions=True)

        return uploaded_files
    except Exception as e:
        print(f"Gemini Files API upload failed: {e}")
        # å›é€€åˆ°Base64
        return [await self._convert_to_data_url_async(frame) for frame in frames]
```

## é¢„æœŸæ€§èƒ½æå‡

### å½“å‰æ€§èƒ½
- **ä¸²è¡Œå¤„ç†**ï¼š10æ‰¹æ¬¡ Ã— 40ç§’ = 400ç§’ï¼ˆ6.6åˆ†é’Ÿï¼‰
- **å•ä¸ªæ‰¹æ¬¡**ï¼š40ç§’

### ä¼˜åŒ–åæ€§èƒ½

| å¹¶å‘æ•° | ç†è®ºæ—¶é—´ | å®é™…æ—¶é—´* | åŠ é€Ÿæ¯” |
|--------|----------|-----------|--------|
| 3å¹¶å‘ | 133ç§’ | 150-180ç§’ | **2.7x** |
| 5å¹¶å‘ | 80ç§’ | 100-120ç§’ | **4x** |
| 10å¹¶å‘ | 40ç§’ | 60-80ç§’ | **6-7x** |

*å®é™…æ—¶é—´è€ƒè™‘äº†APIé™æµå’Œç³»ç»Ÿèµ„æº

## å®æ–½å»ºè®®

### é˜¶æ®µ1ï¼šç«‹å³å®æ–½ï¼ˆ30åˆ†é’Ÿï¼‰
1. ä½¿ç”¨**çº¿ç¨‹æ± å¹¶å‘**ï¼ˆæ–¹æ¡ˆ2ï¼‰
2. é™åˆ¶å¹¶å‘æ•°ä¸º3ï¼ˆé¿å…APIé™æµï¼‰
3. ä¿æŒç°æœ‰APIè°ƒç”¨é€»è¾‘ä¸å˜

### é˜¶æ®µ2ï¼šçŸ­æœŸä¼˜åŒ–ï¼ˆ1å¤©ï¼‰
1. å®ç°**asyncioå¹¶å‘**ï¼ˆæ–¹æ¡ˆ1ï¼‰
2. æ·»åŠ æ€§èƒ½ç›‘æ§å’Œé”™è¯¯é‡è¯•
3. ä¼˜åŒ–å†…å­˜ä½¿ç”¨

### é˜¶æ®µ3ï¼šé•¿æœŸä¼˜åŒ–ï¼ˆ3-5å¤©ï¼‰
1. å®ç°**æ··åˆç­–ç•¥**ï¼ˆæ–¹æ¡ˆ3ï¼‰
2. Gemini Files APIé¢„ä¸Šä¼ 
3. æ™ºèƒ½å¹¶å‘æ•°è°ƒæ•´

## é£é™©æ§åˆ¶

### APIé™æµ
- è®¾ç½®`max_concurrent=3`ä½œä¸ºåˆå§‹å€¼
- æ ¹æ®APIå“åº”æ—¶é—´åŠ¨æ€è°ƒæ•´
- æ·»åŠ æŒ‡æ•°é€€é¿é‡è¯•æœºåˆ¶

### å†…å­˜ç®¡ç†
- æ¯ä¸ªå¹¶å‘ä»»åŠ¡ç‹¬ç«‹å¤„ç†ï¼Œé¿å…å…±äº«çŠ¶æ€
- åŠæ—¶é‡Šæ”¾å¤§å¯¹è±¡ï¼ˆå›¾ç‰‡ã€APIå“åº”ï¼‰

### é”™è¯¯å¤„ç†
- å•ä¸ªæ‰¹æ¬¡å¤±è´¥ä¸å½±å“å…¶ä»–æ‰¹æ¬¡
- è®°å½•è¯¦ç»†é”™è¯¯æ—¥å¿—ç”¨äºè°ƒè¯•
- æä¾›é™çº§åˆ°ä¸²è¡Œå¤„ç†çš„é€‰é¡¹

## ç›‘æ§æŒ‡æ ‡

```python
# æ·»åŠ æ€§èƒ½ç›‘æ§
import time
import asyncio

class PerformanceMonitor:
    def __init__(self):
        self.batch_times = []
        self.concurrent_batches = 0
        self.max_concurrent = 0

    async def measure_batch(self, batch_id: int, coro):
        start = time.time()
        result = await coro
        elapsed = time.time() - start

        self.batch_times.append(elapsed)
        self.concurrent_batches = max(self.concurrent_batches, asyncio.current_task().concurrency_level)

        print(f"[Perf] Batch {batch_id}: {elapsed:.2f}s (avg: {np.mean(self.batch_times):.2f}s)")
        return result
```

## ç»“è®º

**å¹¶å‘ä¸Šä¼ æ˜¯è§£å†³è¿™ä¸ªé—®é¢˜çš„æœ€ä½³æ–¹æ¡ˆ**ï¼ŒåŸå› ï¼š

1. âœ… **ç›´æ¥é’ˆå¯¹é—®é¢˜**ï¼šè§£å†³ä¸²è¡Œæ‰¹å¤„ç†çš„æ ¹æœ¬é—®é¢˜
2. âœ… **æ— å‰¯ä½œç”¨**ï¼šä¸å‹ç¼©å›¾ç‰‡ï¼Œä¸æ”¹å˜æ•°æ®æ ¼å¼
3. âœ… **æ¸è¿›å¼ä¼˜åŒ–**ï¼šå¯ä»¥ä»3å¹¶å‘å¼€å§‹ï¼Œé€æ­¥æå‡
4. âœ… **å…¼å®¹æ€§å¥½**ï¼šä¿æŒç°æœ‰APIè°ƒç”¨é€»è¾‘
5. âœ… **èµ„æºé«˜æ•ˆ**ï¼šå……åˆ†åˆ©ç”¨ç½‘ç»œå’ŒAPIå¹¶å‘èƒ½åŠ›

**æ¨èä¼˜å…ˆçº§**ï¼š
1. **ç«‹å³**ï¼šçº¿ç¨‹æ± å¹¶å‘ï¼ˆmax_workers=3ï¼‰
2. **çŸ­æœŸ**ï¼šasyncioå¹¶å‘ä¼˜åŒ–
3. **é•¿æœŸ**ï¼šæ··åˆç­–ç•¥ï¼ˆæ–‡ä»¶é¢„ä¸Šä¼  + å¹¶å‘ï¼‰
