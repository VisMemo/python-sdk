# 文本记忆统一接入方案

> 本文档定义对话/文本记忆如何统一接入 MOYAN TKG（时空知识图谱）底座，确保文本与视觉记忆在同一物理图中共存、互通，同时保持语义隔离与噪声控制。

---

## 1. 核心决策：单图架构 (Single Graph, Multiple Domains)

### 1.1 Linus 三问

| 问题 | 回答 |
|------|------|
| **这是个真问题吗？** | 是。决定"对话记忆"在整个记忆底座里的地位：是外挂缓存，还是 TKG 的一级公民。 |
| **有更简单的方法吗？** | 把对话丢进独立向量库能跑，但会否认 TKG 的设计初心和 LoCoMo 验证过的优势。 |
| **会破坏什么吗？** | 粗暴混合会污染现有测试和查询假设，需要清晰的隔离与抽象。 |

### 1.2 决策结论

**采用单图方案**：文本/对话记忆与视觉记忆共享同一个 TKG 物理底座。

**理由**：
1. **因果链完整性**：对话事件（"Bob 建议我去健身"）与物理事件（"去健身房"）通过 `TEMPORAL_NEXT` 串联，系统可回答"为什么去健身房？"
2. **基础设施复用**：`TimeSlice`、`TEMPORAL_NEXT`、`PARTICIPATED_IN` 等图结构可直接用于文本数据，无需重写时序推理引擎。
3. **LoCoMo 验证**：Benchmark 已证明图增强检索在 L2-L5 时序/多跳问题上的优势，文本数据同样适用。

**隔离策略**（避免"污染"）：
- **物理上**：同一张图。
- **逻辑上**：通过 `source`、`memory_domain`、`Edge Type` 做分层过滤。

---

## 2. Schema 扩展：文本记忆的节点与边

### 2.1 节点类型

在现有 TKG Schema 基础上，文本记忆引入以下节点类型：

| 节点类型 | kind | source | memory_domain | 说明 |
|----------|------|--------|---------------|------|
| **Session (TimeSlice)** | `timeslice` | `conversation` | `dialog` | 一次完整对话会话，提供时间边界 |
| **Fact (长期事实)** | `semantic` | `mem0` | `dialog` | 从对话中提炼的持久化知识 |
| **Preference (偏好)** | `semantic` | `mem0` | `dialog` | 用户表达的偏好/喜好 |
| **Task (待办)** | `semantic` | `mem0` | `dialog` | 对话中产生的计划/任务 |
| **Rule (规则)** | `semantic` | `mem0` | `dialog` | 用户设定的规则/原则 |
| **Summary (摘要)** | `episodic` | `conversation` | `dialog` | 对话会话的高层摘要 |

### 2.2 边类型

| 边类型 | 含义 | 来源 |
|--------|------|------|
| `TEMPORAL_NEXT` | 时序链：事件 A 之后发生事件 B | 会话内部时序 |
| `PARTICIPATED_IN` | 参与关系：Entity -> Event | Speaker 参与对话 |
| `CONTAINS` | 包含关系：TimeSlice -> Event/Fact | 会话包含事实 |
| `STATED_BY` | 陈述关系：Fact -> Entity | 谁说的这个事实 |
| `MENTIONS` | 提及关系：Event/Fact -> Concept | 提及的话题/关键词 |
| `DERIVED_FROM` | 来源关系：Fact -> Event | 事实从哪个原始事件提炼 |

### 2.3 与视觉节点的互操作

| 场景 | 视觉节点 | 文本节点 | 连接方式 |
|------|----------|----------|----------|
| 同一时间段 | `MediaSegment` | `Session` | 通过 `TimeSlice` 时间窗口重叠 |
| 同一参与者 | `Entity (Face)` | `Entity (Speaker)` | 通过 `character` 等价合并 |
| 关于同一地点 | `Location` | `Fact (mentions location)` | `MENTIONS` 边指向同一 `Concept` |

---

## 3. 身份唯一性：账号体系决定，LLM 不猜

### 3.1 核心原则

> **"唯一实体身份" = 账号层 identity（user_id / character），不是 LLM 猜出来的。**

### 3.2 身份层级

```
Account (user_id: "10086")
    └── Character (可选，如 "工作人格" / "家庭人格")
        └── Alias (文本中出现的称呼："我"、"张三"、"老板")
```

### 3.3 写入规则

1. **调用方决定主体**：HTTP 请求头 `X-User-ID` 或 `metadata.user_id` 必须由调用方提供。
2. **LLM 只负责内容抽取**：`fact_extractor` 从对话中抽取"事实"，但不决定"这是谁的记忆"。
3. **他人按 Mention 处理**：对话中提到的第三方（"张三"、"老婆"）暂不建 Entity，只作为文本保留在 `metadata.mentions` 中。

### 3.4 代码示例

```python
# 正确做法：身份由调用方提供
entry = MemoryEntry(
    kind="semantic",
    modality="text",
    contents=["用户偏好早上喝黑咖啡"],
    metadata={
        "user_id": request.headers["X-User-ID"],  # 来自账号体系
        "source": "mem0",
        "memory_domain": "dialog",
        "extracted_from": "session_12345",
    }
)

# 错误做法：让 LLM 猜
# entry.metadata["user_id"] = llm.infer("这是谁的记忆？")  # ❌ 幻觉风险
```

---

## 4. 写入管道：Session 后统一抽取 (Post-Session Extraction)

### 4.1 核心策略：奥卡姆剃刀

采用 **"会话后统一抽取"** 策略，放弃流式/实时抽取。

**理由**：
1. **原子性**：Session 结束时 LLM 拥有上帝视角，能产出最终结论（避免"决定A"->"改为B"的反复擦除）。
2. **经济性**：一次性抽取比每轮对话都抽节省大量 Token 和 Latency。
3. **整洁度**：这是防止"垃圾/过程数据"进图的最强防火墙。

### 4.2 架构流程图

```
┌─────────────────────────────────────────────────────────────────┐
│                        Live Session (进行中)                     │
│  - 所有 turns 积攒在 Hot Buffer (Redis)                          │
│  - 不碰图，不做抽取                                               │
└─────────────────────────────────────────────────────────────────┘
                                │
                                ▼ (Session 结束/归档)
┌─────────────────────────────────────────────────────────────────┐
│  LLM Extractor (上帝视角)                                       │
│  - 输入：完整 Session Dialog                                     │
│  - Prompt："阅读对话，提取最终事实/计划/偏好，忽略中间废弃方案。"      │
│  - 输出：                                                        │
│    • Facts (事实)                                                │
│    • Preferences (偏好)                                          │
│    • Tasks (待办)                                                │
│    • Rules (规则)                                                │
│    • Session Summary (摘要/Pre-context)                          │
└─────────────────────────────────────────────────────────────────┘
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│  Layer 2: 长期图谱 (TKG)                                         │
│  - 写入 TimeSlice (Session)                                      │
│  - 写入提取出的 Facts / Summary                                  │
│  - 建立关联：Fact -> DERIVED_FROM -> Session                     │
└─────────────────────────────────────────────────────────────────┘
```

### 4.3 关键场景：旧对话重开 (Session Resume)

当用户"过了很久把一段对话拿出来继续聊"时，必须处理好**重复写入**和**事实修正**问题。

#### 场景 1: 避免重复写入 (Double Counting)
*   **原则**：已归档的 Session 是 **Immutable History (不可变历史)**。
*   **做法**：
    *   加载上下文时：读取旧 Session 的 Raw Turns (或 Summary) 作为 `Context`。
    *   **抽取范围限制**：LLM 抽取时，显式以此 `Context` 为背景，**仅从 New Turns 中提取新事实**。

#### 场景 2: 事实修正与冲突 (Conflict Resolution)
*   **场景**：Session A 结论是"选红色"（已入图），Session B (Resume) 用户说"改成绿色"。
*   **做法**：**State Update (状态机更新)**。
    *   抽取指令要求 LLM 生成 **Diff 操作**：`DELETE Fact(红色)` + `ADD Fact(绿色)`。
    *   图谱层执行 Update 逻辑。

#### 场景 3: 上下文过长 (Context Pruning)
*   **做法**：
    *   当重开很久前的对话时，不加载原始千行对话。
    *   从 TKG 读取 `Session Summary` + `Entity Facts` 作为 **Pre-context** 塞入新 Session 开头。
    *   用户感觉在"接着聊"，Bot 读的是"精简笔记"。

### 4.4 抽取触发条件

| 触发条件 | 说明 |
|----------|------|
| **Session 结束** | 用户明确说"再见" / "End" |
| **Timeout 归档** | 用户 N 分钟未回复 (如 30min) -> 视为会话结束，触发自动抽取与归档 |
| **主动归档** | 客户端主动调用 `/session/archive` |

---

### 4.5 抽取规则与 Prompt 设计

> 目标：基于 **MOYAN 自己的 TKG 设计**，而不是简单复刻 mem0 的向量记忆提示词，定义一套专门面向 `Fact/Preference/Task/Rule` + `TimeSlice/DERIVED_FROM/STATED_BY` 的抽取规则与输出 Schema。

#### 4.5.1 为什么不是直接用 mem0 的 Prompt？

mem0 的抽取 Prompt 主要针对的是：

- 目标后端是“键值向量库 + 简单 metadata”的记忆系统；
- 粗粒度区分“短期/长期记忆”，以 `ADD/UPDATE/DELETE/NONE` 操作为主；
- 事实本身没有明确的 **时空锚点** 与 **图关系** 输出。

而 MOYAN 的设计要求更高：

- 抽取结果需要可以直接映射为 `MemoryEntry + Edge`，挂在统一 TKG 上；
- 必须显式包含：
  - `memory_domain`（如 `"dialog"`）与 `source`（如 `"mem0"`）；
  - 事实类型：`fact/preference/task/rule`；
  - 时间范围与生效条件（永久、直到被修改、仅本 Session 有效等）；
  - 溯源信息：来自哪一个 Session / 哪些 Turn；
  - 图关系意图：是否需要生成 `STATED_BY`、`DERIVED_FROM`、`CONTAINS` 等边。

因此，我们只借用 mem0 的 **操作思想**（ADD/UPDATE/DELETE/NONE + 冲突合并），但 Prompt 与输出 Schema 必须按 MOYAN 的图模型重写。

#### 4.5.2 抽取对象与规则（LLM 视角）

抽取时，LLM 只看“当前 Session 的完整对话 + 可选的旧记忆摘要”，遵循以下硬规则：

1. **身份不猜测**
   - 不允许推断 `user_id`、账号、角色 ID，这些由调用方在 metadata 中提供。
   - 只在文本中用自然语言称呼（例如“我”“用户”“你的小助手”）。

2. **只抽“对主体长期有用”的内容**
   - 抽取候选必须满足：在未来的对话中，有可能被问到 / 需要记住。
   - 丢弃：
     - 纯闲聊语句（“哈哈”“好的”）；
     - 与当前主体无关的第三方八卦；
     - 完全被后文否定 / 覆盖的中间状态。

3. **事实四类化：fact / preference / task / rule**
   - `fact`：关于主体的客观信息（职业、家庭、长期状态）；
   - `preference`：偏好/喜好（饮食/作息/沟通风格等）；
   - `task`：有明确目标的待办/计划（带状态：open/done/cancelled）；
   - `rule`：主体设定的规则/原则（例如“不在晚上 11 点后打电话给我”）。

4. **时间与生效范围**
   - 对每条抽出的 item，都需要标注：
     - `scope`: `"permanent" | "until_changed" | "temporary"`；
     - `valid_from` / `valid_to`（可为空）；  
   - 若文本出现明确“更改/撤销”，使用 `UPDATE/DELETE` 操作替换旧项，而不是新增一个相反事实。

5. **溯源与证据**
   - 每条 item 必须给出 `source_session_id` 与 `source_turn_ids`（列表），方便落地时生成 `DERIVED_FROM`、`CONTAINS` 边；
   - 允许简短的 `rationale`（一句话解释“为什么这么抽”），用于审计与调参。

6. **操作级别抽取（对照旧记忆）**
   - 若提供了 `existing_items`（旧记忆摘要），LLM 必须输出对比结果：
     - 对于不变项目 → 标记为 `"op": "KEEP"`（不落库）；
     - 对于被修改/推翻项目 → 输出 `"op": "UPDATE"` 或 `"DELETE"`；
     - 对于新增项目 → 输出 `"op": "ADD"`。

#### 4.5.3 输出 Schema（供 MemoryEntry/Edge 映射）

抽取 Prompt 的输出统一为一个 JSON 对象，便于直接映射到 `MemoryEntry + Edge`：

```json
{
  "facts": [
    {
      "op": "ADD | UPDATE | DELETE | KEEP",
      "id": "optional_old_fact_id",
      "type": "fact | preference | task | rule",
      "title": "简短标题，便于人类/工具浏览",
      "statement": "适合作为 MemoryEntry.contents[0] 的自然语言描述",
      "status": "open | done | cancelled | n/a",
      "scope": "permanent | until_changed | temporary",
      "valid_from": "optional ISO datetime",
      "valid_to": "optional ISO datetime",
      "importance": "low | medium | high",
      "source_session_id": "session_123",
      "source_turn_ids": [3, 4],
      "rationale": "简要解释这一条是如何从对话中得出的"
    }
  ]
}
```

落库时的映射约定（示意）：

- `statement` → `MemoryEntry.contents[0]`；
- `type` → `MemoryEntry.metadata.type`（`fact/preference/task/rule`）；
- `status/scope/importance` → `MemoryEntry.metadata.*` 与 TTL 策略；
- `source_session_id/source_turn_ids` → `MemoryEntry.metadata.extracted_from`，并生成：
  - `DERIVED_FROM`：Fact → Session/TimeSlice；
  - `CONTAINS`：Session/TimeSlice → 原始对话 Event；
  - `STATED_BY`：Fact → 主体 Entity（由 `user_id` 决定）。

#### 4.5.4 抽取 Prompt 草案（示例）

> 下列示例仅用于文档说明，实际实现可拆分为 system + user 多段，并根据测试迭代。

```text
你是一个"对话记忆抽取器"，负责从用户与助手的完整对话 Session 中，
为一个已经存在的长期记忆系统抽取结构化的记忆条目。

重要原则：
- 不要猜测用户身份或账号ID，这些由系统提供。
- 只抽取对未来仍然有用的内容，忽略纯闲聊。
- 将内容归类为四种类型之一：fact / preference / task / rule。
- 如果提供了旧记忆摘要(existing_items)，需要输出对比后的操作：
  - ADD: 新增的记忆；
  - UPDATE: 旧记忆被更改（例如用户改主意）；
  - DELETE: 旧记忆被明确否定；
  - KEEP: 旧记忆仍然有效（可以省略不返回）。

你的输出必须是一个 JSON，对应下面的 Schema：
{
  "facts": [
    {
      "op": "ADD | UPDATE | DELETE | KEEP",
      "id": "optional_old_fact_id",
      "type": "fact | preference | task | rule",
      "title": "...",
      "statement": "...",
      "status": "open | done | cancelled | n/a",
      "scope": "permanent | until_changed | temporary",
      "valid_from": "ISO-8601 或 null",
      "valid_to": "ISO-8601 或 null",
      "importance": "low | medium | high",
      "source_session_id": "session_123",
      "source_turn_ids": [3, 4],
      "rationale": "..."
    }
  ]
}

现在我会给你：
1) 当前 Session 的完整对话转写(transcript)，包含轮次编号；
2) 可选的 existing_items（来自该用户的旧记忆摘要）。

请严格按照上述 Schema 输出 JSON，不要添加任何额外说明文字。
```

> 说明：  
> - mem0 既有的 Prompt 可以作为参考样本，但最终以本节 Schema 为准；  
> - 后续在 `application/fact_extractor_mem0.py` 中实现时，应将该 Prompt 拆分为可配置模板，并通过测试逐步收紧输出格式。

---

## 5. 读取策略：三路召回

### 5.1 召回路径总览

| 路径 | 场景 | 实现方式 | 内核接口 |
|------|------|----------|----------|
| **A. 通用 QA** | "我之前说过什么计划？" | Planner LLM + memory.* 工具 | `/search` + 图扩展 |
| **B. 结构化 Profile** | "列出用户偏好" | 专用视图接口 | 图查询 + 规则聚合 |
| **C. 最近上下文** | "延续当前对话" | 短期缓存直取 | Redis / Context Window |

### 5.2 路径 A：通用 QA（Agent 驱动）

```
用户问题
    │
    ▼
┌─────────────────────────────────────────┐
│  Planner LLM (Agent)                    │
│  - 选择工具：memory.search_basic /      │
│    memory.search_temporal /             │
│    memory.get_timeline                  │
│  - 生成参数：query, filters, time_hint  │
└─────────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────────┐
│  Memory Tool Layer                       │
│  - 内部调用 MemoryService.search        │
│  - 应用 filters: memory_domain="dialog" │
│  - 启用 expand_graph=True               │
└─────────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────────┐
│  MemoryService.search (内核)            │
│  - 向量检索 (Qdrant)                    │
│  - 图扩展 (Neo4j)                       │
│  - Rerank (时间新鲜度 + 重要性)         │
└─────────────────────────────────────────┘
    │
    ▼
Evidence → QA LLM → 答案
```

### 5.3 路径 B：结构化 Profile 视图

新增接口：`MemoryService.build_user_view(user_id, domain_scope)`

```python
@dataclass
class UserMemoryView:
    """对 Agent 友好的结构化记忆视图"""
    identity: UserIdentity
    preferences: List[Preference]
    habits: List[Habit]
    open_tasks: List[Task]
    rules: List[Rule]
    recent_facts: List[Fact]

def build_user_view(
    user_id: str,
    domain_scope: List[str] = ["dialog", "lifelog"],
    time_range: Optional[Tuple[float, float]] = None,
) -> UserMemoryView:
    """
    从图中构建用户记忆视图。
    
    实现逻辑：
    1. 搜索：按 user_id + memory_domain 过滤 MemoryEntry
    2. 分类：根据 kind + metadata.type 归类
    3. 去重：对同类事实做合并（mem0 的 ADD/UPDATE 逻辑）
    4. 输出：结构化 JSON，LLM 只需阅读，不需搜索
    """
    ...
```

### 5.4 路径 C：最近上下文

**不经过 TKG**，直接从对话系统的短期缓存读取：

```python
def get_recent_context(session_id: str, n_turns: int = 10) -> List[Turn]:
    """从 Redis/内存获取最近 N 轮对话"""
    return redis.lrange(f"dialog:{session_id}", -n_turns, -1)
```

---

## 6. Source 与 Domain 的隔离设计

### 6.1 字段定义

| 字段 | 含义 | 示例值 |
|------|------|--------|
| `source` | 数据来源系统 | `m3`, `mem0`, `conversation`, `manual` |
| `memory_domain` | 记忆归属领域 | `lifelog`, `dialog`, `device`, `work` |

### 6.2 典型组合

| source | memory_domain | 节点类型 | 说明 |
|--------|---------------|----------|------|
| `m3` | `lifelog` | Event/Segment | 视频分析产生的物理事件 |
| `conversation` | `dialog` | Session/Summary | 原始对话会话和摘要 |
| `mem0` | `dialog` | Fact/Preference/Task | 从对话抽取的长期知识 |
| `mem0` | `lifelog` | Fact | 从视觉事件抽取的知识 |

### 6.3 边类型隔离

| 边类型 | 来源 | 用途 |
|--------|------|------|
| `OBSERVED_AT` | 视觉系统 | 视觉观测的时空关系 |
| `STATED_BY` | 文本系统 | 对话中的陈述关系 |
| `TEMPORAL_NEXT` | 通用 | 时序链（两个系统共享） |

**查询隔离示例**：

```cypher
-- 只查视觉记忆
MATCH (e:Event)-[:OBSERVED_AT]->(l:Location)
WHERE e.source = "m3" AND e.memory_domain = "lifelog"
RETURN e, l

-- 只查对话记忆
MATCH (f:Fact)-[:STATED_BY]->(u:Entity)
WHERE f.source = "mem0" AND f.memory_domain = "dialog"
RETURN f, u

-- 联合查询（跨模态）
MATCH (e1)-[:TEMPORAL_NEXT*1..3]->(e2)
WHERE e1.memory_domain IN ["lifelog", "dialog"]
RETURN e1, e2
```

---

## 7. 实现检查清单

### Phase 1: Schema 定义与写入管道

- [ ] 在 `contracts/graph_models.py` 中扩展 `source` 和 `memory_domain` 枚举
- [ ] 在 `application/fact_extractor_mem0.py` 中实现对话事实抽取
- [ ] 定义 `DialogSession` -> `TimeSlice` 的映射逻辑
- [ ] 实现 `Fact/Preference/Task/Rule` 节点的写入 API

### Phase 2: 读取接口

- [ ] 实现 `MemoryService.build_user_view()` 结构化视图接口
- [ ] 在 `/search` 中支持 `memory_domain` 过滤
- [ ] 为 Agent 暴露 `memory.get_profile` / `memory.get_open_tasks` 工具

### Phase 3: 测试与验证

- [ ] 创建 `tests/unit/test_dialog_memory_pipeline.py`
- [ ] 在 `benchmark/` 中增加对话记忆场景的评测用例
- [ ] 验证视觉+文本联合查询的正确性

---

## 9. 接口与 SDK 规范 (对外入口)

> 目标：面向外部开发者提供极简且稳定的 SDK 接口，封装底层的 TKG 抽取细节。开发者只需在"会话结束"时提交完整对话，服务端负责异步清洗与入图。

### 9.1 设计原则

1. **黑盒交付**：开发者只需关注 `user_id` / `session_id` / `turns[]`；不需要了解 Neo4j, Qdrant, MemoryEntry 等内部概念。
2. **Post-Session 模式**：仅提供 Session 级别的归档接口，不支持流式单句写入。
3. **默认异步**：采用 Fire-and-Forget 模式（`sync=false`），返回 `job_id`，避免 LLM 抽取阻塞主业务线程。
4. **幂等性**：`session_id` 必须作为全系统唯一的去重键（绑定到 `run_id`）。同一 session_id 的重复请求将被视为更新操作或直接忽略（取决于参数），严禁重复写入Fact。

### 9.2 HTTP 接口设计 (服务端)

**入口**：`POST /dialog/v1/archive_session`

**请求体**：
```json
{
  "user_id": "user_123",           // 必填：主权所属ID
  "session_id": "chat_abc_001",    // 必填：会话ID，作为幂等键
  "memory_domain": "dialog",       // 可选，默认 "dialog"
  "turns": [
    {
      "turn_id": 1,
      "role": "user",
      "text": "我早上喜欢喝黑咖啡。",
      "timestamp": 1709459200.0,
      "metadata": { "channel": "web" }
    },
    {
      "turn_id": 2,
      "role": "assistant",
      "text": "好的，我会记住。",
      "timestamp": 1709459210.0,
      "metadata": {}
    }
  ],
  "options": {
    "sync": false,              // 默认 false：仅排队，快速返回
    "max_items": 20,            // 抽取数量上限保护
    "overwrite_existing": true  // true=重新抽取并Diff更新; false=若已存在则跳过
  }
}
```

**响应 (Async)**：
```json
{
  "session_id": "chat_abc_001",
  "status": "accepted",
  "job_id": "job_789_uuid"
}
```

**响应 (Sync)** (仅供调试/同步调用)：
```json
{
  "session_id": "chat_abc_001",
  "status": "completed",
  "extracted": {
    "facts": [
      { "type": "preference", "statement": "用户喜欢黑咖啡", ... }
    ]
  }
}
```

### 9.3 SDK 接口形态 (客户端)

提供 Python / TS 版本 SDK，核心只暴露一个 Client 和 `archive_session` 方法。

**Python SDK (`moyan-text-memory`)**:

```python
from moyan_text_memory import TextMemoryClient, Turn

client = TextMemoryClient(
    base_url="https://memory.moyan.ai",
    api_key="sk-...",
)

turns = [
    Turn(role="user", text="我早上喜欢喝黑咖啡。", timestamp=1709459200.0),
    Turn(role="assistant", text="好的，我会记住。", timestamp=1709459210.0),
]

# 会话结束时调用
client.archive_session(
    user_id="user_123",
    session_id="chat_abc_001",
    turns=turns,
    sync=False
)
```

### 9.4 内部实现链路

1. **接收**：API Gateway 收到请求，校验 `api_key` 与 Schema。
2. **去重**：检查 `session_id` 是否已在 `audit_store` 中存在。
3. **抽取**：
   - 组装 Prompt（见 4.5 节）；
   - 调用 LLM 服务，传入完整 turns；
   - 接收结构化 JSON。
4. **入图**：
   - 开启 Graph 事务；
   - 写入/更新 `TimeSlice` (Session)；
   - 根据 JSON 执行 `ADD/UPDATE/DELETE` Fact 节点；
   - 建立 `Fact -> DERIVED_FROM -> Session` 边；
   - (可选) 写入 Redis/VectorDB 以便快速回溯。
5. **回调/完成**：更新 Job 状态。

---

## 10. 版本记录

| 版本 | 日期 | 变更内容 |
|------|------|----------|
| v0.1 | 2025-12-05 | 初稿：确立单图架构、双层写入、三路召回 |
| v0.2 | 2025-12-05 | 新增：Post-Session 抽取管道、Resume 逻辑、抽取 Prompt Schema、SDK 规范 |
