# 对话会话三段式写入管线（V0）施工规范
（启发式去噪 → LLM 价值标注（原文无损）→ 抽取建图写入）

> 目标：把“开发者/Agent 框架导出的上下文”转化为**可预测、可回归、可审计**的记忆写入流水线。  
> 核心原则：**过滤可以有损，但凡被保留的原话必须无损**（逐字不改 + 可追溯到 turn + 可校验）。

---

## 0. 一句话总览

我们把“写入对话记忆”拆成三段：

1) **Stage 1 — 规则化去噪（Deterministic, No-LLM）**  
   把各种输入（OpenAI messages / AI Studio 导出文本 / agent trace / 开发者自定义）统一归一成 `turns[]`，并做结构性去噪（去掉明显无意义的 debug 垃圾、截断超长工具输出并留下引用）。

2) **Stage 2 — 价值标注（LLM, Lossless retention）**  
   LLM 不负责“改写/总结”，只负责：  
   - 选择哪些 turn（或 turn 的片段 span）值得进入记忆系统；  
   - 给这些“保留的原文片段”打上**重要性/TTL/遗忘策略/可信度/类别**等标签；  
   - 输出必须能被程序校验（`span.text_exact == turn.text[start:end]`）。

3) **Stage 3 — 抽取建图写入（LLM + 现有 TKG pipeline）**  
   仅对 Stage 2 选出的“干净且有价值”的 turns 做知识抽取与建图，并写入：
   - TKG 图（Neo4j）  
   - 向量索引（Qdrant：utterance index + fact index）  
   - 同时把 Stage 2 的 TTL/重要性等治理标签无损透传到写入 metadata。

---

## 1. 设计边界（必须写死的产品语义）

### 1.1 我们要解决的真问题

- 开发者的“上下文”格式高度不统一：有的只有 `messages[]`，有的是 agent trace，有的是 AI Studio 导出（含 run settings/parts/tokenCount）。  
- 如果把“全上下文 JSON 原样喂 LLM 抽取”，会出现 token 爆炸、噪声污染、不可回归、串号与泄露风险。  
- 我们必须用**确定性结构化**先把输入变成可控的数据结构（turns），再做“价值判断”，最后才做建图。

### 1.2 非目标（本规范不做）

- 不在 Stage 1/2 做跨会话的实体全局对齐（Identity Resolution）。  
- 不在 Stage 2 直接生成 TKG 节点/边（它只打标签与做筛选）。  
- 不做“自动猜输入格式并路由”：必须由调用方显式指定 `input_format`，否则宁可报错。

---

## 2. 核心数据结构（Schema）

> 约束：所有字段命名与含义必须稳定；实现语言可自由（dataclass/pydantic/ts interface），但 JSON 结构必须一致。

### 2.1 CanonicalTurn（Stage 1 输出、Stage 2 输入）

```json
{
  "turn_id": "t0001",
  "role": "user|assistant|tool|system",
  "speaker": "Alice|MOYAN|tool:web_search|system",
  "timestamp_iso": "2025-12-21T10:00:00Z",
  "text": "原文文本（UTF-8）",
  "source_ref": {
    "input_format": "openai_messages_v1|ai_studio_export_text_v1|agent_trace_v1|canonical_turns_v1",
    "raw_index": 12,
    "raw_path": "chunkedPrompt.chunks[12].parts[3]"
  },
  "attachments": [
    {
      "type": "tool_result|file|image_ref",
      "name": "web_search",
      "truncated": true,
      "sha256": "…",
      "ref": "blob://…"
    }
  ]
}
```

**硬约束：**
- `turn_id` 必须稳定且可排序（推荐固定宽度序号）。
- `text` 必须是原文（Stage 1 不允许“改写/润色”）。
- `role` 必须是枚举，且可映射到 `session_write` 的 `role/speaker`。

### 2.2 ValueTag（Stage 2 输出：对“原文片段”的标签）

Stage 2 的输出不是“总结”，而是**对原文片段的选择与标注**：

```json
{
  "tag_id": "m0001",
  "turn_id": "t0007",
  "span": { "start": 0, "end": 42, "text_exact": "逐字原文子串（必须完全一致）" },

  "category": "fact|preference|task|rule",
  "subtype": "profile|constraint|commitment|decision|tool_grounded_fact|…",
  "subject": "u:{user_id}|p:{product_id}|pub",

  "evidence_level": "S0_user_claim|S1_ai_inference|S2_tool_grounded|S3_user_confirmed",
  "requires_confirmation": true,

  "importance": 0.0,
  "ttl_seconds": 0,
  "forget_policy": "permanent|until_changed|temporary",

  "write_action": "write_fact|write_task|write_rule|write_preference|archive_only|drop",
  "reason": "一句话说明为什么值得记/为什么只归档/为什么不写",

  "hints": {
    "entity_names": ["张三", "Caroline"],
    "time_hint": "next Friday|2025-12-24",
    "dedup_key": "可选：用于同类记忆去重/覆盖"
  }
}
```

**硬约束：**
- `span.text_exact` 必须等于 `turn.text[span.start:span.end]`；不满足则判定 Stage 2 输出无效，必须重跑/降级。
- `importance` 使用 `0.0~1.0` 的连续值（而不是 low/medium/high），便于后续统一排序与阈值决策。
- `ttl_seconds`：`0` 表示长期（由治理系统决定是否永久），`>0` 表示过期秒数。
- `write_action=drop` 的 tag 不允许出现在输出（drop 只作为 turn 级别标记），避免自相矛盾。

### 2.3 ValueTaggingOutput（Stage 2 总输出）

```json
{
  "version": "value_tagging_v1",
  "session_id": "sess_...",
  "kept_turn_ids": ["t0002", "t0007", "t0011"],
  "dropped_turn_ids": ["t0001", "t0003"],
  "tags": [ /* ValueTag[] */ ],
  "stats": {
    "input_turns": 120,
    "kept_turns": 35,
    "dropped_turns": 85,
    "tag_count": 18
  }
}
```

---

## 3. Stage 1：规则化去噪（启发式脚本，确定性）

### 3.1 责任与原则

Stage 1 只做三件事：
- **解析（Parse）**：把输入解析成可遍历结构（允许“非严格 JSON”按文本兜底）。
- **归一（Normalize）**：统一生成 `CanonicalTurn[]`。
- **结构去噪（Denoise）**：去掉明显无意义/不可用的噪声 turn，或将其标记为 `drop_candidate`。

> Stage 1 不做语义判断：不判断“值不值得记”；它只做“格式清洗 + 明显垃圾去除”。

### 3.2 输入格式（必须显式指定）

建议固定枚举：

- `canonical_turns_v1`：开发者直接提供 `turns[]`（推荐、最稳定）
- `openai_messages_v1`：`[{role, content, tool_calls?}]`
- `ai_studio_export_text_v1`：Google AI Studio 导出的“类 JSON 文本”（可能有尾逗号/非严格 JSON）
- `agent_trace_v1`：框架 trace（必须由你们提供官方 adapter；不接受开发者随意拼字段）

**禁止**：不带 `input_format` 的自动识别（会产生 silent corruption）。

### 3.3 结构去噪的最低规则（建议默认开启）

1) **空文本 drop**：`text.strip()==""` 直接丢弃  
2) **纯 token/统计信息 drop**：如仅包含 `tokenCount/finishReason` 这类元字段  
3) **超长工具输出处理**：超过阈值（如 8k 字符）的 tool result：
   - `turn.text` 截断为前 N 字符 + `…[TRUNCATED]`
   - 计算 `sha256`，把完整内容写入外部 blob（或文件）并在 `attachments[].ref` 引用
   - 标记 `attachments[].truncated=true`

> 注意：截断不会破坏“原文无损”要求，因为 Stage 2 只允许选择 `text_exact` 与 `turn.text` 一致的片段。若要对截断内容做无损引用，必须走 `attachments.ref` 体系（未来扩展）。

### 3.4 输出验收（必须有）

Stage 1 输出 `CanonicalTurn[]` 后必须通过：
- role 合法性检查（只允许枚举值）
- `turn_id` 唯一性
- `text` 非空比例（否则直接报错：输入不含有效内容）

---

## 4. Stage 2：价值标注（LLM，保留原文无损）

### 4.1 责任与硬约束

Stage 2 的 LLM 只做“筛选 + 标注”，严禁做“改写/总结/合并原文”：

- 允许丢弃噪声 turn（减少写入污染）
- 允许从一个 turn 中选择一段 `span`
- **但凡选择出来的 span，必须逐字来自 turn**

### 4.2 “值得记”的最小公共语义（给 LLM 的价值引导）

默认只把以下内容标为可写入（write_*），其余一律 `archive_only` 或 drop：

1) **用户稳定信息**：偏好、禁忌、身份、长期项目背景（S0/S3）
2) **任务/承诺**：用户要求/AI承诺、截止时间、状态（S0/S3）
3) **决定与结果**：最终选择、确认结论（S3 或 S2）
4) **工具证据事实**：明确来自 tool 结果的事实（S2）

**默认不写入（污染源）**：
- AI 自己生成的常识复述、建议性文字、推测性结论（S1）
- 任何没有工具证据且没有用户确认的“事实”

### 4.3 TTL / 遗忘策略（建议默认表）

> 这是产品策略，不是模型自由发挥；必须写成表并在 prompt 中硬编码。

| category | 默认 forget_policy | ttl_seconds（建议） | 说明 |
|---|---|---:|---|
| preference | until_changed | 0 | 直到用户改变 |
| rule | permanent | 0 | 用户明确规则/边界 |
| task(open) | temporary | 30d | 未完成任务默认保留 30 天 |
| task(done) | temporary | 7d | 完成后保留一周用于解释 |
| fact(user claim) | temporary | 180d | 用户陈述事实，默认半年（可被覆盖） |
| fact(tool grounded) | permanent | 0 | 有证据的事实长期保留 |
| ai_output(no evidence) | archive_only | 1d | AI 输出默认只短期归档 |

> 注意：`ttl_seconds=0` 表示长期；并不等价“永不删除”，实际回收由治理层最终决定。

### 4.4 输出必须可校验（程序化验收）

Stage 2 输出后，程序必须逐条校验：
- `span.text_exact` 是否为原文子串
- `turn_id` 是否存在于输入 turns
- `kept_turn_ids` 是否覆盖所有 tag 的 `turn_id`
- `ttl_seconds` 合法（>=0）
- `importance` 合法（0..1）

校验失败时：
- **第一优先**：把失败原因（哪条 tag、期望子串、实际子串）回传给 LLM 让其修正（retry 1 次）
- retry 仍失败：整段 Stage 2 降级为 `archive_only`（只保留原始 turns，且 TTL 短），不进入 Stage 3 建图

---

## 5. Stage 3：抽取建图写入（对齐现有 TKG pipeline）

### 5.1 输入

Stage 3 的输入由两部分组成：
- `turns_kept[]`：由 Stage 2 的 `kept_turn_ids` 从 Stage 1 turns 中筛出来（文本原文）
- `tags[]`：Stage 2 的治理标签（importance/ttl/证据等级/类别）

### 5.2 写入策略（必须写死）

1) **utterance index（向量）**  
   - 只写 `turns_kept[]`（避免噪声进入向量召回漏斗）  
   - 每条 entry metadata 必须携带 `turn_id/role/speaker/session_id` 以便溯源

2) **knowledge/fact index（向量）**  
   - 来自现有知识抽取器（TKG knowledge extractor）的 `statement`  
   - 同时把 Stage 2 的治理信息合并到 metadata（至少：`importance/ttl_seconds/evidence_level/requires_confirmation`）

3) **TKG 图（Neo4j）**  
   - Event：按 kept turn 建 Event（或按现有 pipeline：UtteranceEvidence + Event）  
   - Knowledge：抽取的知识节点  
   - 边：必须能回指到 `source_turn_ids`（证据链可审计）

### 5.3 治理标签如何落库（无损透传）

至少保证：
- 每个写入的 Knowledge/Fact entry：带 `ttl_seconds/importance/evidence_level/requires_confirmation`
- 每个 Knowledge 节点：带同样字段（或在图节点 properties 中）
- 若一个 Knowledge 由多个 tag 触发，合并规则必须确定性（建议：importance 取 max，ttl_seconds 取 max 或按更严格策略取 min，并写入 `ttl_policy` 说明）

---

## 6. 工程化落地建议（按优先级）

### P0（必须）
- Stage 1：实现至少 2 种输入 adapter：`canonical_turns_v1` + `openai_messages_v1`
- Stage 2：实现 value tagging 的 JSON schema + 校验器（不通过就降级）
- Stage 3：在现有 `session_write` 前插入 `turns_kept` 过滤（只对保留 turns 建 index/建图）

### P1（强烈建议）
- 为 `ai_studio_export_text_v1` 提供 adapter（文本解析 + parts 拼接）
- tool 输出的外部 blob 引用（避免截断导致信息丢失）
- 增加“待确认记忆”的产品闭环（requires_confirmation=true 的候选不直接写长期知识）

---

## 7. 与现有 API 的对齐点

- `memory.session_write(...)`：本规范可作为它的“前置管线”（Stage 1/2），Stage 3 复用现有抽取与写入能力。  
- LoCoMo/benchmark：可在评测模式关闭 Stage 1/2（等价全量 turns），保证可比性。

