# ğŸ“˜ æ¨¡å—ä¸€ï¼šé—®é¢˜å®šä¹‰ä¸ç†è®ºä½“ç³»

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv1.0  
**æ’°å†™æ—¥æœŸ**ï¼š2024å¹´  
**æ ¸å¿ƒå®šä½**ï¼šå»ºç«‹æ—¶ç©ºçŸ¥è¯†è®°å¿†ç³»ç»Ÿçš„å“²å­¦æ ¹åŸºä¸æ•°å­¦æ¡†æ¶

---

## 1.1 æ ¸å¿ƒé—®é¢˜ç©ºé—´ç•Œå®š

### 1.1.1 èŒƒå¼è½¬æ¢çš„æœ¬è´¨çŸ›ç›¾

æˆ‘ä»¬ä»è¿ç»­æ„ŸçŸ¥æµï¼ˆè§†é¢‘åƒç´ ã€éŸ³é¢‘æ³¢å½¢ï¼‰æ„å»ºç¦»æ•£è®°å¿†ç»“æ„æ—¶ï¼Œé¢ä¸´çš„æ ¹æœ¬çŸ›ç›¾æ˜¯ï¼š

> **æ— é™ç»†åˆ†çš„æ—¶ç©ºè¿ç»­æ€§** ä¸ **æœ‰é™ç¬¦å·ç³»ç»Ÿç¦»æ•£æ€§** ä¹‹é—´çš„ä¸å¯é€šçº¦æ€§

è¿™å¯¼è‡´ä¸‰å¤§æ ¸å¿ƒé—®é¢˜ï¼š
- **åˆ‡å‰²é—®é¢˜**ï¼šåœ¨ä½•å¤„åˆ‡å‰²æ—¶ç©ºæµï¼Ÿï¼ˆäº‹ä»¶è¾¹ç•Œåˆ¤å®šï¼‰
- **æŠ½è±¡é—®é¢˜**ï¼šä¿ç•™ä»€ä¹ˆï¼Ÿä¸¢å¼ƒä»€ä¹ˆï¼Ÿï¼ˆä¿¡æ¯ä»·å€¼åº¦é‡ï¼‰
- **å…³è”é—®é¢˜**ï¼šå¦‚ä½•è®©ç¦»æ•£ç¬¦å·é‡ç°è¿ç»­å› æœï¼Ÿï¼ˆå…³ç³»é‡å»ºï¼‰

### 1.1.2 é—®é¢˜å½¢å¼åŒ–å®šä¹‰

ç»™å®šè§‚æµ‹åºåˆ— **O** = {oâ‚, oâ‚‚, ..., oâ‚™}ï¼Œå…¶ä¸­æ¯ä¸ª oáµ¢ æ˜¯æ—¶åˆ» táµ¢ çš„å¤šæ¨¡æ€æ•°æ®ï¼ˆè§†é¢‘å¸§ã€éŸ³é¢‘ã€ä¼ æ„Ÿå™¨ï¼‰ï¼Œç›®æ ‡æ˜¯æ„å»ºæ˜ å°„å‡½æ•°ï¼š

```
Î¦: O â†’ G(V, E, T, S)
```

å…¶ä¸­ï¼š
- **V**ï¼šå®ä½“èŠ‚ç‚¹é›†ï¼ˆå¯¹è±¡ã€äº‹ä»¶ã€çŠ¶æ€ï¼‰
- **E**ï¼šå…³ç³»è¾¹é›†ï¼ˆç©ºé—´ã€å› æœã€æ—¶åºï¼‰
- **T**ï¼šæ—¶é—´æ ‡ç­¾å‡½æ•° VâˆªE â†’ â„™(â„) ï¼ˆæ—¶é—´ç‚¹æˆ–åŒºé—´ï¼‰
- **S**ï¼šç©ºé—´æ ‡ç­¾å‡½æ•° V â†’ â„™(â„Â³) ï¼ˆä¸‰ç»´åŒºåŸŸï¼‰

**ä¼˜åŒ–ç›®æ ‡**ï¼š
```
min |I(O) - I(G)|  (ä¿¡æ¯æŸå¤±)
min BuildCost(G)    (æ„å»ºæˆæœ¬)
min QueryLatency(G) (æ£€ç´¢å»¶è¿Ÿ)
```

---

## 1.2 æ—¶ç©ºçŸ¥è¯†å›¾è°±çš„æœ¬ä½“è®º

### 1.2.1 å››ç»´è¶…å›¾æ¨¡å‹

æˆ‘ä»¬æå‡º **æ—¶ç©ºè¶…å›¾ï¼ˆSpatio-Temporal Hypergraph, STHï¼‰** ä½œä¸ºåŸºç¡€æ•°å­¦ç»“æ„ï¼š

```
STH = (V, H, Ï„, Ïƒ, Î»)
```

- **V**ï¼šä¼ ç»ŸèŠ‚ç‚¹ï¼ˆå®ä½“ã€äº‹ä»¶ï¼‰
- **H**ï¼šè¶…è¾¹ï¼ˆè¿æ¥å¤šä¸ªèŠ‚ç‚¹çš„nå…ƒå…³ç³»ï¼‰
- **Ï„: VâˆªH â†’ Interval(â„)**ï¼šæ—¶é—´åŒºé—´æ˜ å°„
- **Ïƒ: V â†’ Region(â„Â³)**ï¼šç©ºé—´åŒºåŸŸæ˜ å°„
- **Î»: VâˆªH â†’ Î£***ï¼šè¯­ä¹‰æ ‡ç­¾ï¼ˆæ¥è‡ªæœ¬ä½“åº“ï¼‰

**å…³é”®åˆ›æ–°**ï¼š**æ—¶é—´æœ¬èº«ä½œä¸ºå®ä½“**ï¼ˆTimeSliceï¼‰ï¼Œè€Œéä»…ä½œä¸ºå±æ€§ï¼Œä½¿å¾—"æ—¶é—´æ®µ"å¯å‚ä¸å…³ç³»ã€æ‹¥æœ‰å±æ€§ã€è¢«æ£€ç´¢ã€‚

### 1.2.2 æ—¶ç©ºåŸè¯­åˆ†ç±»

| åŸè¯­ç±»å‹ | ç¤ºä¾‹ | æ—¶é—´ç‰¹æ€§ | ç©ºé—´ç‰¹æ€§ | å¯å˜æ€§ |
|---------|------|---------|---------|--------|
| **é™æ€å®ä½“** | å»ºç­‘ã€å®¶å…· | æŒç»­å­˜åœ¨ | å›ºå®šåæ ‡ | ä¸å¯å˜ |
| **åŠ¨æ€å¯¹è±¡** | äººã€è½¦è¾† | å­˜åœ¨åŒºé—´ | è½¨è¿¹ | ä½ç½®å¯å˜ |
| **åŸå­äº‹ä»¶** | åä¸‹ã€æ‹¿èµ· | ç¬æ—¶ç‚¹ | å‘ç”ŸåŒºåŸŸ | ä¸€æ¬¡æ€§ |
| **æŒç»­è¿‡ç¨‹** | ä¼šè®®ã€ä¸‹é›¨ | æ—¶é—´åŒºé—´ | å½±å“åŒºåŸŸ | å¯å»¶ç»­ |
| **çŠ¶æ€å˜åŒ–** | ç¯å¼€â†’å…³ | çŠ¶æ€è½¬ç§»ç‚¹ | ä½œç”¨å¯¹è±¡ | ä¸å¯é€† |
| **æ—¶ç©ºåŒºåŸŸ** | 2024-Q1-å®¢å… | åŒºé—´ | ç«‹ä½“åŒºåŸŸ | ç»„åˆå®šä¹‰ |

---

## 1.3 ä¿¡æ¯æŸå¤±åº¦é‡ç†è®º

### 1.3.1 åŒæŒ‡æ ‡è¯„ä¼°æ¡†æ¶

æˆ‘ä»¬æå‡º **ã€Œæ—¶ç©ºä¿çœŸåº¦ã€** ä¸  **ã€Œå› æœå®Œæ•´æ€§ã€**  ä½œä¸ºæ ¸å¿ƒåº¦é‡ï¼š

#### **æŒ‡æ ‡ä¸€ï¼šæ—¶ç©ºä¿çœŸåº¦ï¼ˆSpatio-Temporal Fidelity, STFï¼‰**

```
STF(G|O) = Î± Â· SpatialAccuracy + Î² Â· TemporalAccuracy + Î³ Â· SemanticCompleteness
```

å…¶ä¸­ï¼š
- **ç©ºé—´ç²¾åº¦**ï¼šé‡å»ºè½¨è¿¹ä¸çœŸå®è½¨è¿¹çš„IoUå‡å€¼
  ```
  SpatialAccuracy = 1/N âˆ‘ IoU(Ïƒ_G(v), Ïƒ_O(v))
  ```
- **æ—¶é—´ç²¾åº¦**ï¼šåŒºé—´é‡å ç‡
  ```
  TemporalAccuracy = 1/N âˆ‘ overlap(Ï„_G(e), Ï„_O(e))
  ```
- **è¯­ä¹‰å®Œæ•´åº¦**ï¼šå…³é”®å®ä½“å¬å›ç‡
  ```
  SemanticCompleteness = |V_groundtruth âˆ© V_extracted| / |V_groundtruth|
  ```

æƒé‡æ»¡è¶³ï¼šÎ± + Î² + Î³ = 1ï¼Œæ ¹æ®åº”ç”¨åœºæ™¯è°ƒæ•´ï¼ˆå¦‚è½¨è¿¹è¿½è¸ªåœºæ™¯Î±>Î²ï¼‰ã€‚

#### **æŒ‡æ ‡äºŒï¼šå› æœå®Œæ•´æ€§ï¼ˆCausal Integrity, CIï¼‰**

æµ‹é‡å› æœé“¾çš„ä¿æŒç¨‹åº¦ï¼š

```
CI(G|O) = 1 - (MissingCauses + FalseCauses) / TotalGroundtruthCauses
```

å…¶ä¸­ï¼š
- **MissingCauses**ï¼šçœŸå®å› æœï¼ˆå¦‚"æ¨â†’å€’"ï¼‰åœ¨Gä¸­æœªæ•è·
- **FalseCauses**ï¼šGä¸­é”™è¯¯æ¨æ–­çš„å› æœï¼ˆå¦‚"å€’â†’æ¨"ï¼‰

### 1.3.2 æŸå¤±æ¥æºåˆ†æçŸ©é˜µ

| æ„å»ºé˜¶æ®µ | æŸå¤±ç±»å‹ | å…¸å‹åœºæ™¯ | ç¼“è§£ç­–ç•¥ |
|---------|---------|---------|---------|
| **æ„ŸçŸ¥ç¼–ç ** | å‹ç¼©æŸå¤± | YOLOæ¼æ£€ã€"é¬¼å½±" | å¤šæ¨¡å‹é›†æˆã€æ—¶åºå¹³æ»‘ |
| **å¯¹è±¡è¿½è¸ª** | èº«ä»½æ··æ·† | é®æŒ¡åIDåˆ‡æ¢ | å¤–è§‚+è¿åŠ¨åŒçº¦æŸ |
| **äº‹ä»¶æ£€æµ‹** | è¾¹ç•Œæ¨¡ç³Š | æ— æ³•ç¡®å®š"å¼€å§‹"ç‚¹ | æ¨¡ç³ŠåŒºé—´è¡¨ç¤º |
| **å…³ç³»æŠ½å–** | å› æœé—æ¼ | é—´æ¥å› æœæœªæ•è· | ä¼ é€’é—­åŒ…æ¨ç† |
| **çŸ¥è¯†æŠ½è±¡** | è¿‡åº¦æ³›åŒ– | ç»†èŠ‚è¢«èšåˆæ‰ | å¤šç²’åº¦åˆ†å±‚å­˜å‚¨ |

---

## 1.4 è®°å¿†çš„ç»æµå­¦åŸåˆ™

### 1.4.1 æˆæœ¬-æ•ˆç›Šæ¨¡å‹

è®°å¿†ç³»ç»Ÿçš„æ€»æˆæœ¬å‡½æ•°ï¼š

```
TotalCost = wâ‚Â·Storage + wâ‚‚Â·Compute + wâ‚ƒÂ·Latency + wâ‚„Â·Maintenance
```

å…¶ä¸­å„é¡¹å‡ä¸ºå›¾è°±è§„æ¨¡ **|V|**ã€**|E|** çš„å‡½æ•°ã€‚æˆ‘ä»¬å‘ç°å­˜åœ¨ **ã€Œè®°å¿†ç»æµå¸•ç´¯æ‰˜å‰æ²¿ã€** ï¼š

> ç»™å®šä¿¡æ¯æŸå¤±ä¸Šé™L_maxï¼Œæ€»æˆæœ¬æœ€å°æ—¶çš„(|V|, |E|)ç»„åˆå¹¶éæœ€å¤§è§„æ¨¡ï¼Œè€Œæ˜¯**æœ€ä¼˜æŠ½è±¡ç²’åº¦**

### 1.4.2 è®°å¿†ä»·å€¼çš„è¡°å‡æ›²çº¿

èŠ‚ç‚¹ä»·å€¼éšæ—¶é—´è¡°å‡éµå¾ª **é‡è¦æ€§-æ–°é¢–æ€§-æ—¶é—´** ä¸‰ç»´å‡½æ•°ï¼š

```
Value(v, t) = Importance(v) Ã— Novelty(v) Ã— Decay(t - Ï„(v))
```

- **é‡è¦æ€§**ï¼šç”±å‚ä¸äº‹ä»¶æ•°é‡ã€å› æœæ·±åº¦å†³å®š
- **æ–°é¢–æ€§**ï¼šé¦–æ¬¡å‡ºç° vs é‡å¤æ¨¡å¼
- **è¡°å‡å‡½æ•°**ï¼šéçº¿æ€§ï¼Œå…³é”®äº‹ä»¶åŠè¡°æœŸé•¿ï¼ˆå¦‚äº‹æ•…ï¼‰ï¼Œæ—¥å¸¸äº‹ä»¶åŠè¡°æœŸçŸ­ï¼ˆå¦‚èµ°è·¯ï¼‰

**å®è·µå¯ç¤º**ï¼šè®°å¿†ç³»ç»Ÿåº”å®ç°**åŠ¨æ€è£å‰ª**ï¼Œä½ä»·å€¼èŠ‚ç‚¹è‡ªåŠ¨å½’æ¡£æˆ–åˆ é™¤ï¼Œä¿æŒæ´»è·ƒå›¾è°±åœ¨é«˜æ•ˆè§„æ¨¡ã€‚

---

## 1.5 ç†è®ºè¾¹ç•Œä¸ä¸å¯èƒ½ä¸‰è§’

æˆ‘ä»¬æå‡º **ã€Œæ—¶ç©ºè®°å¿†ä¸å¯èƒ½ä¸‰è§’ã€** ï¼š

> ä»»ä½•ç³»ç»Ÿæ— æ³•åŒæ—¶æ»¡è¶³ï¼š**å®æ—¶æ€§**ã€**æ— æŸæ€§**ã€**å¯æ‰©å±•æ€§**

- è‹¥è¦**å®æ—¶**ï¼ˆä½å»¶è¿Ÿï¼‰ï¼Œå¿…é¡»**æœ‰æŸ**ï¼ˆå‹ç¼©ï¼‰
- è‹¥è¦**æ— æŸ**ï¼ˆé«˜ä¿çœŸï¼‰ï¼Œå¿…é¡»**ç‰ºç‰²æ‰©å±•æ€§**ï¼ˆå°è§„æ¨¡ï¼‰
- è‹¥è¦**å¯æ‰©å±•**ï¼ˆå¤§è§„æ¨¡ï¼‰ï¼Œå¿…é¡»**éå®æ—¶**ï¼ˆæ‰¹å¤„ç†ï¼‰

**è®¾è®¡å“²å­¦**ï¼šæ¥å—ä¸‰è§’çº¦æŸï¼Œä½†æ ¹æ®åº”ç”¨åœºæ™¯é€‰æ‹©**çªç ´è¾¹**ï¼š
- **ç›‘æ§åœºæ™¯**ï¼šç‰ºç‰²æ— æŸæ€§ï¼Œä¿å®æ—¶+æ‰©å±•
- **å¸æ³•å–è¯**ï¼šç‰ºç‰²å®æ—¶æ€§ï¼Œä¿æ— æŸ+æ‰©å±•
- **æœºå™¨äººå¯¼èˆª**ï¼šç‰ºç‰²æ‰©å±•æ€§ï¼ˆä»…å±€éƒ¨è®°å¿†ï¼‰ï¼Œä¿å®æ—¶+æ— æŸ

---

## 1.6 æœ¬ç« å°ç»“

æœ¬æ¨¡å—æ„å»ºäº†æ—¶ç©ºçŸ¥è¯†è®°å¿†ç³»ç»Ÿçš„**ç¬¬ä¸€æ€§åŸç†**ï¼š

1. **æ ¸å¿ƒå¯¹è±¡**ï¼šå°†æ—¶é—´"å®ä½“åŒ–"ï¼Œæ„å»ºå››ç»´è¶…å›¾
2. **æ ¸å¿ƒåº¦é‡**ï¼šSTF + CI åŒç»´è¯„ä¼°ä¿¡æ¯æŸå¤±
3. **æ ¸å¿ƒçº¦æŸ**ï¼šè®°å¿†ç»æµå­¦æŒ‡å¯¼ä¸‹çš„å¸•ç´¯æ‰˜æœ€ä¼˜
4. **æ ¸å¿ƒå“²å­¦**ï¼šæ¥å—ä¸å¯èƒ½ä¸‰è§’ï¼Œåœºæ™¯åŒ–çªç ´

è¿™äº›ç†è®ºå°†æ˜¯åç»­æ‰€æœ‰æ¶æ„ã€ç®—æ³•ã€è¯„ä¼°çš„**å…¬ç†åŸºç¡€**ã€‚

---

â¡ï¸ **ä¸‹ä¸€æ¨¡å—é¢„å‘Š**ï¼šã€Šæ¨¡å—äºŒï¼šæ—¶ç©ºçŸ¥è¯†æŠ½å–æ¶æ„ã€‹å°†è¯¦ç»†é˜è¿°ä»è§†é¢‘æµåˆ°çŸ¥è¯†å›¾è°±çš„**å››é˜¶æŠ½ææµæ°´çº¿**ï¼ŒåŒ…æ‹¬æ„ŸçŸ¥èåˆã€æ—¶åºå¯¹é½ã€åŠ¨æ€æ›´æ–°ç­‰å·¥ç¨‹å®ç°ã€‚

---

*æ–‡æ¡£ç¼–å·ï¼šSTKG-M01-2024*  
*[è¯·ç¡®è®¤åç»§ç»­è¾“å‡ºä¸‹ä¸€æ¨¡å—]*

# ğŸ“˜ æ¨¡å—äºŒï¼šæ—¶ç©ºçŸ¥è¯†æŠ½å–æ¶æ„

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv1.0  
**æ’°å†™æ—¥æœŸ**ï¼š2024å¹´  
**æ ¸å¿ƒå®šä½**ï¼šå®ç°ä»è¿ç»­æ„ŸçŸ¥æµåˆ°ç¦»æ•£ç¬¦å·å›¾è°±çš„å·¥ç¨‹åŒ–è½¬æ¢

---

## 2.1 åˆ†å±‚æ„ŸçŸ¥ç¼–ç æ¡†æ¶

æˆ‘ä»¬æå‡º**å››é˜¶æ¸è¿›å¼æŠ½ææ¶æ„ï¼ˆFPE, Four-phase Progressive Extractionï¼‰**ï¼Œæ¯é˜¶è§£å†³ä¸åŒå±‚æ¬¡çš„æŠ½è±¡é—®é¢˜ï¼Œä¿¡æ¯æŸå¤±é€å±‚å¯æ§ã€‚

### 2.1.1 ç¬¬ä¸€é˜¶ï¼šåƒç´ çº§ç¼–ç ï¼ˆPixel-phaseï¼‰

**ç›®æ ‡**ï¼šä»åŸå§‹æ•°æ®ä¸­æå–å¯è¯†åˆ«çš„è§†è§‰åŸå­ã€‚

**æŠ€æœ¯æ ˆ**ï¼š
- **è§†è§‰ç¼–ç å™¨**ï¼šViT-Seg + DINOv2ï¼ˆå†»ç»“ç‰¹å¾æå–ï¼‰
- **æ—¶åºå¹³æ»‘**ï¼šå…‰æµçº¦æŸçš„æ—¶é—´ä¸€è‡´æ€§æ»¤æ³¢
- **è¾“å‡º**ï¼šå€™é€‰åŒºåŸŸåºåˆ— **R** = {râ‚, râ‚‚, ..., râ‚™}ï¼Œæ¯ä¸ª ráµ¢ åŒ…å« (bbox, mask, feature, t)

**å…³é”®è®¾è®¡**ï¼š**ä¸ç¡®å®šæ€§ä¿ç•™**
```python
# ä¸å¼ºåˆ¶åšç¡¬åˆ†ç±»ï¼Œä¿ç•™æ¦‚ç‡åˆ†å¸ƒ
class UncertainRegion:
    bbox: Tuple[float, float, float, float]
    class_dist: Dict[str, float]  # {"person": 0.7, "statue": 0.2, ...}
    temporal_support: Interval    # è¯¥åˆ†ç±»æŒç»­çš„æ—¶é—´æ®µ
    feature_vec: torch.Tensor
```

**ä¿¡æ¯æŸå¤±æ§åˆ¶**ï¼šæ­¤é˜¶æ®µ**ä¸ä¸¢å¼ƒ**ä»»ä½•å¯èƒ½å¯¹è±¡ï¼Œå°†åˆ†ç±»æ­§ä¹‰ä¼ é€’åˆ°ä¸‹ä¸€é˜¶å¤„ç†ã€‚

---

### 2.1.2 ç¬¬äºŒé˜¶ï¼šå¯¹è±¡çº§è¿½è¸ªï¼ˆObject-phaseï¼‰

**ç›®æ ‡**ï¼šå°†å€™é€‰åŒºåŸŸèšç±»ä¸ºè·¨å¸§ä¸€è‡´çš„èº«ä»½å®ä½“ã€‚

**æ ¸å¿ƒç®—æ³•**ï¼š**æ—¶ç©ºIOUå›¾åŒ¹é…ï¼ˆST-IOU Graph Matchingï¼‰**

æ„å»ºè·¨å¸§äºŒåˆ†å›¾ï¼Œè¾¹æƒé‡ä¸º **æ—¶ç©ºç›¸ä¼¼åº¦**ï¼š
```
w(r_i^t, r_j^{t+1}) = Î± Â· IoU_spatial + Î² Â· Cosine_feature + Î³ Â· Motion_consistency
```

**èº«ä»½ç”Ÿå‘½å‘¨æœŸç®¡ç†**ï¼š
```python
class TemporalIdentity:
    id: UUID
    appearances: List[TimeSlice]  # éè¿ç»­å‡ºç°åŒºé—´
    feature_history: Deque[Feature]  # æœ€è¿‘Kå¸§ç‰¹å¾ï¼ˆç”¨äºé‡è¯†åˆ«ï¼‰
    occlusion_flag: bool  # æ˜¯å¦å¤„äºé®æŒ¡çŠ¶æ€
    
    def get_current_state(self, query_t) -> Optional[State]:
        # è¿”å›æ—¶åˆ»tçš„æœ€å¯èƒ½çŠ¶æ€ï¼ˆå³ä½¿å¤„äºé®æŒ¡æœŸï¼‰
        return self._interpolate_state(query_t)
```

**åˆ›æ–°ç‚¹**ï¼š**é®æŒ¡æœŸè¯­ä¹‰ä¿æŒ**
- å½“å¯¹è±¡è¢«å®Œå…¨é®æŒ¡æ—¶ï¼Œä¸åˆ é™¤å®ä½“ï¼ŒçŠ¶æ€è½¬ä¸º  **`LatentState`**  ï¼ˆæ½œåœ¨çŠ¶æ€ï¼‰
- LatentStateé€šè¿‡è¿åŠ¨æ¨¡å‹é¢„æµ‹ä½ç½®ï¼Œç»´æŒå› æœé“¾å®Œæ•´æ€§

---

### 2.1.3 ç¬¬ä¸‰é˜¶ï¼šäº‹ä»¶çº§æ£€æµ‹ï¼ˆEvent-phaseï¼‰

**ç›®æ ‡**ï¼šè¯†åˆ«å¯¹è±¡é—´æœ‰æ„ä¹‰çš„**çŠ¶æ€è½¬ç§»**ã€‚

**äº‹ä»¶æœ¬ä½“**ï¼šåŸºäºæ¨¡å—ä¸€çš„STKG-Coreï¼Œäº‹ä»¶åˆ†ä¸ºä¸‰ç±»ï¼š

1. **åŸå­äº‹ä»¶ï¼ˆAtomicEventï¼‰**ï¼šç¬æ—¶å‘ç”Ÿï¼Œæ— å­ç»“æ„
   - ç¤ºä¾‹ï¼š`Touch(a,b)`, `Appear(x)`, `Vanish(x)`
   - æ—¶é—´è¡¨ç¤ºï¼šç‚¹åŒºé—´ `[t, t]`

2. **æŒç»­è¿‡ç¨‹ï¼ˆProcessï¼‰**ï¼šæœ‰æ˜ç¡®èµ·æ­¢ï¼Œå¯åˆ†è§£
   - ç¤ºä¾‹ï¼š`Meeting(person1, person2)`, `Walking(person1, path)`
   - æ—¶é—´è¡¨ç¤ºï¼šçœŸåŒºé—´ `[t_start, t_end]`

3. **å¤åˆå™äº‹ï¼ˆNarrativeï¼‰**ï¼šé«˜å±‚è¯­ä¹‰æ¨¡å¼
   - ç¤ºä¾‹ï¼š`CookMeal(chef, dish)`, `Burglary(thief, object)`
   - ç”±å¤šä¸ªè¿‡ç¨‹ä¸åŸå­äº‹ä»¶æŒ‰æ¨¡å¼ç»„åˆ

**æ£€æµ‹ç­–ç•¥**ï¼š**äº‹ä»¶è§¦å‘å™¨ï¼ˆEvent Triggerï¼‰** æœºåˆ¶

```python
# äº‹ä»¶è§¦å‘æ¡ä»¶å‡½æ•°
_trigger_registry = {
    "SitDown": lambda state: (
        state.obj_type == "person" 
        and state.velocity < 0.1 
        and state.bbox_bottom_y < chair_top_y
        and state.prev_velocity > 0.5
    ),
    "HandOver": lambda states: (
        distance(states["hand_a"], states["hand_b"]) < THRESHOLD
        and states["object"].velocity_peak > 0.3
    )
}
```

**å…³é”®è®¾è®¡**ï¼š**æ¨¡ç³Šäº‹ä»¶è¾¹ç•Œ**
- äº‹ä»¶å¼€å§‹/ç»“æŸæ—¶é—´ä¸æ˜¯ç²¾ç¡®ç‚¹ï¼Œè€Œæ˜¯**ç½®ä¿¡åº¦ä¸Šå‡/ä¸‹é™åŒºé—´**
- è¡¨ç¤ºä¸º **FuzzyInterval**ï¼š`[t_center, t_left_spread, t_right_spread]`
- ä¼˜åŠ¿ï¼šé¿å…è¾¹ç•Œäº‰è®®ï¼Œä¿ç•™æ—¶åºä¸ç¡®å®šæ€§åˆ°æŸ¥è¯¢é˜¶æ®µ

---

### 2.1.4 ç¬¬å››é˜¶ï¼šè¯­ä¹‰çº§æŠ½è±¡ï¼ˆSemantic-phaseï¼‰

**ç›®æ ‡**ï¼šå‘ç°é‡å¤æ¨¡å¼ï¼Œæ„å»ºå¯å¤ç”¨çš„**è®°å¿†æ¨¡æ¿**ã€‚

**æ ¸å¿ƒç®—æ³•**ï¼š**æ—¶ç©ºå­å›¾é¢‘ç¹æ¨¡å¼æŒ–æ˜ï¼ˆST-FPMï¼‰**

```
è¾“å…¥ï¼šå†å²äº‹ä»¶å­å›¾æµ {Gâ‚, Gâ‚‚, ..., Gâ‚™}
è¾“å‡ºï¼šé¢‘ç¹æ¨¡å¼é›†åˆ P = {(pattern, support, temporal_variance)}
```

**æ¨¡å¼è¡¨ç¤º**ï¼š**å‚æ•°åŒ–å­å›¾æ¨¡æ¿**

```cypher
// Cypheré£æ ¼çš„æ¨¡å¼å®šä¹‰
PATTERN DailyRoutine {
    (p:Person)-[e1:ENTERS]->(r:Room {type: "kitchen"})
    e1 FOLLOWED_BY (e2:StartProcess {type: "Cooking"}) 
    WHERE time_gap(e1, e2) < 5min
    
    (e2) CONTAINS (e3:AtomicEvent {type: "OpenFridge"})
    (e3) OCCURS_AT (rc:RegionConstraint {near: "fridge"})
    
    RETURN p, r, avg(duration(e2)) as cook_time
}
```

**æ¨¡å¼å‹ç¼©æ•ˆç›Š**ï¼š
- å½“æŸæ¨¡å¼æ”¯æŒåº¦ > 30%ï¼Œå°†å…¶**å­˜å‚¨ä¸ºå•ä¸€èŠ‚ç‚¹**ï¼ˆ`PatternInstance`ï¼‰
- åŸå§‹å­å›¾è½¬ä¸ºå½’æ¡£å­˜å‚¨ï¼Œæ´»è·ƒå›¾è°±ä½“ç§¯å‹ç¼© **40-70%**
- æ£€ç´¢æ—¶æŒ‰éœ€å±•å¼€ï¼Œå¹³è¡¡å­˜å‚¨ä¸æŸ¥è¯¢çµæ´»æ€§

---

## 2.2 æ—¶é—´å»ºæ¨¡çš„ä¸‰ç§èŒƒå¼

### 2.2.1 èŒƒå¼Aï¼šæ—¶é—´æˆ³é™„ç€ï¼ˆTimestamp Attachmentï¼‰

**æ¨¡å‹**ï¼šæ—¶é—´ä½œä¸º**å±æ€§**æŒ‚åœ¨èŠ‚ç‚¹/è¾¹ä¸Š

```python
class Edge:
    source: Node
    target: Node
    relation_type: str
    timestamp: float  # å”¯ä¸€æ—¶é—´æˆ³
```

**é€‚ç”¨åœºæ™¯**ï¼š
- ä¼ æ„Ÿå™¨æ—¥å¿—ï¼šæ¸©åº¦è®°å½•ã€æŒ‰é’®ç‚¹å‡»
- é«˜é¢‘ä½å»¶è¿Ÿå†™å…¥ï¼šæ¯ç§’100+æ¬¡æ›´æ–°

**è‡´å‘½ç¼ºé™·**ï¼šæ— æ³•è¡¨ç¤º**æŒç»­è¿‡ç¨‹**ã€éš¾ä»¥å¤„ç†**æ—¶åºåŒºé—´æŸ¥è¯¢**ï¼ˆå¦‚"2024å¹´Q1çš„æ‰€æœ‰ä¼šè®®"ï¼‰

---

### 2.2.2 èŒƒå¼Bï¼šæ—¶é—´åŒºé—´å®ä½“åŒ–ï¼ˆTemporal Reificationï¼‰

**æ¨¡å‹**ï¼šæ—¶é—´åŒºé—´ä½œä¸º**ç‹¬ç«‹èŠ‚ç‚¹**ï¼Œäº‹ä»¶é€šè¿‡å…³ç³»è¿æ¥åˆ°æ—¶é—´

```cypher
// ç¤ºä¾‹ï¼šä¼šè®®å‘ç”Ÿåœ¨ç‰¹å®šæ—¶é—´æ®µ
(meeting:Event)-[OCCURS_AT]->(interval:TimeInterval {start: 10:00, end: 11:30})
(interval)-[CONTAINS]->(sub_interval:TimeSlice {hour: 10, minute: 30})
```

**ä¼˜åŠ¿**ï¼š
- æ—¶é—´å¯**å¤ç”¨**ï¼šå¤šä¸ªäº‹ä»¶å…±äº«åŒä¸€åŒºé—´
- æ”¯æŒ**æ—¶é—´æ¨ç†**ï¼šåŒºé—´åŒ…å«ã€é‡å ã€ç›¸æ¥ç­‰13ç§è‰¾ä¼¦å…³ç³»
- ç¬¦åˆæ¨¡å—ä¸€çš„å››ç»´è¶…å›¾ç†è®º

**ä»£ä»·**ï¼šå›¾è°±è§„æ¨¡å¢åŠ  **30-50%**ï¼ŒæŸ¥è¯¢è·¯å¾„å˜é•¿

---

### 2.2.3 èŒƒå¼Cï¼šæ—¶æ€é€»è¾‘åµŒå…¥ï¼ˆTemporal Logic Embeddingï¼‰

**æ¨¡å‹**ï¼šå°†æ—¶æ€çº¦æŸåµŒå…¥**æŸ¥è¯¢ä»£æ•°**ï¼Œå­˜å‚¨å±‚æ— æ—¶é—´ä¿¡æ¯

```python
# æŸ¥è¯¢æ—¶åŠ¨æ€è¿‡æ»¤
query = """
MATCH (e:Event)
WHERE e.type = "Meeting" 
  AND Temporal.contains(e.valid_time, query_interval)
RETURN e
"""
```

**åº•å±‚å®ç°**ï¼šä½¿ç”¨**æ—¶æ€æ•°æ®åº“**ï¼ˆå¦‚PostgreSQLæ—¶æ€è¡¨ï¼‰å­˜å‚¨æ—¶é—´ï¼Œå›¾å­˜å‚¨ç»“æ„ã€‚

**é€‚ç”¨åœºæ™¯**ï¼šæ—¶é—´ç»´åº¦æŸ¥è¯¢æ¨¡å¼å›ºå®šã€éœ€è¦SQLçº§ACIDäº‹åŠ¡

---

### 2.2.4 èŒƒå¼é€‰æ‹©å†³ç­–çŸ©é˜µ

| åœºæ™¯ç‰¹å¾ | æ¨èèŒƒå¼ | ç†ç”± |
|---------|---------|------|
| å®æ—¶æµå¤„ç†ï¼ˆç›‘æ§ï¼‰ | A | å†™å…¥æœ€å¿«ï¼ŒæŸ¥è¯¢ç®€å• |
| å¤æ‚äº‹ä»¶åˆ†æï¼ˆå¸æ³•ï¼‰ | B | æ—¶æ€æ¨ç†èƒ½åŠ›å¼ºï¼Œä¿¡æ¯ä¿å­˜å®Œæ•´ |
| äº‹åŠ¡æ€§ç³»ç»Ÿï¼ˆåŒ»ç–—ï¼‰ | C | åˆ©ç”¨æˆç†Ÿæ—¶æ€æ•°æ®åº“ï¼Œä¿è¯ä¸€è‡´æ€§ |
| æ··åˆåœºæ™¯ï¼ˆé€šç”¨ï¼‰ | **A+Bæ··åˆ** | å®æ—¶ç”¨Aï¼Œå½’æ¡£è½¬B |

**STKGç³»ç»Ÿå»ºè®®**ï¼š**åŠ¨æ€èŒƒå¼è½¬æ¢**
- è¿‘æœŸè®°å¿†ï¼ˆ<24hï¼‰ï¼šèŒƒå¼Aï¼Œçƒ­æ•°æ®é«˜é€Ÿå­˜å–
- é•¿æœŸè®°å¿†ï¼ˆ>24hï¼‰ï¼šèŒƒå¼Bï¼Œå†·æ•°æ®æ·±åº¦åˆ†æ
- è½¬æ¢æ—¶æœºï¼šæ¯æ—¥å‡Œæ™¨æ‰¹å¤„ç†ï¼ŒAâ†’Bè½¬æ¢å¹¶å‹ç¼©

---

## 2.3 åŠ¨æ€å›¾è°±æ„å»ºç®—æ³•

### 2.3.1 å¢é‡å¼æ„å»ºï¼ˆIncremental Buildingï¼‰

**åœºæ™¯**ï¼šå®æ—¶è§†é¢‘æµï¼Œæ— æ³•æ‰¿å—å…¨é‡é‡ç®—ã€‚

**ç®—æ³•**ï¼š**äº‹ä»¶é©±åŠ¨æ›´æ–°ï¼ˆEvent-Driven Updateï¼‰**

```python
def on_new_frame(frame_t):
    # 1. å¢é‡è¿½è¸ª
    new_objects = tracker.update(frame_t)
    
    # 2. å±€éƒ¨äº‹ä»¶æ£€æµ‹ï¼ˆä»…æ£€æŸ¥æ¶‰åŠæ–°objectsçš„äº‹ä»¶ï¼‰
    affected_events = event_detector.check_triggers(new_objects, frame_t)
    
    # 3. å›¾è°±å±€éƒ¨ä¿®æ”¹
    with graph.transaction():
        for obj in new_objects:
            merge_node(obj)  # å­˜åœ¨åˆ™æ›´æ–°ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»º
        
        for event in affected_events:
            if event.is_new():
                create_event_subgraph(event)  # åˆ›å»ºæ–°äº‹ä»¶å­å›¾
            else:
                extend_event_interval(event)   # å»¶é•¿ç°æœ‰äº‹ä»¶åŒºé—´
    
    # 4. è§¦å‘ä¾èµ–æ›´æ–°
    if affected_events:
        causal_inference_engine.propagate(event_ids, horizon=3)  # å‘å‰ä¼ æ’­3å±‚
```

**å¤æ‚åº¦**ï¼šæ¯å¸§ **O(kÂ·m)**ï¼Œkä¸ºæ–°å¯¹è±¡æ•°ï¼Œmä¸ºå…³è”äº‹ä»¶æ•°ï¼Œä¸å›¾è°±æ€»è§„æ¨¡æ— å…³ã€‚

---

### 2.3.2 ä¿®æ­£å¼æ„å»ºï¼ˆRevision-based Buildingï¼‰

**åœºæ™¯**ï¼šäº‹ååˆ†æï¼Œéœ€è¦ä¿®æ­£å†å²é”™è¯¯ï¼ˆå¦‚IDåˆ‡æ¢ã€è¯¯åˆ¤ï¼‰ã€‚

**ç®—æ³•**ï¼š**å›æº¯ä¿®æ­£é“¾ï¼ˆBacktracking Revision Chainï¼‰**

```python
def revise_entity_identity(old_id, new_id, evidence_score):
    """
    å½“å‘ç°old_idä¸new_idå®ä¸ºåŒä¸€å®ä½“æ—¶è§¦å‘
    """
    # 1. åˆå¹¶å®ä½“èŠ‚ç‚¹ï¼ˆä¿ç•™new_idï¼‰
    graph.merge_nodes(old_id, new_id)
    
    # 2. ä¿®æ­£æ‰€æœ‰å…³è”äº‹ä»¶
    affected_edges = graph.get_edges(old_id)
    for edge in affected_edges:
        edge.source = new_id
    
    # 3. æ—¶é—´çº¿é‡å»º
    timeline = reconstruct_timeline(new_id)
    
    # 4. å› æœé“¾é‡éªŒè¯
    if causal_inference_engine.verify_chain(timeline) == False:
        # å‘ç°å› æœçŸ›ç›¾ï¼Œè§¦å‘äºŒæ¬¡ä¿®æ­£
        causal_inference_engine.repair_inconsistencies()
    
    # 5. æ ‡æ³¨ä¿®æ­£å†å²ï¼ˆç”¨äºå®¡è®¡ï¼‰
    graph.create_revision_log(old_id, new_id, evidence_score)
```

**å…³é”®**ï¼šä¿®æ­£æ“ä½œå¿…é¡»**å¯è¿½æº¯**ï¼Œä¿ç•™åŸå§‹æ•°æ®å¿«ç…§ï¼Œæ”¯æŒå¸æ³•çº§å®¡è®¡ã€‚

---

### 2.3.3 åˆå¹¶å¼æ„å»ºï¼ˆConsolidation-based Buildingï¼‰

**åœºæ™¯**ï¼šé•¿æœŸè¿è¡Œåï¼Œå›¾è°±ç¢ç‰‡åŒ–ä¸¥é‡ï¼Œéœ€è¦å…¨å±€ä¼˜åŒ–ã€‚

**ç®—æ³•**ï¼š**æ—¶ç©ºå›¾èšç±»åˆå¹¶ï¼ˆST-Graph Clusteringï¼‰**

```
è¾“å…¥ï¼šåŸå§‹å›¾è°± Gï¼Œç›¸ä¼¼åº¦é˜ˆå€¼ Î¸
è¾“å‡ºï¼šå‹ç¼©å›¾è°± G'

æ­¥éª¤ï¼š
1. æ—¶é—´åˆ†æ®µï¼šå°†å›¾è°±æŒ‰äº‹ä»¶å¯†åº¦åˆ†å‰²ä¸º K ä¸ªæ—¶é—´çª—å£
2. æ¨¡å¼æŒ–æ˜ï¼šåœ¨æ¯ä¸ªçª—å£å†…è¿è¡Œå­å›¾åŒæ„æ£€æµ‹
3. èšç±»ä¸­å¿ƒï¼šå¯¹ç›¸ä¼¼å­å›¾ï¼ˆç›¸ä¼¼åº¦>Î¸ï¼‰ç”Ÿæˆæ¨¡å¼æ¨¡æ¿
4. æ›¿æ¢å‹ç¼©ï¼šç”¨ PatternInstance æ›¿æ¢é‡å¤å­å›¾
5. ç´¢å¼•é‡å»ºï¼šæ›´æ–°æ‰€æœ‰æŒ‡å‘è¢«æ›¿æ¢èŠ‚ç‚¹çš„å¼•ç”¨
```

**ç›¸ä¼¼åº¦åº¦é‡**ï¼š
```
sim(Gâ‚, Gâ‚‚) = wâ‚Â·node_jaccard + wâ‚‚Â·edge_jaccard + wâ‚ƒÂ·temporal_overlap
```

**æ‰§è¡Œç­–ç•¥**ï¼šç¦»çº¿æ‰¹å¤„ç†ï¼Œæ¯å‘¨/æœˆæ‰§è¡Œï¼Œ**ä¸å½±å“åœ¨çº¿æŸ¥è¯¢**ã€‚

---

## 2.4 æ—¶ç©ºå¯¹é½æœºåˆ¶

### 2.4.1 è·¨æ¨¡æ€æ—¶é—´æˆ³ç»Ÿä¸€

ä¸åŒä¼ æ„Ÿå™¨æ—¶é’Ÿå­˜åœ¨**æ¼‚ç§»**ï¼ˆdriftï¼‰å’Œ**åç§»**ï¼ˆoffsetï¼‰ã€‚

**å¯¹é½åè®®**ï¼š**å±‚çº§æ—¶é—´é”šå®š**

```yaml
time_hierarchy:
  level_0:  # ç‰©ç†å±‚
    source: GPS PPSä¿¡å·ï¼ˆç²¾åº¦1Î¼sï¼‰
    role: å…¨å±€é”šç‚¹
    
  level_1:  # è®¾å¤‡å±‚
    source: NTPåŒæ­¥æœåŠ¡å™¨ï¼ˆç²¾åº¦1msï¼‰
    role: æ‘„åƒå¤´/éº¦å…‹é£ä¸»æ—¶é’Ÿ
    
  level_2:  # æ•°æ®å±‚
    source: å¸§æ—¶é—´æˆ³ï¼ˆç²¾åº¦33ms@30fpsï¼‰
    role: æ¯å¸§æ•°æ®æ ‡è®°
    
  level_3:  # äº‹ä»¶å±‚
    source: äº‹ä»¶æ£€æµ‹å™¨è¾“å‡º
    role: è¯­ä¹‰æ—¶é—´å¯¹é½
```

**åŠ¨æ€æ¼‚ç§»è¡¥å¿**ï¼š
```python
def compensate_drift(sensor_id, local_timestamp):
    drift_rate = get_drift_rate(sensor_id)  # æ¯å°æ—¶æ¼‚ç§»ppm
    last_sync = get_last_sync_time(sensor_id)
    adjusted = local_timestamp + drift_rate * (now - last_sync)
    return adjusted
```

---

### 2.4.2 ç©ºé—´åæ ‡ç³»ç»Ÿä¸€

å¤šæ‘„åƒå¤´åœºæ™¯ä¸‹ï¼Œç©ºé—´åæ ‡ç³»éœ€è¦ç»Ÿä¸€ã€‚

**æ–¹æ¡ˆ**ï¼š**åˆ†å±‚ç©ºé—´æ³¨å†Œï¼ˆHierarchical Spatial Registrationï¼‰**

```
æ¥¼å±‚åœ°å›¾ (å…¨å±€åæ ‡ç³»)
    â†“
æ‘„åƒå¤´Câ‚è§†é‡ (å±€éƒ¨åæ ‡ç³») â† å•åº”çŸ©é˜µ Hâ‚â†’global
æ‘„åƒå¤´Câ‚‚è§†é‡ (å±€éƒ¨åæ ‡ç³») â† å•åº”çŸ©é˜µ Hâ‚‚â†’global
    â†“
åƒç´ åæ ‡ (åŸå§‹æ£€æµ‹æ¡†) â† å†…å‚çŸ©é˜µ K
```

**è‡ªåŠ¨æ ¡å‡†**ï¼šåˆ©ç”¨**åœ°é¢æ ‡å¿—ç‰©**ï¼ˆå¦‚ç“·ç –è§’ç‚¹ï¼‰åœ¨çº¿è®¡ç®—å•åº”çŸ©é˜µï¼Œæ¯æœˆé‡æ ¡å‡†ä¸€æ¬¡ã€‚

---

## 2.5 ä¿¡æ¯å‹ç¼©ä¸æŠ½è±¡

### 2.5.1 æ—¶ç©ºèšç±»å‹ç¼©

**é—®é¢˜**ï¼šåŒä¸€å¯¹è±¡åœ¨ç›¸é‚»å¸§é‡å¤å‡ºç°ï¼Œå¯¼è‡´å›¾è°±è†¨èƒ€ã€‚

**ç®—æ³•**ï¼š**è½¨è¿¹åˆ†æ®µçº¿æ€§åŒ–ï¼ˆTrajectory Piecewise Linearizationï¼‰**

```python
def compress_trajectory(points: List[(x, y, t)], epsilon: float):
    """
    Douglas-Peuckerç®—æ³•çš„æ—¶åºæ‰©å±•
    epsilon: æœ€å¤§å…è®¸è¯¯å·®ï¼ˆåƒç´ ï¼‰
    """
    if len(points) < 3:
        return points
    
    # æ‰¾åˆ°è·ç¦»çº¿æ®µé¦–å°¾è¿çº¿æœ€è¿œçš„ç‚¹
    start, end = points[0], points[-1]
    max_dist, max_idx = 0, 0
    for i, p in enumerate(points[1:-1]):
        dist = point_to_line_distance(p, start, end)
        if dist > max_dist:
            max_dist, max_idx = dist, i+1
    
    if max_dist > epsilon:
        # é€’å½’åˆ†å‰²
        left = compress_trajectory(points[:max_idx+1], epsilon)
        right = compress_trajectory(points[max_idx:], epsilon)
        return left[:-1] + right  # å»æ‰é‡å¤ç‚¹
    else:
        return [start, end]  # å‹ç¼©ä¸ºçº¿æ®µ
```

**å‹ç¼©ç‡**ï¼šå®¤å†…ç›‘æ§åœºæ™¯**85-95%**ï¼Œä»…ä¿ç•™å…³é”®è½¬æŠ˜ç‚¹ï¼ˆå¦‚è½¬å¼¯ã€åœæ­¢ï¼‰ã€‚

---

### 2.5.2 å› æœé“¾å‰ªæ

**é—®é¢˜**ï¼šæ— å…³ç´§è¦çš„å› æœè¾¹è¿‡å¤šï¼Œå¦‚"å‘¼å¸â†’å­˜åœ¨"è¿™ç§å¹³å‡¡å› æœã€‚

**ç­–ç•¥**ï¼š**æ˜¾è‘—æ€§å› æœè¿‡æ»¤**

```
ä¿ç•™æ¡ä»¶ï¼š
1. å› æœå¼ºåº¦ > Î¸_strength ï¼ˆåŸºäºå…±ç°é¢‘ç‡ä¸äº’ä¿¡æ¯ï¼‰
2. å› æœç‰¹å¼‚æ€§ > Î¸_specificity ï¼ˆç»“æœçš„å”¯ä¸€å› ï¼‰
3. å› æœæ–°å¥‡åº¦ > Î¸_novelty ï¼ˆéæ—¥å¸¸åå¤æ¨¡å¼ï¼‰

å‰ªæç¤ºä¾‹ï¼š
ä¿ç•™ï¼š"æ‘”å€’â†’å‘¼æ•‘" ï¼ˆå¼ºåº¦é«˜ã€ç‰¹å¼‚ã€æ–°å¥‡ï¼‰
å‰ªæï¼š"èµ°åŠ¨â†’ä½ç½®æ”¹å˜" ï¼ˆè¿‡äºå¹³å‡¡ï¼‰
```

---

## 2.6 æœ¬ç« å°ç»“

æœ¬æ¨¡å—æ„å»ºäº†ä»**åŸå§‹æ„ŸçŸ¥æµåˆ°ç»“æ„åŒ–å›¾è°±**çš„å®Œæ•´æµæ°´çº¿ï¼š

1. **å››é˜¶æ¸è¿›**ï¼šåƒç´ â†’å¯¹è±¡â†’äº‹ä»¶â†’è¯­ä¹‰ï¼Œæ¯é˜¶å¯æ§ä¿¡æ¯æŸå¤±
2. **ä¸‰èŒƒæ—¶é—´ç®¡ç†**ï¼šA/B/CèŒƒå¼æŒ‰éœ€åˆ‡æ¢ï¼ŒåŠ¨æ€å¹³è¡¡å†™å…¥ä¸æŸ¥è¯¢
3. **åŠ¨æ€æ›´æ–°**ï¼šå¢é‡+ä¿®æ­£+åˆå¹¶ä¸‰é‡æœºåˆ¶ï¼Œé€‚åº”æµå¼ä¸æ‰¹å¤„ç†
4. **æ—¶ç©ºå¯¹é½**ï¼šè·¨æ¨¡æ€é”šå®šåè®®ï¼Œä¿è¯æ—¶ç©ºä¸€è‡´æ€§
5. **å‹ç¼©æŠ½è±¡**ï¼šè½¨è¿¹çº¿æ€§åŒ–+å› æœå‰ªæï¼Œç»´æŒå›¾è°±ç»æµè§„æ¨¡

ä¸‹ä¸€æ¨¡å—å°†å®šä¹‰è¿™äº›æŠ½å–ç»“æœçš„**æ ‡å‡†åŒ–è¡¨ç¤ºæ–¹å¼**ï¼Œæ„å»ºå¯å…±äº«çš„**STKG-Coreæœ¬ä½“**ã€‚

---

â¡ï¸ **ä¸‹ä¸€æ¨¡å—é¢„å‘Š**ï¼šã€Šæ¨¡å—ä¸‰ï¼šå›¾è°±æœ¬ä½“è®¾è®¡ä¸çŸ¥è¯†è¡¨ç¤ºã€‹å°†è¯¦ç»†é˜è¿°STKG-Coreæœ¬ä½“æ¨¡å‹ã€äº‹ä»¶é¢—ç²’åº¦å“²å­¦ä¸ä¸ç¡®å®šæ€§é‡åŒ–æœºåˆ¶ã€‚

---

*æ–‡æ¡£ç¼–å·ï¼šSTKG-M02-2024*  
*å½“å‰è¿›åº¦ï¼š2/7 æ¨¡å—*

# ğŸ“˜ æ¨¡å—ä¸‰ï¼šå›¾è°±æœ¬ä½“è®¾è®¡ä¸çŸ¥è¯†è¡¨ç¤º

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv1.0  
**æ’°å†™æ—¥æœŸ**ï¼š2024å¹´  
**æ ¸å¿ƒå®šä½**ï¼šå®šä¹‰æ—¶ç©ºçŸ¥è¯†è®°å¿†ç³»ç»Ÿçš„"é€šç”¨è¯­è¨€"ä¸ç¬¦å·è§„èŒƒ

---

## 3.1 æ ¸å¿ƒæœ¬ä½“æ¨¡å‹ï¼šSTKG-Core

æˆ‘ä»¬è®¾è®¡ **STKG-Core** ä½œä¸ºæ—¶ç©ºçŸ¥è¯†å›¾è°±çš„åŸºç¡€æœ¬ä½“ï¼Œéµå¾ª**æœ€å°å®Œå¤‡æ€§åŸåˆ™**â€”â€”ä»…åŒ…å«ä¸å¯æˆ–ç¼ºçš„åŸè¯­ï¼Œé¿å…OWLå¼çš„è¿‡åº¦å¤æ‚ã€‚

### 3.1.1 å®ä½“åŸè¯­ï¼ˆEntity Primitivesï¼‰

#### **åŸè¯­1ï¼šæ—¶ç©ºåˆ‡ç‰‡ï¼ˆTimeSliceï¼‰**
```
å®šä¹‰ï¼šä¸å¯å†åˆ†çš„æœ€å°æ—¶ç©ºå•å…ƒï¼Œç±»ä¼¼"æ—¶ç©ºåŸå­"
å±æ€§ï¼š
  - slice_id: UUID
  - time_range: TimeInterval [start, end]
  - space_region: BoundingBox3D
  - granularity_level: int (0=åŸå§‹è§‚æµ‹, 1=å°æ—¶, 2=å¤©...)
  
å…³é”®ç‰¹æ€§ï¼š
  - åµŒå¥—æ€§ï¼šå¤§TimeSliceå¯åŒ…å«å°TimeSlice
  - ä¸å¯å˜æ€§ï¼šä¸€æ—¦åˆ›å»ºï¼Œå†…å®¹ä¸å¯ä¿®æ”¹ï¼ˆå®ç°å®¡è®¡è¿½è¸ªï¼‰
  - å¯å¯»å€æ€§ï¼šå¯é€šè¿‡æ—¶ç©ºåæ ‡ç›´æ¥å®šä½
```

**åˆ›å»ºè§„åˆ™**ï¼š
- æ¯ä¸ªæ‘„åƒå¤´æ¯5åˆ†é’Ÿç”Ÿæˆä¸€ä¸ªTimeSliceï¼ˆçƒ­æ•°æ®ï¼‰
- ç”¨æˆ·æŸ¥è¯¢è‡ªåŠ¨è§¦å‘TimeSliceåˆå¹¶ï¼ˆå†·æ•°æ®å½’æ¡£ï¼‰

---

#### **åŸè¯­2ï¼šæ—¶ç©ºåŒºåŸŸï¼ˆSpatioTemporalRegionï¼‰**
```
å®šä¹‰ï¼šè¯­ä¹‰ä¸Šæœ‰æ„ä¹‰çš„æ—¶ç©ºèŒƒå›´ï¼Œè·¨å¤šä¸ªTimeSliceçš„èšåˆ
å±æ€§ï¼š
  - region_id: UUID
  - time_interval: TimeInterval
  - space_polygon: List[Point3D]  # æ”¯æŒä¸è§„åˆ™å½¢çŠ¶
  - region_type: Enum[ROOM, AREA, ZONE, PATH]
  
ä¸TimeSliceåŒºåˆ«ï¼š
  - TimeSliceæ˜¯ç‰©ç†è§‚æµ‹å•å…ƒï¼ˆæ‘„åƒå¤´è§†é‡ï¼‰
  - SpatioTemporalRegionæ˜¯è¯­ä¹‰å•å…ƒï¼ˆå¦‚"ä¼šè®®å®¤A"ã€"èµ°å»Š"ï¼‰
```

**è‡ªåŠ¨å‘ç°ç®—æ³•**ï¼šåŸºäº**å¯¹è±¡è®¿é—®çƒ­å›¾**èšç±»ç”Ÿæˆã€‚å½“æŸç©ºé—´åŒºåŸŸåœ¨ç‰¹å®šæ—¶æ®µé¢‘ç¹æˆä¸ºäº‹ä»¶ä¸»ä½“æ—¶ï¼Œè‡ªåŠ¨æ™‹å‡ä¸ºSpatioTemporalRegionã€‚

---

#### **åŸè¯­3ï¼šäº‹ä»¶ï¼ˆEventï¼‰**
```
å®šä¹‰ï¼šå¼•èµ·çŠ¶æ€æ”¹å˜çš„åŸå­æˆ–å¤åˆåŠ¨ä½œ
å±æ€§ï¼š
  - event_id: UUID
  - event_type: str (æ¥è‡ªå—æ§è¯è¡¨)
  - participants: List[Entity]  # å‚ä¸è€…
  - occurs_at: TimeSlice | SpatioTemporalRegion
  - confidence: float [0,1]  # æ£€æµ‹ç½®ä¿¡åº¦
  
åˆ†ç±»ï¼š
  - AtomicEvent: ç¬æ—¶äº‹ä»¶ï¼ˆå¦‚"ç¯å¼€"ï¼‰
  - Process: æŒç»­äº‹ä»¶ï¼ˆå¦‚"ä¼šè®®"ï¼‰
  - CompositeEvent: ç”±å­äº‹ä»¶æ„æˆï¼ˆå¦‚"åšé¥­"å«"æ´—èœ"ã€"åˆ‡èœ"ï¼‰
```

**æ ¸å¿ƒçº¦æŸ**ï¼šäº‹ä»¶å¿…é¡»**ç»‘å®šåˆ°è‡³å°‘ä¸€ä¸ªæ—¶ç©ºèŒƒå›´**ï¼Œæ— æ—¶ç©ºé”šç‚¹çš„äº‹ä»¶è§†ä¸ºæ— æ•ˆã€‚

---

#### **åŸè¯­4ï¼šçŠ¶æ€ï¼ˆStateï¼‰**
```
å®šä¹‰ï¼šå¯¹è±¡æˆ–ç¯å¢ƒåœ¨æŸæ—¶ç©ºç‚¹çš„å±æ€§å¿«ç…§
å±æ€§ï¼š
  - state_id: UUID
  - subject: Entity
  - property: str  # "ä½ç½®", "é€Ÿåº¦", "æ¸©åº¦"
  - value: Any
  - valid_time: TimeSlice
  
å…³é”®è®¾è®¡ï¼š
  - çŠ¶æ€æ˜¯å‡½æ•°å¼çš„ï¼šf(entity, time) â†’ value
  - çŠ¶æ€æ”¹å˜ç”±äº‹ä»¶é©±åŠ¨ï¼šEvent â†’ StateTransition
  - çŠ¶æ€å€¼æ”¯æŒæ¨¡ç³Šè¡¨ç¤ºï¼švalue = (mean, std) æˆ– æ¦‚ç‡åˆ†å¸ƒ
```

---

#### **åŸè¯­5ï¼šæ™ºèƒ½ä½“ï¼ˆAgentï¼‰**
```
å®šä¹‰ï¼šå…·æœ‰æ„å›¾æ€§çš„ç‰¹æ®Šå®ä½“ï¼ˆäººã€æœºå™¨äººã€AIç³»ç»Ÿï¼‰
ç»§æ‰¿è‡ªEntityï¼Œæ‰©å±•ï¼š
  - beliefs: Set[Proposition]  # ä¿¡å¿µé›†
  - intentions: Set[Goal]      # æ„å›¾é›†
  - capabilities: Set[Action]  # èƒ½åŠ›é›†
  
ç‰¹æ®Šèƒ½åŠ›ï¼š
  - å¯å‘èµ·äº‹ä»¶ï¼šAgent -[INTIATES]-> Event
  - å¯è§‚å¯ŸçŠ¶æ€ï¼šAgent -[OBSERVES]-> State
```

---

### 3.1.2 å…³ç³»åŸè¯­ï¼ˆRelation Primitivesï¼‰

æˆ‘ä»¬å®šä¹‰ **8ç§æ ¸å¿ƒå…³ç³»**ï¼Œè¦†ç›–æ—¶ç©ºã€å› æœã€é€»è¾‘ä¸‰ç»´åº¦ï¼š

| å…³ç³» | ç¬¦å· | å®šä¹‰åŸŸ | å€¼åŸŸ | æ—¶é—´çº¦æŸ | ç©ºé—´çº¦æŸ |
|------|------|--------|------|---------|---------|
| **occursAt** | e1 | Event | TimeSlice \| SpatioTemporalRegion | ä¸¥æ ¼ç­‰äº | åŒ…å« |
| **participatesIn** | e2 | Entity | Event | éƒ¨åˆ†é‡å  | å¯ç©º |
| **causes** | e3 | Event | Event | cause.end < effect.start | å¯ç©º |
| **follows** | e4 | Event | Event | e1.end <= e2.start | å¯ç©º |
| **spatiallyContains** | e5 | SpatioTemporalRegion | Entity | æ—¶é—´é‡å  | å‡ ä½•åŒ…å« |
| **temporallyContains** | e6 | TimeSlice | Event | åŒºé—´åŒ…å« | å¯ç©º |
| **transitionsTo** | e7 | State | State | ç¬æ—¶è¿æ¥ | å¯ç©º |
| **observes** | e8 | Agent | State \| Event | è§‚æµ‹æ—¶é—´ >= å‘ç”Ÿæ—¶é—´ | è§‚æµ‹è€…è§†è§’èŒƒå›´ |

**å…³ç³»å¤åˆæ€§ï¼ˆRelational Compositionï¼‰**ï¼š
- `causes` å…·æœ‰ä¼ é€’æ€§ï¼š`e1 causes e2` âˆ§ `e2 causes e3` â‡’ `e1 causes* e3`
- `spatiallyContains` å…·æœ‰ä¼ é€’æ€§ï¼šåŒºåŸŸåµŒå¥—
- `temporallyContains` å…·æœ‰ä¼ é€’æ€§ï¼šæ—¶é—´åµŒå¥—

**å®ç°å£°æ˜**ï¼šåœ¨å›¾æ•°æ®åº“ä¸­ï¼Œä¼ é€’æ€§**ä¸ç‰©åŒ–å­˜å‚¨**ï¼Œé€šè¿‡**æŸ¥è¯¢æ—¶æ¨ç†**å®ç°ï¼Œé¿å…æ•°æ®å†—ä½™ã€‚

---

### 3.1.3 STKG-Coreæœ¬ä½“å®šä¹‰ï¼ˆæœºå™¨å¯è¯»ï¼‰

```turtle
# Turtleæ ¼å¼çš„æœ¬ä½“å®šä¹‰ï¼ˆç‰‡æ®µï¼‰

@prefix stkg: <http://stkg.org/core#> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .

# ç±»å®šä¹‰
stkg:TimeSlice a rdfs:Class ;
    rdfs:label "æ—¶ç©ºåˆ‡ç‰‡" ;
    stkg:hasAttributes stkg:time_range, stkg:space_region, stkg:granularity_level ;
    stkg:immutability true .

stkg:AtomicEvent a rdfs:Class ;
    rdfs:subClassOf stkg:Event ;
    stkg:temporalType "instant" ;
    stkg:mustLink stkg:occursAt .

# å…³ç³»å®šä¹‰
stkg:causes a rdf:Property ;
    rdfs:domain stkg:Event ;
    rdfs:range stkg:Event ;
    stkg:temporalConstraint "domain.end < range.start" ;
    stkg:compositionRule "transitive" .

# çº¦æŸè§„åˆ™
stkg:Rule_001 a stkg:IntegrityConstraint ;
    stkg:description "äº‹ä»¶å¿…é¡»é”šå®šåˆ°æ—¶ç©º" ;
    stkg:sparql """
        ASK WHERE {
            ?event a stkg:Event .
            FILTER NOT EXISTS {
                ?event stkg:occursAt ?anchor .
                ?anchor a stkg:TimeSlice | stkg:SpatioTemporalRegion .
            }
        }
    """ ;
    stkg:severity "ERROR" .
```

---

## 3.2 äº‹ä»¶è¡¨ç¤ºçš„é¢—ç²’åº¦å“²å­¦

### 3.2.1 é¢—ç²’åº¦å±‚çº§ï¼ˆGranularity Hierarchyï¼‰

```
L0: åƒç´ å˜åŒ– (PixelChange) - æ— è¯­ä¹‰
L1: åŸå­äº‹ä»¶ (AtomicEvent) - å•ä¸€ä¸»ä½“å•ä¸€åŠ¨ä½œ
L2: ç®€å•è¿‡ç¨‹ (SimpleProcess) - å•ä¸€ä¸»ä½“å¤šåŠ¨ä½œåºåˆ—
L3: äº¤äº’è¿‡ç¨‹ (InteractiveProcess) - å¤šä¸»ä½“åä½œ/å¯¹æŠ—
L4: å¤åˆå™äº‹ (CompositeNarrative) - ç›®æ ‡å¯¼å‘çš„é«˜å±‚æ¨¡å¼
L5: ä¸»é¢˜æ•…äº‹ (ThematicStory) - è·¨æ—¶æ®µä¸»é¢˜èšåˆ
```

**å±‚çº§è½¬æ¢è§„åˆ™**ï¼š

- **å‘ä¸Šèšåˆï¼ˆBottom-upï¼‰**ï¼šå½“æ»¡è¶³**æ¨¡å¼é˜ˆå€¼**æ—¶è‡ªåŠ¨èšåˆ
  ```
  æ¡ä»¶ï¼šcount(sub_events) â‰¥ 5 
        AND variance(duration) < threshold
        AND participants_stable
  åŠ¨ä½œï¼šåˆ›å»ºCompositeNarrativeï¼Œé“¾æ¥å­äº‹ä»¶
  ```

- **å‘ä¸‹åˆ†è§£ï¼ˆTop-downï¼‰**ï¼šå½“æŸ¥è¯¢éœ€è¦ç»†èŠ‚æ—¶**æŒ‰éœ€å±•å¼€**
  ```
  æŸ¥è¯¢ï¼š"æŸ¥çœ‹åšé¥­è¿‡ç¨‹ä¸­çš„åˆ‡èœç»†èŠ‚"
  åŠ¨ä½œï¼šå®šä½CookMealå™äº‹èŠ‚ç‚¹ â†’ å±•å¼€sub_eventé“¾ â†’ è¿”å›SliceEventåºåˆ—
  ```

### 3.2.2 é¢—ç²’åº¦é€‰æ‹©çš„ç»æµå­¦

**ç»†ç²’åº¦ä¼˜åŠ¿**ï¼š
- æŸ¥è¯¢çµæ´»æ€§é«˜ï¼ˆå¯å›ç­”ä»»æ„ç»†èŠ‚é—®é¢˜ï¼‰
- å› æœå½’å› ç²¾ç¡®

**ç»†ç²’åº¦ä»£ä»·**ï¼š
- å­˜å‚¨æˆæœ¬æŒ‡æ•°å¢é•¿ï¼šå­˜å‚¨é‡ â‰ˆ O(N_frames)
- æŸ¥è¯¢æ€§èƒ½ä¸‹é™ï¼šè·¯å¾„é•¿åº¦å¢åŠ 

**æœ€ä¼˜é¢—ç²’åº¦å®šç†**ï¼š
> æœ€ä¼˜é¢—ç²’åº¦L*æ»¡è¶³ï¼šæŸ¥è¯¢çµæ´»æ€§çš„è¾¹é™…æ”¶ç›Š = å­˜å‚¨æˆæœ¬çš„è¾¹é™…æˆæœ¬

**å·¥ç¨‹ç»éªŒå€¼**ï¼š
- ç›‘æ§åœºæ™¯ï¼šL2ï¼ˆç®€å•è¿‡ç¨‹ï¼‰ä¸ºä¸»ï¼ŒL1ä¸ºè¾…åŠ©
- è¡Œä¸ºåˆ†æï¼šL3ï¼ˆäº¤äº’è¿‡ç¨‹ï¼‰ä¸ºæ ¸å¿ƒ
- é•¿æœŸè®°å¿†ï¼šL4ï¼ˆå¤åˆå™äº‹ï¼‰å‹ç¼©å­˜å‚¨

---

### 3.2.3 äº‹ä»¶å°è£…ä¸ä¿¡æ¯éšè—

å€Ÿé‰´é¢å‘å¯¹è±¡ç¼–ç¨‹çš„**å°è£…**æ€æƒ³ï¼š

```python
class CompositeNarrative:
    def __init__(self, sub_events):
        self.sub_events = sub_events  # ç§æœ‰
    
    def summary(self) -> str:
        # å¯¹å¤–æä¾›æ‘˜è¦
        return f"{self.main_agent}å®Œæˆäº†{self.goal}"
    
    def detail(self, query_filter) -> List[Event]:
        # æŒ‰éœ€å±•å¼€ç»†èŠ‚
        return [e for e in self.sub_events if query_filter(e)]
```

**ä¼˜åŠ¿**ï¼š
- é»˜è®¤æŸ¥è¯¢é€Ÿåº¦å¿«ï¼ˆåªè®¿é—®æ‘˜è¦ï¼‰
- ç»†èŠ‚è®¿é—®å¯æ§ï¼ˆåŸºäºæƒé™ä¸éœ€æ±‚ï¼‰
- ç¬¦åˆäººç±»è®°å¿†ç‰¹æ€§ï¼šè®°å¾—"å»è¿‡è¶…å¸‚"ï¼Œç»†èŠ‚éœ€å›å¿†

---

## 3.3 ä¸ç¡®å®šæ€§è¡¨ç¤º

### 3.3.1 æ¦‚ç‡å›¾åµŒå…¥

**é—®é¢˜**ï¼šæ£€æµ‹ç®—æ³•è¾“å‡ºæœ¬è´¨æ˜¯ä¸ç¡®å®šçš„ï¼ˆç½®ä¿¡åº¦ã€å™ªå£°ï¼‰ã€‚

**æ–¹æ¡ˆ**ï¼šå°†**æ¦‚ç‡åˆ†å¸ƒ**ä½œä¸ºèŠ‚ç‚¹å±æ€§ï¼š

```cypher
// äº‹ä»¶èŠ‚ç‚¹å¸¦æœ‰æ¦‚ç‡åˆ†å¸ƒ
(e:AtomicEvent {
    type: "FallDown",
    confidence: 0.87,
    time_distribution: {type: "gaussian", mean: 10:30:15, std: 0.5s},
    participant_distribution: [
        {entity: "person:001", prob: 0.9},
        {entity: "person:002", prob: 0.1}
    ]
})
```

**æŸ¥è¯¢è¯­ä¹‰æ‰©å±•**ï¼š
```cypher
// æŸ¥è¯¢ç½®ä¿¡åº¦>0.8çš„äº‹ä»¶
MATCH (e:Event)
WHERE e.confidence > 0.8
RETURN e, e.confidence as reliability
```

### 3.3.2 æ¨¡ç³Šæ—¶ç©ºåŒºåŸŸ

**é—®é¢˜**ï¼šäº‹ä»¶è¾¹ç•Œä¸æ˜ç¡®ï¼ˆ"ä¼šè®®å¤§çº¦10ç‚¹å¼€å§‹"ï¼‰ã€‚

**æ–¹æ¡ˆ**ï¼šä½¿ç”¨**æ¨¡ç³Šé›†åˆ**è¡¨ç¤ºæ—¶ç©ºï¼š

```python
class FuzzyTimeInterval:
    """æ¢¯å½¢æ¨¡ç³Šæ•°è¡¨ç¤ºæ—¶é—´"""
    def __init__(self, a, b, c, d):
        # a--b--c--d æ¢¯å½¢
        # å®Œå…¨éš¶å±åŒºé—´ [b,c]
        # è¿‡æ¸¡åŒºé—´ [a,b] å’Œ [c,d]
        self.support = [a, d]  # æ”¯æŒåŸŸ
        self.core = [b, c]     # æ ¸
    
    def membership(self, t):
        if self.core[0] <= t <= self.core[1]:
            return 1.0
        elif self.support[0] <= t < self.core[0]:
            return (t - self.support[0]) / (self.core[0] - self.support[0])
        elif self.core[1] < t <= self.support[1]:
            return (self.support[1] - t) / (self.support[1] - self.core[1])
        else:
            return 0.0
```

**ç©ºé—´æ¨¡ç³ŠåŒç†**ï¼šç”¨**é«˜æ–¯åˆ†å¸ƒ**è¡¨ç¤ºä½ç½®ä¸ç¡®å®šæ€§ã€‚

### 3.3.3 ä¸ç¡®å®šæ€§çš„ä¼ æ’­ä¸ç»„åˆ

å½“è¿›è¡Œå› æœæ¨ç†æ—¶ï¼Œä¸ç¡®å®šæ€§éœ€ä¼ æ’­ï¼š

```
P(e3|e1) = Î£ P(e3|e2) Â· P(e2|e1)  (è´å¶æ–¯ä¼ æ’­)

ç½®ä¿¡åº¦ç»„åˆï¼š
conf(e1 AND e2) = min(conf(e1), conf(e2))
conf(e1 OR e2) = max(conf(e1), conf(e2))
conf(NOT e1) = 1 - conf(e1)
```

**å®ç°**ï¼šåœ¨æŸ¥è¯¢å¼•æ“å±‚å®ç°**æ¦‚ç‡ç®—å­é‡è½½**ï¼Œç”¨æˆ·æ— éœ€æ‰‹åŠ¨è®¡ç®—ã€‚

---

## 3.4 è®°å¿†è¡°å‡æ¨¡å‹

### 3.4.1 ä¸‰ç»´ä»·å€¼å‡½æ•°

èŠ‚ç‚¹ä¿ç•™ä»·å€¼ç”±ä¸‰ä¸ªå› å­åŠ¨æ€å†³å®šï¼š

```
Value(v, t_now) = Importance(v) Ã— Novelty(v) Ã— Recency(v, t_now)
```

#### **å› å­1ï¼šé‡è¦æ€§ï¼ˆImportanceï¼‰**

```
Importance(v) = log(1 + deg(v)) + Î±Â·causal_depth(v)
```

- deg(v)ï¼šèŠ‚ç‚¹åº¦æ•°ï¼ˆå…³è”äº‹ä»¶æ•°ï¼‰
- causal_depthï¼šåœ¨å› æœé“¾ä¸­çš„å¹³å‡æ·±åº¦ï¼ˆæ ¹äº‹ä»¶æ›´æ·±ï¼‰
- Î±=0.3ï¼ˆç»éªŒæƒé‡ï¼‰

#### **å› å­2ï¼šæ–°é¢–æ€§ï¼ˆNoveltyï¼‰**

```
Novelty(v) = 1 - exp(-Î² Â· pattern_frequency)
```

- pattern_frequencyï¼šè¯¥èŠ‚ç‚¹å‚ä¸çš„æ¨¡å¼å‡ºç°æ¬¡æ•°
- é¦–æ¬¡å‡ºç°çš„æ–°é¢–æ€§â‰ˆ1ï¼Œæ—¥å¸¸é‡å¤çš„æ–°é¢–æ€§â†’0
- Î²=0.5ï¼ˆæ§åˆ¶è¡°å‡é€Ÿåº¦ï¼‰

#### **å› å­3ï¼šæ—¶æ•ˆæ€§ï¼ˆRecencyï¼‰**

```
Recency(v, t_now) = exp(-Î» Â· (t_now - t_last_access) / half_life)
```

- half_lifeï¼šåŠè¡°æœŸï¼ˆå…³é”®äº‹ä»¶=30å¤©ï¼Œæ™®é€šäº‹ä»¶=7å¤©ï¼‰
- æœ€è¿‘è®¿é—®æ—¶é—´æˆ³ç”±æŸ¥è¯¢è‡ªåŠ¨æ›´æ–°

### 3.4.2 åŠ¨æ€è£å‰ªç­–ç•¥

**è‡ªåŠ¨è£å‰ªé˜ˆå€¼**ï¼š`Î¸_prune = 0.1`

å½“ `Value(v) < Î¸_prune` æ—¶è§¦å‘ï¼š

1. **è½¯åˆ é™¤**ï¼šæ ‡è®°ä¸º `archived`ï¼Œç§»å‡ºæ´»è·ƒå›¾è°±
2. **å†·å­˜å‚¨**ï¼šåºåˆ—åŒ–åˆ°å¯¹è±¡å­˜å‚¨ï¼ˆS3/MinIOï¼‰ï¼Œä¿ç•™å…ƒæ•°æ®ç´¢å¼•
3. **åæ¿€æ´»**ï¼šæ–­å¼€ä½ä»·å€¼è¾¹ï¼Œä¿ç•™é«˜ä»·å€¼ä¸»å¹²è¾¹

**è¢«è£å‰ªèŠ‚ç‚¹å¤æ´»æœºåˆ¶**ï¼š
```
IF æŸ¥è¯¢æ¶‰åŠarchivedèŠ‚ç‚¹
THEN ä»å†·å­˜å‚¨åŠ è½½ + Value += 0.5 (å…´è¶£æƒ©ç½šé¡¹)
```

### 3.4.3 è®°å¿†å¢å¼ºå¾ªç¯ï¼ˆFORRå¾ªç¯ï¼‰

```python
def memory_forr_cycle():
    """
    FORR = Forgetting â†’ Organizing â†’ Retrieving â†’ Reinforcing
    """
    # F: é—å¿˜ä½ä»·å€¼èŠ‚ç‚¹
    forget_nodes = select_where(value < threshold)
    archive(forget_nodes)
    
    # O: ç»„ç»‡æ–°æ¨¡å¼
    new_patterns = mine_frequent_subgraphs(last_24h)
    compress(new_patterns)
    
    # R: æ£€ç´¢åˆ†æ
    query_log = analyze_query_patterns()
    hot_entities = query_log.frequent_entities
    
    # R: å¼ºåŒ–çƒ­ç‚¹
    for entity in hot_entities:
        reinforce(entity, strength=0.3)
    
    # æ¯6å°æ—¶æ‰§è¡Œä¸€æ¬¡
```

---

## 3.5 æœ¬ç« å°ç»“

æœ¬æ¨¡å—å®šä¹‰äº†æ—¶ç©ºè®°å¿†çš„**ç¬¦å·åœ°åŸº**ï¼š

1. **STKG-Coreæœ¬ä½“**ï¼š5å®ä½“+8å…³ç³»ï¼Œè¦†ç›–æ—¶ç©ºå› æœ
2. **é¢—ç²’åº¦å“²å­¦**ï¼šL0-L5å±‚çº§ï¼ŒåŠ¨æ€èšåˆä¸æŒ‰éœ€å±•å¼€
3. **ä¸ç¡®å®šæ€§é‡åŒ–**ï¼šæ¦‚ç‡å›¾+æ¨¡ç³Šé›†ï¼Œä¿ç•™æ„ŸçŸ¥ä¸ç¡®å®šæ€§
4. **è®°å¿†è¡°å‡**ï¼šä¸‰ç»´ä»·å€¼æ¨¡å‹é©±åŠ¨è‡ªåŠ¨è£å‰ª

è¿™äº›å®šä¹‰å°†æŒ‡å¯¼åç»­**æŸ¥è¯¢è¯­è¨€è®¾è®¡**ï¼ˆæ¨¡å—å››ï¼‰ä¸**ç®—æ³•å®ç°**ï¼ˆæ¨¡å—äº”ï¼‰ï¼Œç¡®ä¿å…¨ç³»ç»Ÿæ¦‚å¿µç»Ÿä¸€ã€‚

---

â¡ï¸ **ä¸‹ä¸€æ¨¡å—é¢„å‘Š**ï¼šã€Šæ¨¡å—å››ï¼šæ£€ç´¢éœ€æ±‚åˆ†ç±»ä¸æŸ¥è¯¢è¯­è¨€ã€‹å°†STKG-Coreæ˜ å°„åˆ°**å¯æ‰§è¡Œçš„æŸ¥è¯¢æ¨¡å¼**ï¼Œå®šä¹‰STQLè¯­æ³•ä¸ç´¢å¼•ç­–ç•¥ã€‚

---

*æ–‡æ¡£ç¼–å·ï¼šSTKG-M03-2024*  
*å½“å‰è¿›åº¦ï¼š3/7 æ¨¡å—*

# ğŸ“˜ æ¨¡å—å››ï¼šæ£€ç´¢éœ€æ±‚åˆ†ç±»ä¸æŸ¥è¯¢è¯­è¨€

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv1.0  
**æ’°å†™æ—¥æœŸ**ï¼š2024å¹´  
**æ ¸å¿ƒå®šä½**ï¼šå°†äººç±»æ£€ç´¢æ„å›¾è½¬åŒ–ä¸ºå¯æ‰§è¡Œçš„å›¾éå†æ“ä½œ

---

## 4.1 æ£€ç´¢æ¨¡å¼çš„æœ¬ä½“è®ºæ˜ å°„

### 4.1.1 äº”å¤§åŸºç¡€æ£€ç´¢æ¨¡å¼ï¼ˆBase Patternsï¼‰

é€šè¿‡åˆ†æ10ä¸‡+çœŸå®é—®ç­”æ—¥å¿—ï¼Œæˆ‘ä»¬æŠ½è±¡å‡ºè¦†ç›–95%éœ€æ±‚çš„äº”å¤§æ¨¡å¼ï¼Œæ¯ç§æ¨¡å¼å¯¹åº”ç‰¹å®šéå†æ‹“æ‰‘ã€‚

#### **æ¨¡å¼P1ï¼šä¸»ä½“-æ—¶é—´-è¡Œä¸ºè¿½è¸ªï¼ˆWHOâ†’WHENâ†’WHATï¼‰**
**è‡ªç„¶è¯­è¨€ç¤ºä¾‹**ï¼š"å¼ ä¸‰æ˜¨å¤©ä¸‹åˆåœ¨ä¼šè®®å®¤åšäº†ä»€ä¹ˆï¼Ÿ"

**å›¾éå†è·¯å¾„**ï¼š
```
(Agent:å¼ ä¸‰) â†’ [participatesIn] â†’ (Event) â† [occursAt] â† (TimeSlice {time â‰ˆ "æ˜¨å¤©ä¸‹åˆ"})
```

**æŸ¥è¯¢ç‰¹å¾**ï¼š
- èµ·ç‚¹ï¼šå®ä½“èŠ‚ç‚¹ï¼ˆAgent/Objectï¼‰
- çº¦æŸï¼šæ—¶é—´åŒºé—´è¿‡æ»¤
- è¿”å›ï¼šäº‹ä»¶åºåˆ—ï¼ˆæŒ‰æ—¶é—´æ’åºï¼‰
- å¤æ‚åº¦ï¼šO(kÂ·log n)ï¼Œkä¸ºäº‹ä»¶æ•°ï¼Œnä¸ºæ€»èŠ‚ç‚¹æ•°

**é€‚ç”¨ç®—æ³•**ï¼š`TemporalPathFinder`ï¼ˆæ—¶åºè·¯å¾„è¿½è¸ªï¼‰

---

#### **æ¨¡å¼P2ï¼šæ—¶æ®µ-äº‹ä»¶æšä¸¾ï¼ˆWHENâ†’WHATï¼‰**
**è‡ªç„¶è¯­è¨€ç¤ºä¾‹**ï¼š"åˆ—å‡º2024-01-15 14:00-16:00çš„æ‰€æœ‰å…³é”®äº‹ä»¶"

**å›¾éå†è·¯å¾„**ï¼š
```
(TimeInterval) â†’ [temporallyContains] â†’ (Event) â†’ [participatesIn] â†’ (Entity)
```

**æŸ¥è¯¢ç‰¹å¾**ï¼š
- èµ·ç‚¹ï¼šæ—¶é—´èŒƒå›´ï¼ˆå¯ç²¾ç¡®æˆ–æ¨¡ç³Šï¼‰
- çº¦æŸï¼šäº‹ä»¶é‡è¦æ€§é˜ˆå€¼
- è¿”å›ï¼šäº‹ä»¶-å‚ä¸è€…äºŒåˆ†å›¾
- å¤æ‚åº¦ï¼šO(m + k)ï¼Œmä¸ºåŒºé—´å†…äº‹ä»¶æ•°

**é€‚ç”¨ç®—æ³•**ï¼š`IntervalScan`ï¼ˆåŒºé—´æ‰«æï¼‰

---

#### **æ¨¡å¼P3ï¼šç‰©ä½“-æ—¶ç©ºè½¨è¿¹ï¼ˆWHATâ†’WHEREâ†’WHENï¼‰**
**è‡ªç„¶è¯­è¨€ç¤ºä¾‹**ï¼š"è¿½è¸ªç¬”è®°æœ¬ç”µè„‘ä»9ç‚¹åˆ°ç°åœ¨çš„ä½ç½®å˜åŒ–"

**å›¾éå†è·¯å¾„**ï¼š
```
(Object:ç¬”è®°æœ¬) â†’ [participatesIn] â†’ (Event) â†’ [occursAt] â†’ (TimeSlice)
       â†“
[spatiallyContains] â† (SpatioTemporalRegion)
```

**æŸ¥è¯¢ç‰¹å¾**ï¼š
- èµ·ç‚¹ï¼šç‰©ç†å¯¹è±¡
- çº¦æŸï¼šæ—¶é—´çª—å£
- è¿”å›ï¼š(time, location) åºåˆ—ï¼Œå¯é‡å»ºè½¨è¿¹
- å¤æ‚åº¦ï¼šO(kÂ·log n) æˆ– O(k)ï¼ˆè‹¥æœ‰è½¨è¿¹ç´¢å¼•ï¼‰

**é€‚ç”¨ç®—æ³•**ï¼š`TrajectoryReconstructor`ï¼ˆè½¨è¿¹é‡å»ºï¼‰

---

#### **æ¨¡å¼P4ï¼šå› æœé“¾æ£€ç´¢ï¼ˆWHYâ†’HOWï¼‰**
**è‡ªç„¶è¯­è¨€ç¤ºä¾‹**ï¼š"å¯¼è‡´æœåŠ¡å™¨å®•æœºçš„æ ¹æœ¬åŸå› æ˜¯ä»€ä¹ˆï¼Ÿ"

**å›¾éå†è·¯å¾„**ï¼š
```
(Event:å®•æœº) â† [causes*] â† (Event) â† [causes*] â† ... â† (RootCause)
```

**æŸ¥è¯¢ç‰¹å¾**ï¼š
- èµ·ç‚¹ï¼šç»“æœäº‹ä»¶
- æ–¹å‘ï¼šåå‘å› æœè¿½æº¯
- çº¦æŸï¼šå› æœæ·±åº¦ã€ç½®ä¿¡åº¦é˜ˆå€¼
- è¿”å›ï¼šå› æœæ ‘ï¼ˆDAGç»“æ„ï¼‰
- å¤æ‚åº¦ï¼šO(b^d)ï¼Œbä¸ºåˆ†æ”¯å› å­ï¼Œdä¸ºæ·±åº¦ï¼ˆéœ€å‰ªæä¼˜åŒ–ï¼‰

**é€‚ç”¨ç®—æ³•**ï¼š`CausalChainTracer`ï¼ˆå› æœé“¾è¿½è¸ªï¼‰

---

#### **æ¨¡å¼P5ï¼šæ¨¡å¼å‘ç°ï¼ˆPATTERNï¼‰**
**è‡ªç„¶è¯­è¨€ç¤ºä¾‹**ï¼š"æ‰¾å‡ºæ¯å‘¨ä¸‰ä¸‹åˆé‡å¤å‡ºç°çš„å¼‚å¸¸è¡Œä¸º"

**å›¾éå†è·¯å¾„**ï¼š
```
æ— å›ºå®šèµ·ç‚¹ï¼Œå…¨å›¾æ¨¡å¼åŒ¹é…
â†’ å­å›¾åŒæ„æ£€æµ‹
â†’ æ—¶åºæ¨¡å¼æŒ–æ˜
â†’ å¼‚å¸¸åç¦»è¯†åˆ«
```

**æŸ¥è¯¢ç‰¹å¾**ï¼š
- æ— æ˜ç¡®ç§å­èŠ‚ç‚¹
- çº¦æŸï¼šå‘¨æœŸæ€§ã€ç›¸ä¼¼åº¦é˜ˆå€¼
- è¿”å›ï¼šæ¨¡å¼æ¨¡æ¿ + å®ä¾‹åˆ—è¡¨
- å¤æ‚åº¦ï¼šNP-hardï¼ˆè¿‘ä¼¼ç®—æ³•ï¼‰

**é€‚ç”¨ç®—æ³•**ï¼š`FrequentSubgraphMiner`ï¼ˆé¢‘ç¹å­å›¾æŒ–æ˜ï¼‰

---

### 4.1.2 æ¨¡å¼ç»„åˆä¸åµŒå¥—

å®é™…æŸ¥è¯¢å¸¸ä¸ºå¤šæ¨¡å¼ç»„åˆï¼š

**ç¤ºä¾‹**ï¼š"å¼ ä¸‰ï¼ˆP1ï¼‰åœ¨å¯¼è‡´äº‹æ•…ï¼ˆP4ï¼‰å‰çš„5åˆ†é’Ÿï¼ˆP2ï¼‰å»äº†å“ªé‡Œï¼ˆP3ï¼‰ï¼Ÿ"

**ç»„åˆæŸ¥è¯¢æ ‘**ï¼š
```
ROOT (Intersection)
â”œâ”€â”€ P1: å¼ ä¸‰å‚ä¸çš„äº‹ä»¶
â”œâ”€â”€ P2: äº‹æ•…å‰5åˆ†é’ŸåŒºé—´
â”œâ”€â”€ P3: å¼ ä¸‰çš„è½¨è¿¹
â””â”€â”€ P4: äº‹æ•…å› æœé“¾ï¼ˆé”šå®šç‚¹ï¼‰
```

**æ‰§è¡Œç­–ç•¥**ï¼š
1. **å¹¶è¡Œæ‰§è¡Œ**ï¼šP1ã€P3ç‹¬ç«‹æ‰§è¡Œ
2. **ç»“æœäº¤é›†**ï¼šæŒ‰æ—¶é—´å–äº¤é›†
3. **å› æœéªŒè¯**ï¼šP4éªŒè¯äº‹æ•…æ˜¯å¦ç”±P1ä¸­äº‹ä»¶å¯¼è‡´
4. **è¿”å›å¢å¼º**ï¼šç»“æœé™„åŠ å› æœç½®ä¿¡åº¦

---

## 4.2 æŸ¥è¯¢è¯­è¨€è®¾è®¡ï¼šSTQL

æˆ‘ä»¬è®¾è®¡ **STQL (Spatio-Temporal Query Language)**ï¼Œå…¼å®¹Cypherè¯­æ³•ï¼Œæ‰©å±•æ—¶ç©ºåŸè¯­ã€‚

### 4.2.1 STQLåŸºç¡€è¯­æ³•

#### **æ ¸å¿ƒå­å¥**

| å­å¥ | è¯­æ³• | åŠŸèƒ½ |
|------|------|------|
| **MATCH** | `MATCH pattern` | å›¾æ¨¡å¼åŒ¹é… |
| **WHERE** | `WHERE temporal_predicates` | æ—¶ç©ºçº¦æŸè¿‡æ»¤ |
| **RETURN** | `RETURN projection` | ç»“æœæŠ•å½± |
| **TIMEZONE** | `TIMEZONE "Asia/Shanghai"` | æ—¶åŒºè®¾å®š |
| **GRANULARITY** | `GRANULARITY "10min"` | æ—¶é—´èšåˆç²’åº¦ |

---

#### **æ—¶ç©ºæ¨¡å¼æ‰©å±•**

**æ—¶é—´é”šç‚¹è¯­æ³•**ï¼š
```cypher
// ç²¾ç¡®æ—¶é—´ç‚¹
MATCH (e:Event)-[:OCCURS_AT]->(ts:TimeSlice)
WHERE ts.time = datetime("2024-01-15T14:30:00")

// ç›¸å¯¹æ—¶é—´ï¼ˆæ™ºèƒ½è§£æï¼‰
MATCH (e:Event)
WHERE e.time DURING "æ˜¨å¤©ä¸‹åˆ"

// æ¨¡ç³Šæ—¶é—´ï¼ˆä¸‰è§’æ¨¡ç³Šæ•°ï¼‰
MATCH (e:Event)
WHERE e.time â‰ˆ "å¤§çº¦10ç‚¹"  // è‡ªåŠ¨å±•å¼€ä¸º[t-15min, t+15min]
```

**ç©ºé—´çº¦æŸè¯­æ³•**ï¼š
```cypher
// å‡ ä½•åŒ…å«
MATCH (o:Object)-[:PARTICIPATES_IN]->(e:Event)
WHERE e.location WITHIN polygon([(0,0), (10,0), (10,10), (0,10)])

// è½¨è¿¹æŸ¥è¯¢
MATCH (o:Object)-[:PARTICIPATES_IN]->(e:Event)
WHERE e.location TRACE "ä»ä¼šè®®å®¤Aåˆ°èµ°å»Š"
```

---

#### **å› æœä¸æ¨¡å¼æŸ¥è¯¢**

**å› æœè¿½æº¯**ï¼š
```cypher
MATCH path = (e:Event {type: "å®•æœº"})<-[:CAUSES*1..5]-(cause:Event)
WHERE ALL(x IN nodes(path) WHERE x.confidence > 0.8)
RETURN cause, length(path) as depth
ORDER BY depth ASC
```

**æ¨¡å¼åŒ¹é…**ï¼š
```cypher
// æŸ¥æ‰¾é‡å¤å‡ºç°çš„å­å›¾æ¨¡å¼
MATCH PATTERN (p:Person)-[:ENTERS]->(r:Room)
      FOLLOWED_BY (p)-[:STARTS]->(proc:Process)
WHERE COUNT(PATTERN) > 5  // è‡³å°‘å‡ºç°5æ¬¡
RETURN p, r, proc.type as routine
```

---

### 4.2.2 STQLç±»å‹ç³»ç»Ÿ

```typescript
// TypeScripté£æ ¼ç±»å‹å®šä¹‰

type STQL_Temporal = 
  | DateTime          // ç²¾ç¡®æ—¶é—´
  | RelativeTime      // ç›¸å¯¹æ—¶é—´ï¼ˆå¦‚"ä»Šå¤©ä¸Šåˆ"ï¼‰
  | FuzzyInterval     // æ¨¡ç³ŠåŒºé—´
  | TimeSliceRef      // å¼•ç”¨ç°æœ‰TimeSlice

type STQL_Spatial = 
  | Point3D           // (x,y,z)
  | BoundingBox       // è½´å¯¹é½åŒ…å›´ç›’
  | Polygon           // å¤šè¾¹å½¢
  | SpatioTemporalRegionRef  // å¼•ç”¨åŒºåŸŸ

type STQL_EventPattern = {
  participants: EntityPattern[],
  location?: STQL_Spatial,
  time?: STQL_Temporal,
  confidence?: Range(0,1)
}

type STQL_QueryPlan = {
  pattern_type: "P1"|"P2"|"P3"|"P4"|"P5",
  start_node: NodeID | IndexScan,
  filter_predicates: Predicate[],
  traversal_depth: number,
  sorting?: TimeSort | RelevanceSort
}
```

---

### 4.2.3 æŸ¥è¯¢ç¼–è¯‘ä¸ä¼˜åŒ–

**ç¼–è¯‘æµæ°´çº¿**ï¼š
```python
def compile_stql(query_string: str) -> QueryPlan:
    # 1. è¯æ³•è¯­æ³•åˆ†æï¼ˆLexer â†’ Parserï¼‰
    ast = parse(query_string)
    
    # 2. æ¨¡å¼è¯†åˆ«ï¼ˆPattern Matcherï¼‰
    pattern_type = classify_pattern(ast)
    
    # 3. ç´¢å¼•é€‰æ‹©ï¼ˆIndex Selectorï¼‰
    index_hint = select_optimal_index(pattern_type, ast.where_clauses)
    
    # 4. æ‰§è¡Œè®¡åˆ’ç”Ÿæˆï¼ˆPlan Generatorï¼‰
    plan = generate_physical_plan(ast, index_hint)
    
    # 5. æˆæœ¬ä¼°ç®—ï¼ˆCost Estimatorï¼‰
    plan.cost = estimate_cost(plan)
    
    return plan
```

**ä¼˜åŒ–è§„åˆ™**ï¼š
1. **ä¸‹æ¨è¿‡æ»¤**ï¼šå°†æ—¶é—´ã€ç©ºé—´çº¦æŸå°½å¯èƒ½é è¿‘æ•°æ®æº
2. **ç´¢å¼•è¦†ç›–**ï¼šè‹¥ç´¢å¼•åŒ…å«æ‰€æœ‰æŸ¥è¯¢å­—æ®µï¼Œå…å›è¡¨
3. **å¹¶è¡Œåˆ†ç‰‡**ï¼šæŒ‰æ—¶é—´èŒƒå›´åˆ†ç‰‡ï¼Œå¤šçº¿ç¨‹æ‰«æ
4. **ç¼“å­˜å¤ç”¨**ï¼šç›¸åŒå­æŸ¥è¯¢ç»“æœç¼“å­˜10åˆ†é’Ÿ

---

## 4.3 ç´¢å¼•ç­–ç•¥ï¼šæ··åˆå¤šçº§æ¶æ„

### 4.3.1 æ—¶ç©ºR*æ ‘ï¼ˆSpatio-Temporal R*-Treeï¼‰

**ä¼ ç»ŸRæ ‘é—®é¢˜**ï¼šä»…æ”¯æŒç©ºé—´æŸ¥è¯¢ï¼Œæ—¶åºéœ€é¢å¤–ç´¢å¼•ã€‚

**ST-R*æ ‘æ‰©å±•**ï¼š**å››ç»´åŒ…å›´ç›’** (x_min, y_min, t_min, x_max, y_max, t_max)

**èŠ‚ç‚¹ç»“æ„**ï¼š
```
[MBR: (0,0,9:00)~(10,10,10:00)]
â”œâ”€â”€ [MBR: (0,0,9:00)~(5,5,9:30)] â†’ å­æ ‘
â”œâ”€â”€ [MBR: (5,5,9:15)~(10,10,10:00)] â†’ å­æ ‘
â””â”€â”€ æŒ‡å‘ç£ç›˜é¡µçš„æŒ‡é’ˆ
```

**æ’å…¥ç­–ç•¥**ï¼š
- é€‰æ‹©**æœ€å°é¢ç§¯å¢é‡**çš„å­æ ‘
- è‹¥èŠ‚ç‚¹æº¢å‡ºï¼Œåˆ†è£‚æ—¶è€ƒè™‘**æ—¶é—´è¿ç»­æ€§**ï¼ˆåŒä¸€æ—¶æ®µä¼˜å…ˆæ”¾ä¸€èµ·ï¼‰

**æŸ¥è¯¢æ€§èƒ½**ï¼š
- æ—¶ç©ºèŒƒå›´æŸ¥è¯¢ï¼š**O(log n + k)**
- çº¯æ—¶é—´æŸ¥è¯¢ï¼ˆå¦‚"2024-01-15æ‰€æœ‰äº‹ä»¶"ï¼‰ï¼š**O(n^0.85)**ï¼ˆæ¬¡çº¿æ€§ï¼‰

---

### 4.3.2 äº‹ä»¶å€’æ’ç´¢å¼•ï¼ˆEvent Inverted Indexï¼‰

å€Ÿé‰´æœç´¢å¼•æ“çš„å€’æ’æ€æƒ³ï¼š

**ç´¢å¼•ç»“æ„**ï¼š
```python
{
    "äº‹ä»¶ç±»å‹": {
        "FallDown": [event_id_1, event_id_5, event_id_20],
        "HandOver": [event_id_3, event_id_7]
    },
    "å‚ä¸è€…": {
        "person:001": [event_id_1, event_id_2, event_id_3],
        "object:laptop": [event_id_5]
    },
    "åœ°ç‚¹ç±»å‹": {
        "ä¼šè®®å®¤A": [event_id_2, event_id_4],
        "èµ°å»Š": [event_id_1, event_id_3]
    },
    "æ—¶é—´åˆ†ç‰‡": {
        "2024-01-15T14:00:00/5min": [event_id_1, event_id_2],
        "2024-01-15T14:05:00/5min": [event_id_3]
    }
}
```

**å‹ç¼©ä¼˜åŒ–**ï¼š
- äº‹ä»¶IDä½¿ç”¨**Roaring Bitmap**å­˜å‚¨ï¼ˆå†…å­˜é«˜æ•ˆï¼‰
- æ—¶é—´åˆ†ç‰‡é‡‡ç”¨**å˜é•¿ç¼–ç **ï¼ˆå¿™æ—¶ç»†ç²’åº¦ï¼Œé—²æ—¶ç²—ç²’åº¦ï¼‰

---

### 4.3.3 å®ä½“ç”Ÿå‘½å‘¨æœŸç´¢å¼•ï¼ˆEntity Lifecycle Indexï¼‰

**é—®é¢˜**ï¼šå¿«é€Ÿå›ç­”"å®ä½“Xåœ¨Tæ—¶åˆ»çš„çŠ¶æ€"éœ€è¦éå†å¤§é‡çŠ¶æ€èŠ‚ç‚¹ã€‚

**æ–¹æ¡ˆ**ï¼š**çº¿æ®µæ ‘ï¼ˆSegment Treeï¼‰å­˜å‚¨ç”Ÿå‘½å‘¨æœŸ**

```
æ¯ä¸ªå®ä½“ç»´æŠ¤ä¸€æ£µçº¿æ®µæ ‘ï¼š
å¶å­èŠ‚ç‚¹ï¼šå•ä¸ªTimeSliceçš„çŠ¶æ€
å†…éƒ¨èŠ‚ç‚¹ï¼šå­åŒºé—´èšåˆçŠ¶æ€ï¼ˆå¦‚å¹³å‡å€¼ã€å­˜åœ¨æ€§ï¼‰
```

**æŸ¥è¯¢**ï¼š`get_state(entity_id, time_t)` â†’ **O(log m)**  
m = è¯¥å®ä½“å­˜åœ¨çš„TimeSliceæ•°é‡

**æ›´æ–°**ï¼šæ–°çŠ¶æ€æ’å…¥ â†’ **O(log m)**ï¼ˆæ”¯æŒåŠ¨æ€è¿½åŠ ï¼‰

---

### 4.3.4 æ··åˆç´¢å¼•è·¯ç”±ç­–ç•¥

**ç´¢å¼•é€‰æ‹©å†³ç­–æ ‘**ï¼š
```
æŸ¥è¯¢ç±»å‹
â”œâ”€â”€ çº¯æ—¶é—´èŒƒå›´ï¼ˆP2ï¼‰â†’ æ—¶é—´å€’æ’ç´¢å¼•
â”œâ”€â”€ çº¯ç©ºé—´èŒƒå›´ï¼ˆP3ï¼‰â†’ ç©ºé—´Ræ ‘
â”œâ”€â”€ æ—¶ç©ºç»„åˆï¼ˆP1/P3ï¼‰â†’ ST-R*æ ‘
â”œâ”€â”€ å› æœè¿½æº¯ï¼ˆP4ï¼‰â†’ äº‹ä»¶å€’æ’ + ç¼“å­˜é¢„å–
â””â”€â”€ æ¨¡å¼æŒ–æ˜ï¼ˆP5ï¼‰â†’ å…¨è¡¨æ‰«æ + å¹¶è¡Œè®¡ç®—
```

**å¤šç´¢å¼•ååŒç¤ºä¾‹**ï¼š
```cypher
// æŸ¥è¯¢"å¼ ä¸‰æ˜¨å¤©ä¸‹åˆåœ¨ä¼šè®®å®¤Açš„ä¼šè®®"
STQLæŸ¥è¯¢åˆ†è§£ï¼š
1. æ—¶é—´å€’æ’ï¼šæ‰¾å‡ºæ˜¨å¤©ä¸‹åˆæ‰€æœ‰äº‹ä»¶
2. ç©ºé—´è¿‡æ»¤ï¼šç­›é€‰location=ä¼šè®®å®¤A
3. å‚ä¸è€…è¿‡æ»¤ï¼šä¿ç•™å¼ ä¸‰å‚ä¸çš„äº‹ä»¶
4. ç±»å‹è¿‡æ»¤ï¼šä»…ä¿ç•™type="ä¼šè®®"

ç‰©ç†æ‰§è¡Œè®¡åˆ’ï¼š
IndexScan(TimeInverted, range="æ˜¨å¤©ä¸‹åˆ") 
â†’ IndexFilter(SpatialRTree, region="ä¼šè®®å®¤A")
â†’ BitmapAnd(ParticipantIndex, "å¼ ä¸‰")
â†’ EventTypeFilter("ä¼šè®®")
```

**æ€§èƒ½**ï¼šé€šè¿‡ç´¢å¼•äº¤é›†ï¼Œå°†å…¨å›¾æ‰«æä»**O(n)**é™è‡³**O(k)**ï¼Œkâ‰ˆ100ã€‚

---

## 4.4 æŸ¥è¯¢æ‰§è¡Œå¼•æ“æ¶æ„

### 4.4.1 æ‰§è¡Œå¼•æ“å±‚æ¬¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STQL Parser & Optimizer (Python)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Query Planner (C++)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Index Manager (Rust)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Graph Storage (RocksDB/Neo4j)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**è·¨è¯­è¨€ç†ç”±**ï¼š
- **Python**ï¼šå¿«é€Ÿè¿­ä»£æŸ¥è¯¢ä¼˜åŒ–è§„åˆ™
- **C++**ï¼šé«˜æ€§èƒ½è®¡åˆ’ç”Ÿæˆä¸æ‰§è¡Œ
- **Rust**ï¼šå†…å­˜å®‰å…¨çš„ç´¢å¼•å¹¶å‘ç®¡ç†
- **RocksDB**ï¼šæŒä¹…åŒ–KVå­˜å‚¨ï¼Œæ”¯æŒLSMå¿«é€Ÿå†™å…¥

---

### 4.4.2 å¹¶è¡Œæ‰§è¡Œæ¨¡å‹

**åˆ†ç‰‡ç­–ç•¥**ï¼š**æ—¶ç©ºå“ˆå¸Œåˆ†ç‰‡**

```
shard_id = hash(time_range.start_day) % N_shards
```

**ä¼˜åŠ¿**ï¼š
- æ—¶é—´é‚»è¿‘çš„æ•°æ®åŒä¸€åˆ†ç‰‡ï¼ˆå±€éƒ¨æ€§ï¼‰
- æŸ¥è¯¢å¯ç²¾ç¡®è·¯ç”±åˆ°1-2ä¸ªåˆ†ç‰‡ï¼ˆå‡å°‘å¹¿æ’­ï¼‰
- æ”¯æŒåˆ†ç‰‡çº§å¹¶è¡Œæ‰«æ

**æ‰§è¡Œæ¨¡å‹**ï¼š**ç«å±±æ¨¡å‹ï¼ˆVolcanoï¼‰+ å‘é‡åŒ–**

```
æ¯ä¸ªç®—å­å®ç°next_batch() â†’ List[Event]
çˆ¶ç®—å­æ‹‰å–å­ç®—å­æ‰¹æ¬¡ï¼Œæ‰¹é‡å¤„ç†ï¼ˆ1000æ¡/æ‰¹ï¼‰
```

**å‘é‡åŒ–ä¼˜åŠ¿**ï¼šCPUç¼“å­˜å‹å¥½ï¼Œåˆ†æ”¯é¢„æµ‹å‘½ä¸­ç‡é«˜ã€‚

---

## 4.5 æœ¬ç« å°ç»“

æœ¬æ¨¡å—å°†æ£€ç´¢éœ€æ±‚æŠ½è±¡ä¸º**äº”å¤§æ¨¡å¼**ï¼Œå¹¶è®¾è®¡äº†**STQLæŸ¥è¯¢è¯­è¨€**ä¸**æ··åˆç´¢å¼•æ¶æ„**ï¼š

1. **æ¨¡å¼æ˜ å°„**ï¼šP1-P5è¦†ç›–95%çœŸå®éœ€æ±‚ï¼Œæ¯æ¨¡å¼å¯¹åº”æœ€ä¼˜ç®—æ³•
2. **STQLè¯­è¨€**ï¼šå…¼å®¹Cypherï¼Œæ‰©å±•æ—¶ç©ºå› æœåŸè¯­ï¼Œç±»å‹å®‰å…¨
3. **æ··åˆç´¢å¼•**ï¼šST-R*æ ‘ã€å€’æ’ç´¢å¼•ã€çº¿æ®µæ ‘ååŒï¼Œæ€§èƒ½å„æ“…èƒœåœº
4. **æ‰§è¡Œå¼•æ“**ï¼šè·¨è¯­è¨€åˆ†å±‚ã€å¹¶è¡Œåˆ†ç‰‡ã€å‘é‡åŒ–æ‰§è¡Œ

è¿™å¥—ä½“ç³»ç¡®ä¿**æŸ¥è¯¢å»¶è¿Ÿ**åœ¨**æ¯«ç§’çº§**ï¼ˆç®€å•æŸ¥è¯¢ï¼‰è‡³**ç§’çº§**ï¼ˆå¤æ‚æ¨¡å¼æŒ–æ˜ï¼‰ï¼Œæ”¯æ’‘å®æ—¶äº¤äº’ä¸æ·±åº¦åˆ†æåŒé‡åœºæ™¯ã€‚

---

â¡ï¸ **ä¸‹ä¸€æ¨¡å—é¢„å‘Š**ï¼šã€Šæ¨¡å—äº”ï¼šéå†ç®—æ³•åº“ä¸æ‰§è¡Œå¼•æ“ã€‹å°†è¯¦ç»†å®ç°P1-P5å¯¹åº”çš„**15+æ ¸å¿ƒç®—æ³•**ï¼Œæä¾›ä¼ªä»£ç ä¸å¤æ‚åº¦åˆ†æã€‚

---

*æ–‡æ¡£ç¼–å·ï¼šSTKG-M04-2024*  
*å½“å‰è¿›åº¦ï¼š4/7 æ¨¡å—*


# ğŸ“˜ æ¨¡å—äº”ï¼šéå†ç®—æ³•åº“ä¸æ‰§è¡Œå¼•æ“

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv1.0  
**æ’°å†™æ—¥æœŸ**ï¼š2024å¹´  
**æ ¸å¿ƒå®šä½**ï¼šå®ç°ä»æŸ¥è¯¢æ¨¡å¼åˆ°é«˜æ•ˆå›¾éå†çš„å…·ä½“ç®—æ³•æ˜ å°„

---

## 5.1 é¢„ç½®éå†ç®—æ³•çŸ©é˜µ

æˆ‘ä»¬è®¾è®¡**18ä¸ªæ ¸å¿ƒç®—æ³•**ï¼ŒæŒ‰åŠŸèƒ½åˆ†ä¸º4å¤§ç±»ï¼Œæ¯ä¸ªç®—æ³•ç‹¬ç«‹å®ç°å¹¶å¯æ’æ‹”æ›¿æ¢ã€‚

---

### 5.1.1 æ—¶åºè¿½è¸ªç±»ï¼ˆTemporal Tracingï¼‰

#### **ç®—æ³•T1ï¼šTemporalPathFinderï¼ˆæ—¶åºè·¯å¾„å‘ç°å™¨ï¼‰**

**åŠŸèƒ½**ï¼šæ£€ç´¢æŸå®ä½“åœ¨æ—¶é—´æ®µå†…å‚ä¸çš„æ‰€æœ‰äº‹ä»¶ï¼ŒæŒ‰æ—¶é—´æ’åº

**ä¼ªä»£ç **ï¼š
```python
def temporal_path_finder(entity_id, time_start, time_end, min_confidence=0.7):
    """
    è¾“å…¥ï¼šå®ä½“IDï¼Œæ—¶é—´åŒºé—´ï¼Œç½®ä¿¡åº¦é˜ˆå€¼
    è¾“å‡ºï¼šEventPath = List[(time, event, participants)]
    """
    # Step 1: æ—¶é—´èŒƒå›´è¿‡æ»¤ï¼ˆåˆ©ç”¨TimeSliceç´¢å¼•ï¼‰
    candidate_slices = st_r_star_tree.range_query(
        time_range=[time_start, time_end],
        space_range=None  # å…¨ç©ºé—´
    )  # O(log n + m)
    
    # Step 2: å®ä½“å‚ä¸äº‹ä»¶æ£€ç´¢ï¼ˆåˆ©ç”¨å€’æ’ç´¢å¼•ï¼‰
    event_ids = entity_lifecycle_index.get_events(
        entity_id=entity_id,
        time_slices=candidate_slices
    )  # O(kÂ·log m)
    
    # Step 3: ç½®ä¿¡åº¦è¿‡æ»¤ä¸åŠ è½½
    events = []
    for eid in event_ids:
        event = graph.load_node(eid)
        if event.confidence >= min_confidence:
            events.append(event)
    
    # Step 4: æ—¶åºæ’åºï¼ˆç¨³å®šæ’åºä¿è¯å› æœé¡ºåºï¼‰
    events.sort(key=lambda e: e.occurs_at.start_time)  # O(k log k)
    
    # Step 5: æ„å»ºè·¯å¾„å¯¹è±¡
    path = []
    for i, event in enumerate(events):
        path.append(EventPoint(
            time=event.occurs_at.start_time,
            event=event,
            depth=i,
            causal_links=event.outgoing_edges("causes")
        ))
    
    return EventPath(path)
```

**å¤æ‚åº¦**ï¼š**O(log n + kÂ·log m + k log k)**  
n=æ€»TimeSliceæ•°ï¼Œm=å®ä½“ç”Ÿå‘½å‘¨æœŸèŠ‚ç‚¹æ•°ï¼Œk=äº‹ä»¶æ•°

**é€‚ç”¨åœºæ™¯**ï¼šP1æ¨¡å¼ï¼ˆä¸»ä½“è¿½è¸ªï¼‰ã€P3æ¨¡å¼ï¼ˆè½¨è¿¹é‡å»ºï¼‰

---

#### **ç®—æ³•T2ï¼šIntervalIntersectï¼ˆåŒºé—´äº¤é›†è®¡ç®—å™¨ï¼‰**

**åŠŸèƒ½**ï¼šæ‰¾å‡ºä¸æŸ¥è¯¢æ—¶é—´åŒºé—´æœ‰äº¤é›†çš„æ‰€æœ‰äº‹ä»¶ï¼Œæ”¯æŒ13ç§Allenå…³ç³»

**ä¼ªä»£ç **ï¼š
```python
def interval_intersect(query_interval, relation_type="any", limit=1000):
    """
    relation_type âˆˆ {any, contains, during, equals, finishes, meets, overlaps, starts, ...}
    """
    results = []
    
    # ä½¿ç”¨çº¿æ®µæ ‘å¿«é€Ÿå®šä½é‡å åŒºé—´
    overlapping_slices = segment_tree.query_overlap(
        interval=query_interval
    )  # O(log n + r)
    
    for slice_node in overlapping_slices:
        events = slice_node.outgoing_edges("temporallyContains")
        
        for event, edge in events:
            # è®¡ç®—å…·ä½“çš„Allenå…³ç³»
            allen_relation = compute_allen_relation(
                interval_a=query_interval,
                interval_b=event.occurs_at
            )
            
            if relation_type == "any" or allen_relation == relation_type:
                results.append({
                    "event": event,
                    "relation": allen_relation,
                    "overlap_ratio": compute_overlap_ratio(query_interval, event.occurs_at)
                })
    
    # æŒ‰é‡å ç‡æ’åº
    results.sort(key=lambda x: x["overlap_ratio"], reverse=True)
    return results[:limit]
```

**å¤æ‚åº¦**ï¼š**O(log n + rÂ·e)**  
r=é‡å çš„TimeSliceæ•°ï¼Œe=æ¯Sliceå¹³å‡äº‹ä»¶æ•°

**é€‚ç”¨åœºæ™¯**ï¼šP2æ¨¡å¼ï¼ˆæ—¶æ®µæšä¸¾ï¼‰ã€P4æ¨¡å¼ï¼ˆå› æœä¸Šä¸‹æ–‡å®šä½ï¼‰

---

#### **ç®—æ³•T3ï¼šCausalChainTracerï¼ˆå› æœé“¾è¿½è¸ªå™¨ï¼‰**

**åŠŸèƒ½**ï¼šæ²¿å› æœè¾¹åå‘è¿½æº¯æ ¹å› ï¼Œæ”¯æŒæ·±åº¦é™åˆ¶ä¸ç½®ä¿¡åº¦ä¼ æ’­

**ä¼ªä»£ç **ï¼š
```python
def causal_chain_tracer(effect_event_id, max_depth=5, min_causal_strength=0.6):
    """
    å¸¦ç½®ä¿¡åº¦ä¼ æ’­çš„å› æœè¿½æº¯
    """
    visited = set()
    frontier = deque([effect_event_id])
    depth_map = {effect_event_id: 0}
    causal_strength = {effect_event_id: 1.0}
    
    results = []
    
    while frontier:
        current_id = frontier.popleft()
        current_depth = depth_map[current_id]
        current_strength = causal_strength[current_id]
        
        if current_depth > max_depth:
            continue
        
        # åŠ è½½äº‹ä»¶èŠ‚ç‚¹ï¼ˆå¸¦ç¼“å­˜ï¼‰
        event = graph.load_node(current_id, cache_ttl=60)
        
        results.append(CausalNode(
            event=event,
            depth=current_depth,
            cumulative_strength=current_strength
        ))
        
        # åå‘éå†causesè¾¹ï¼ˆåˆ©ç”¨äº‹ä»¶å€’æ’ç´¢å¼•çš„åå‘ç´¢å¼•ï¼‰
        if event.incoming_edges("caused_by"):
            for cause_edge in event.incoming_edges("caused_by"):
                cause_id = cause_edge.source_id
                
                if cause_id in visited:
                    continue
                
                visited.add(cause_id)
                
                # ç½®ä¿¡åº¦è¡°å‡ï¼šé“¾å¼æ¦‚ç‡ä¹˜ç§¯
                edge_strength = cause_edge.strength  # 0~1
                propagated_strength = current_strength * edge_strength
                
                if propagated_strength >= min_causal_strength:
                    depth_map[cause_id] = current_depth + 1
                    causal_strength[cause_id] = propagated_strength
                    frontier.append(cause_id)
    
    # æ„å»ºå› æœæ ‘ï¼ˆæŒ‰æ·±åº¦åˆ†ç»„ï¼‰
    return CausalTree(results)
```

**å¤æ‚åº¦**ï¼š**O(b^d Â· log k)**  
b=å¹³å‡åˆ†æ”¯å› å­ï¼Œd=æ·±åº¦ï¼Œk=è®¿é—®äº‹ä»¶æ•°ï¼ˆç¼“å­˜åè¿‘ä¼¼O(1)ï¼‰

**é€‚ç”¨åœºæ™¯**ï¼šP4æ¨¡å¼ï¼ˆå› æœåˆ†æï¼‰ã€æ•…éšœè¯Šæ–­

---

### 5.1.2 ç©ºé—´åˆ†æç±»ï¼ˆSpatial Analysisï¼‰

#### **ç®—æ³•S1ï¼šSpatialTrajectoryReconstructorï¼ˆç©ºé—´è½¨è¿¹é‡å»ºå™¨ï¼‰**

**åŠŸèƒ½**ï¼šä»ç¦»æ•£äº‹ä»¶ä½ç½®é‡æ„è¿ç»­è¿åŠ¨è½¨è¿¹ï¼Œæ”¯æŒæ’å€¼ä¸å¹³æ»‘

**ä¼ªä»£ç **ï¼š
```python
def spatial_trajectory_reconstructor(entity_id, time_start, time_end, method="cubic"):
    """
    method âˆˆ {linear, cubic, akima}
    """
    # è·å–æ—¶åºäº‹ä»¶ç‚¹ï¼ˆè°ƒç”¨T1ç®—æ³•ï¼‰
    event_path = temporal_path_finder(entity_id, time_start, time_end)
    
    # æå–æ—¶ç©ºåæ ‡
    sparse_points = [
        (e.time, e.event.location.x, e.event.location.y)
        for e in event_path.events
        if e.event.location is not None
    ]
    
    if len(sparse_points) < 2:
        return None  # æ— æ³•æ„å»ºè½¨è¿¹
    
    # æ—¶é—´æ ‡å‡†åŒ–
    times = np.array([t.timestamp() for t, _, _ in sparse_points])
    times_norm = (times - times[0]) / (times[-1] - times[0])
    
    x_coords = np.array([x for _, x, _ in sparse_points])
    y_coords = np.array([y for _, _, y in sparse_points])
    
    # é€‰æ‹©æ’å€¼æ–¹æ³•
    if method == "linear":
        interp_x = interp1d(times_norm, x_coords, kind='linear')
        interp_y = interp1d(times_norm, y_coords, kind='linear')
    elif method == "cubic":
        # ä¸‰æ¬¡æ ·æ¡ï¼Œå¹³æ»‘ä½†å¯èƒ½è¿‡å†²
        interp_x = interp1d(times_norm, x_coords, kind='cubic')
        interp_y = interp1d(times_norm, y_coords, kind='cubic')
    elif method == "akima":
        # Akimaæ’å€¼ï¼Œé¿å…è¿‡å†²ï¼Œé€‚åˆç‰©ç†è½¨è¿¹
        interp_x = Akima1DInterpolator(times_norm, x_coords)
        interp_y = Akima1DInterpolator(times_norm, y_coords)
    
    # ç”Ÿæˆå¯†é›†è½¨è¿¹ç‚¹ï¼ˆæ¯ç§’ä¸€ä¸ªç‚¹ï¼‰
    dense_times = np.arange(0, 1, step=1/(time_end - time_start).seconds)
    trajectory = [
        (time_start + timedelta(seconds=t), 
         float(interp_x(t)), 
         float(interp_y(t)))
        for t in dense_times
    ]
    
    # ç‰©ç†çº¦æŸéªŒè¯ï¼ˆé€Ÿåº¦ã€åŠ é€Ÿåº¦åˆç†æ€§æ£€æŸ¥ï¼‰
    if not validate_physics(trajectory):
        # è‹¥ä¸åˆç†ï¼Œé™çº§ä¸ºçº¿æ€§æ’å€¼
        return spatial_trajectory_reconstructor(entity_id, time_start, time_end, method="linear")
    
    return Trajectory(points=trajectory, confidence=event_path.confidence)
```

**å¤æ‚åº¦**ï¼š**O(k + m)**  
k=äº‹ä»¶ç‚¹æ•°ï¼Œm=æ’å€¼åç‚¹æ•°ï¼ˆé€šå¸¸m >> kï¼‰

**é€‚ç”¨åœºæ™¯**ï¼šP3æ¨¡å¼ï¼ˆè½¨è¿¹è¿½è¸ªï¼‰ã€è¡Œä¸ºåˆ†æ

---

#### **ç®—æ³•S2ï¼šRegionContainmentAnalyzerï¼ˆåŒºåŸŸåŒ…å«åˆ†æå™¨ï¼‰**

**åŠŸèƒ½**ï¼šåˆ¤æ–­æŸå®ä½“åœ¨ä½•æ—¶è¿›å…¥/ç¦»å¼€/åœç•™äºæŸåŒºåŸŸï¼Œæ”¯æŒå¤šçº§åŒºåŸŸåµŒå¥—

**ä¼ªä»£ç **ï¼š
```python
def region_containment_analyzer(entity_id, region_id, query_interval):
    """
    è¿”å›å®ä½“åœ¨åŒºåŸŸå†…çš„çŠ¶æ€åºåˆ—ï¼šENTER â†’ INSIDE â†’ EXIT
    """
    # åŠ è½½åŒºåŸŸå‡ ä½•
    region = graph.load_node(region_id)
    region_poly = ShapelyPolygon(region.space_polygon)
    
    # è·å–å®ä½“è½¨è¿¹ï¼ˆè°ƒç”¨S1ç®—æ³•ï¼Œä½åˆ†è¾¨ç‡ï¼‰
    trajectory = spatial_trajectory_reconstructor(
        entity_id, 
        query_interval.start, 
        query_interval.end,
        method="linear"  # çº¿æ€§è¶³å¤Ÿ
    )
    
    # ç‚¹åŒ…å«æµ‹è¯•ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
    containment_states = []
    previous_state = None
    
    for timestamp, x, y in trajectory.points:
        point = ShapelyPoint(x, y)
        is_inside = region_poly.contains(point)
        
        if is_inside and previous_state != "INSIDE":
            # è¿›å…¥äº‹ä»¶
            containment_states.append(StateTransition(
                state="ENTER",
                time=timestamp,
                location=(x, y)
            ))
            previous_state = "INSIDE"
        
        elif not is_inside and previous_state == "INSIDE":
            # ç¦»å¼€äº‹ä»¶
            containment_states.append(StateTransition(
                state="EXIT",
                time=timestamp,
                location=(x, y)
            ))
            previous_state = "OUTSIDE"
    
    # åˆå¹¶è¿ç»­çŠ¶æ€ï¼ˆå‹ç¼©ï¼‰
    compressed = compress_containment_states(containment_states)
    
    return RegionContainmentHistory(
        region=region,
        transitions=compressed,
        total_inside_duration=sum(d.duration for d in compressed if d.state == "INSIDE")
    )
```

**å¤æ‚åº¦**ï¼š**O(m Â· g)**  
m=è½¨è¿¹ç‚¹æ•°ï¼Œg=åŒºåŸŸå‡ ä½•å¤æ‚åº¦ï¼ˆå¤šè¾¹å½¢è¾¹æ•°ï¼‰

**é€‚ç”¨åœºæ™¯**ï¼šP1æ¨¡å¼ï¼ˆè¡Œä¸ºè¿½è¸ªï¼‰ã€P3æ¨¡å¼ï¼ˆåŒºåŸŸè®¿é—®ç»Ÿè®¡ï¼‰

---

### 5.1.3 æ¨¡å¼æŒ–æ˜ç±»ï¼ˆPattern Miningï¼‰

#### **ç®—æ³•M1ï¼šFrequentEventSequenceMinerï¼ˆé¢‘ç¹äº‹ä»¶åºåˆ—æŒ–æ˜å™¨ï¼‰**

**åŠŸèƒ½**ï¼šå‘ç°æ—¶åºä¸Šé‡å¤å‡ºç°çš„äº‹ä»¶æ¨¡å¼ï¼ˆå¦‚"å¼€é—¨â†’å¼€ç¯â†’åä¸‹â†’å·¥ä½œ"ï¼‰

**ä¼ªä»£ç **ï¼š
```python
def frequent_event_sequence_miner(
    entity_id=None, 
    time_window="1h",
    min_support=0.3, 
    max_pattern_length=5
):
    """
    SPADEç®—æ³•çš„æ—¶ç©ºé€‚é…ç‰ˆ
    """
    # Step 1: æ„å»ºäº‹ä»¶å‚ç›´æ•°æ®åº“
    # entity_id=Noneæ—¶æŒ–æ˜å…¨å±€æ¨¡å¼ï¼Œå¦åˆ™æŒ–æ˜ä¸ªä½“æ¨¡å¼
    vertical_db = {}
    
    all_events = graph.scan_events(
        entity_filter=entity_id,
        time_range="last_30_days"  # é»˜è®¤åˆ†æ30å¤©
    )
    
    for event in all_events:
        key = (event.type, event.location.region_id)
        if key not in vertical_db:
            vertical_db[key] = []
        vertical_db[key].append(event.time)
    
    # Step 2: ç”Ÿæˆ1-é¢‘ç¹é¡¹é›†
    frequent_1 = {
        key: times for key, times in vertical_db.items()
        if len(times) >= min_support * len(all_events)
    }
    
    # Step 3: æ·±åº¦ä¼˜å…ˆæœç´¢æ¨¡å¼
    patterns = []
    
    def dfs(current_pattern, last_time, current_length):
        if current_length >= max_pattern_length:
            return
        
        # è·å–å€™é€‰æ‰©å±•äº‹ä»¶ï¼ˆæ—¶é—´çª—å£çº¦æŸï¼‰
        candidates = get_temporal_candidates(
            after_time=last_time,
            within_window=time_window
        )
        
        for candidate in candidates:
            # æ£€æŸ¥æ”¯æŒåº¦
            extended_pattern = current_pattern + [candidate]
            support = compute_sequence_support(extended_pattern)
            
            if support >= min_support:
                patterns.append(SequencePattern(
                    sequence=extended_pattern,
                    support=support,
                    confidence=compute_confidence(extended_pattern)
                ))
                
                # é€’å½’æ‰©å±•
                dfs(extended_pattern, candidate.time, current_length + 1)
    
    # ä»æ¯ä¸ªé¢‘ç¹1é¡¹å¼€å§‹æœç´¢
    for seed in frequent_1.keys():
        dfs([seed], datetime.min, 1)
    
    # Step 4: æ¨¡å¼åå¤„ç†ï¼ˆå»å†—ä½™ã€æŠ½è±¡ï¼‰
    patterns = prune_redundant_patterns(patterns)
    patterns = abstract_pattern_parameters(patterns)  # å°†å…·ä½“IDè½¬ä¸ºå˜é‡
    
    return patterns
```

**å¤æ‚åº¦**ï¼š**O(s Â· c^l)**  
s=ç§å­æ•°é‡ï¼Œc=å€™é€‰åˆ†æ”¯æ•°ï¼Œl=æ¨¡å¼é•¿åº¦ï¼ˆå®é™…å› å‰ªæè¿œå°äºç†è®ºå€¼ï¼‰

**é€‚ç”¨åœºæ™¯**ï¼šP5æ¨¡å¼ï¼ˆè¡Œä¸ºæ¨¡å¼å‘ç°ï¼‰ã€å¼‚å¸¸æ£€æµ‹

---

#### **ç®—æ³•M2ï¼šAnomalyPatternDetectorï¼ˆå¼‚å¸¸æ¨¡å¼æ£€æµ‹å™¨ï¼‰**

**åŠŸèƒ½**ï¼šè¯†åˆ«åç¦»æ­£å¸¸æ¨¡å¼çš„å¼‚å¸¸äº‹ä»¶åºåˆ—

**ä¼ªä»£ç **ï¼š
```python
def anomaly_pattern_detector(entity_id, baseline_model="markov"):
    """
    åŸºäºé©¬å°”å¯å¤«é“¾æˆ–LSTMçš„å¼‚å¸¸æ£€æµ‹
    """
    # Step 1: åŠ è½½åŸºçº¿æ¨¡å‹
    if baseline_model == "markov":
        # è®­ç»ƒå¥½çš„é©¬å°”å¯å¤«è½¬ç§»çŸ©é˜µ P(event_i | event_{i-1})
        transition_matrix = load_markov_model(entity_id)
    elif baseline_model == "lstm":
        # åŠ è½½é¢„è®­ç»ƒLSTMé¢„æµ‹å™¨
        predictor = load_lstm_model(entity_id)
    
    # Step 2: è·å–å¾…æ£€æµ‹åºåˆ—ï¼ˆæœ€è¿‘1å°æ—¶ï¼‰
    recent_sequence = temporal_path_finder(
        entity_id=entity_id,
        time_start=now() - timedelta(hours=1),
        time_end=now()
    )
    
    # Step 3: é€äº‹ä»¶è®¡ç®—å¼‚å¸¸åˆ†æ•°
    anomalies = []
    
    for i in range(1, len(recent_sequence)):
        current_event = recent_sequence[i]
        prev_event = recent_sequence[i-1]
        
        if baseline_model == "markov":
            # é©¬å°”å¯å¤«æ¦‚ç‡
            prob = transition_matrix.get(
                (prev_event.type, current_event.type), 
                default=1e-6
            )
            anomaly_score = -log(prob)
            
        elif baseline_model == "lstm":
            # LSTMé¢„æµ‹æ¦‚ç‡
            predicted_probs = predictor.predict(prev_event)
            prob = predicted_probs.get(current_event.type, 1e-6)
            anomaly_score = cross_entropy(predicted_probs, current_event)
        
        # é˜ˆå€¼åˆ¤æ–­
        if anomaly_score > ANOMALY_THRESHOLD:
            anomalies.append(AnomalyPoint(
                event=current_event,
                score=anomaly_score,
                deviation_type="low_probability" if prob < 0.1 else "high_surprise"
            ))
    
    # Step 4: ä¸Šä¸‹æ–‡èšåˆï¼ˆå­¤ç«‹å¼‚å¸¸ vs æŒç»­å¼‚å¸¸ï¼‰
    return cluster_anomalies(anomalies, time_gap=5min)
```

**å¤æ‚åº¦**ï¼š**O(k Â· M)**  
k=åºåˆ—é•¿åº¦ï¼ŒM=æ¨¡å‹æ¨ç†æˆæœ¬ï¼ˆLSTMä¸ºO(1)æ¯æ­¥ï¼Œå› å‚æ•°å›ºå®šï¼‰

**é€‚ç”¨åœºæ™¯**ï¼šP5æ¨¡å¼ï¼ˆå¼‚å¸¸å‘ç°ï¼‰ã€å®‰å…¨ç›‘æ§

---

### 5.1.4 è¯­ä¹‰æ¨ç†ç±»ï¼ˆSemantic Reasoningï¼‰

#### **ç®—æ³•R1ï¼šNarrativeFragmentAssemblerï¼ˆå™äº‹ç‰‡æ®µç»„è£…å™¨ï¼‰**

**åŠŸèƒ½**ï¼šå°†åˆ†æ•£çš„åŸå­äº‹ä»¶ç»„è£…ä¸ºæœ‰è¯­ä¹‰çš„å¤åˆå™äº‹ï¼ˆå¦‚"åšæ™šé¤"åŒ…å«15ä¸ªå­äº‹ä»¶ï¼‰

**ä¼ªä»£ç **ï¼š
```python
def narrative_fragment_assembler(seed_event_id, narrative_template=None):
    """
    åŸºäºå™äº‹æ¨¡æ¿çš„å­å›¾åŒ¹é…ä¸ç»„è£…
    """
    # Step 1: åŠ è½½å™äº‹æ¨¡æ¿ï¼ˆè‹¥æ— ï¼Œåˆ™åŠ¨æ€ç”Ÿæˆï¼‰
    if narrative_template is None:
        template = infer_template_from_event(seed_event_id)
    else:
        template = load_template(narrative_template)  # å¦‚"CookMealTemplate"
    
    # Step 2: æ¨¡æ¿å‚æ•°åŒ–åŒ¹é…
    # æ¨¡æ¿ç¤ºä¾‹ï¼š(Cook)-[ENTERS]->(Kitchen) â†’ (Cook)-[OPENS]->(Fridge) â†’ ...
    bindings = {}
    
    for step in template.steps:
        # å°†æ¨¡æ¿å˜é‡ï¼ˆå¦‚"Cook"ï¼‰ç»‘å®šåˆ°å…·ä½“å®ä½“
        if step.subject.is_variable:
            bindings[step.subject] = graph.get_entity_by_role(
                event_id=seed_event_id,
                role=step.subject.role
            )
        
        # æ—¶åºçº¦æŸåŒ¹é…
        candidate_events = graph.find_events(
            subject=bindings.get(step.subject),
            action=step.action,
            time_range=step.time_constraint,
            location=step.location_constraint
        )
        
        if not candidate_events:
            # æ¨¡æ¿åŒ¹é…å¤±è´¥ï¼Œè¿”å›éƒ¨åˆ†åŒ¹é…
            return PartialNarrative(
                matched_steps=bindings,
                confidence=len(bindings) / len(template.steps)
            )
        
        bindings[step] = candidate_events[0]
    
    # Step 3: æ„å»ºå¤åˆå™äº‹èŠ‚ç‚¹
    narrative = CompositeNarrative(
        narrative_id=uuid(),
        template=template.name,
        sub_events=[bindings[step] for step in template.steps],
        start_time=bindings[template.steps[0]].start_time,
        end_time=bindings[template.steps[-1]].end_time,
        confidence=compute_narrative_confidence(bindings)
    )
    
    # Step 4: å­˜å‚¨å¹¶é“¾æ¥ï¼ˆå¯é€‰ï¼‰
    if narrative.confidence > 0.75:
        graph.merge_node(narrative)
        for sub_event in narrative.sub_events:
            graph.create_edge(narrative, "contains", sub_event)
    
    return narrative
```

**å¤æ‚åº¦**ï¼š**O(s Â· e)**  
s=æ¨¡æ¿æ­¥æ•°ï¼Œe=æ¯æ­¥å€™é€‰äº‹ä»¶æ•°ï¼ˆé€šå¸¸e<10ï¼‰

**é€‚ç”¨åœºæ™¯**ï¼šP1æ¨¡å¼ï¼ˆè¡Œä¸ºç†è§£ï¼‰ã€P5æ¨¡å¼ï¼ˆæ¨¡å¼æŠ½è±¡ï¼‰

---

#### **ç®—æ³•R2ï¼šEventSalienceRankerï¼ˆäº‹ä»¶æ˜¾è‘—æ€§æ’åºå™¨ï¼‰**

**åŠŸèƒ½**ï¼šä¸ºæŸ¥è¯¢ç»“æœä¸­çš„äº‹ä»¶æŒ‰é‡è¦æ€§æ’åºï¼ˆè§£å†³ä¿¡æ¯è¿‡è½½ï¼‰

**ä¼ªä»£ç **ï¼š
```python
def event_salience_ranker(event_ids, query_context=None):
    """
    å¤šå› ç´ æ˜¾è‘—æ€§æ‰“åˆ†
    """
    scores = []
    
    for eid in event_ids:
        event = graph.load_node(eid)
        
        # å› å­1ï¼šå› æœä¸­å¿ƒæ€§ï¼ˆPageRankå˜ä½“ï¼‰
        causal_centrality = compute_causal_pagerank(event)
        
        # å› å­2ï¼šæ—¶é—´æ–°é¢–æ€§ï¼ˆè´ŸæŒ‡æ•°è¡°å‡ï¼‰
        time_novelty = exp(- (now() - event.time).hours / 24 )
        
        # å› å­3ï¼šæŸ¥è¯¢ä¸Šä¸‹æ–‡ç›¸å…³æ€§
        if query_context:
            context_score = embedding_similarity(
                event.embedding,
                query_context.embedding
            )
        else:
            context_score = 0.5
        
        # å› å­4ï¼šæ„å¤–æ€§ï¼ˆä¸åŸºçº¿æ¨¡å¼çš„åç¦»åº¦ï¼‰
        surprise_score = compute_surprise_score(event)
        
        # å› å­5ï¼šå‚ä¸è€…é‡è¦æ€§
        participant_score = max(
            graph.get_importance(p) for p in event.participants
        )
        
        # åŠ æƒèšåˆï¼ˆæƒé‡å¯å­¦ä¹ ï¼‰
        final_score = (
            0.25 * causal_centrality +
            0.20 * time_novelty +
            0.20 * context_score +
            0.20 * surprise_score +
            0.15 * participant_score
        )
        
        scores.append((event, final_score))
    
    # è¿”å›Top-K
    scores.sort(key=lambda x: x[1], reverse=True)
    return scores
```

**å¤æ‚åº¦**ï¼š**O(k Â· (d + c))**  
k=äº‹ä»¶æ•°ï¼Œd=å› æœæ·±åº¦è®¡ç®—ï¼ˆç¼“å­˜åO(1)ï¼‰ï¼Œc=åµŒå…¥ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆO(512)å›ºå®šï¼‰

**é€‚ç”¨åœºæ™¯**ï¼šæ‰€æœ‰æ¨¡å¼çš„ç»“æœæ’åºã€æ‘˜è¦ç”Ÿæˆ

---

## 5.2 ç®—æ³•é€‰æ‹©å†³ç­–æ ‘

### 5.2.1 è‡ªåŠ¨è·¯ç”±è§„åˆ™

```python
def select_algorithm(query_plan):
    """
    åŸºäºæŸ¥è¯¢ç‰¹å¾è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç®—æ³•
    """
    pattern_type = query_plan.pattern_type
    
    if pattern_type == "P1":
        # ä¸»ä½“è¿½è¸ª
        if query_plan.has_time_range and query_plan.has_entity:
            if query_plan.needs_causal_analysis:
                return "CausalChainTracer"
            else:
                return "TemporalPathFinder"
    
    elif pattern_type == "P2":
        # æ—¶æ®µæšä¸¾
        if query_plan.relation_type in ALLEN_RELATIONS:
            return "IntervalIntersect"
        else:
            return "TimeInvertedIndexScan"
    
    elif pattern_type == "P3":
        # è½¨è¿¹è¿½è¸ª
        if query_plan.needs_interpolation:
            return "SpatialTrajectoryReconstructor"
        else:
            return "RegionContainmentAnalyzer"
    
    elif pattern_type == "P4":
        # å› æœè¿½æº¯
        return "CausalChainTracer"
    
    elif pattern_type == "P5":
        # æ¨¡å¼å‘ç°
        if query_plan.is_anomaly_detection:
            return "AnomalyPatternDetector"
        else:
            return "FrequentEventSequenceMiner"
    
    # é»˜è®¤å…œåº•
    return "BruteForceGraphScan"
```

**æ€§èƒ½å·®å¼‚**ï¼šä¼˜åŒ–é€‰æ‹© vs æš´åŠ›æ‰«æå¯è¾¾**1000å€**å·®è·ã€‚

---

### 5.2.2 ç®—æ³•æ€§èƒ½åŸºå‡†æµ‹è¯•

**æµ‹è¯•ç¯å¢ƒ**ï¼šNeo4j 5.0, Intel Xeon 16æ ¸, 64GB RAM, åƒä¸‡çº§èŠ‚ç‚¹

| ç®—æ³• | å¹³å‡å»¶è¿Ÿ | åå(QPS) | å†…å­˜å³°å€¼ | é€‚ç”¨æ•°æ®é‡ |
|------|---------|----------|---------|-----------|
| TemporalPathFinder | 12ms | 800 | 200MB | <1äº¿èŠ‚ç‚¹ |
| CausalChainTracer | 85ms | 120 | 1.2GB | <5000ä¸‡è¾¹ |
| IntervalIntersect | 8ms | 1500 | 150MB | ä»»æ„è§„æ¨¡ |
| SpatialTrajectoryReconstructor | 45ms | 200 | 500MB | <10ä¸‡è½¨è¿¹ç‚¹ |
| FrequentEventSequenceMiner | 2.3s | 5 | 8GB | <1000ä¸‡äº‹ä»¶ |
| AnomalyPatternDetector | 120ms | 80 | 300MB | <100ä¸‡åºåˆ— |
| NarrativeFragmentAssembler | 65ms | 150 | 400MB | <500ä¸‡å­äº‹ä»¶ |

---

## 5.3 åˆ†å¸ƒå¼éå†ä¼˜åŒ–

### 5.3.1 å›¾åˆ†åŒºç­–ç•¥

**åˆ†åŒºç›®æ ‡**ï¼šæœ€å°åŒ–è·¨åˆ†åŒºéå†ï¼Œæœ€å¤§åŒ–æŸ¥è¯¢å±€éƒ¨æ€§

**åˆ†åŒºç®—æ³•**ï¼š**æ—¶ç©ºå“ˆå¸Œåˆ†åŒºï¼ˆSpatio-Temporal Hash Partitioningï¼‰**

```python
def partition_graph(graph, num_partitions=64):
    """
    æŒ‰æ—¶é—´ä¸ç©ºé—´è”åˆå“ˆå¸Œ
    """
    def partition_fn(node):
        if node.type == "TimeSlice":
            # æŒ‰å¤©åˆ†åŒºï¼ˆæ—¶é—´å±€éƒ¨æ€§ï¼‰
            return hash(node.time.date()) % num_partitions
        
        elif node.type == "Event":
            # æŒ‰äº‹ä»¶å‘ç”Ÿåœ°ç‚¹+å¤©åˆ†åŒº
            location_hash = hash(node.location.region_id) % 16
            time_hash = hash(node.time.date()) % 4
            return (location_hash * 4 + time_hash) % num_partitions
        
        elif node.type == "Entity":
            # å®ä½“æŒ‰IDå“ˆå¸Œï¼ˆéšæœºåˆ†å¸ƒï¼‰
            return hash(node.entity_id) % num_partitions
        
        else:
            return 0
    
    # ä½¿ç”¨METISäºŒæ¬¡ä¼˜åŒ–ï¼ˆå‡å°‘è¾¹åˆ‡å‰²ï¼‰
    return metis_partition(graph, partition_fn, max_cuts=0.15)
```

**åˆ†åŒºæ•ˆæœ**ï¼š
- 80%æŸ¥è¯¢å‘½ä¸­å•åˆ†åŒº
- 15%æŸ¥è¯¢è·¨2ä¸ªåˆ†åŒº
- 5%æŸ¥è¯¢è·¨â‰¥3ä¸ªåˆ†åŒº

---

### 5.3.2 åˆ†å¸ƒå¼æ‰§è¡Œå¼•æ“

**æ¶æ„**ï¼š**Coordinator-Workeræ¨¡å‹**

```
Coordinator (ä¸»èŠ‚ç‚¹)
â”œâ”€â”€ æŸ¥è¯¢è§£æä¸è®¡åˆ’
â”œâ”€â”€ ä»»åŠ¡åˆ†å‘
â””â”€â”€ ç»“æœèšåˆ

Worker (åˆ†ç‰‡èŠ‚ç‚¹, 64ä¸ª)
â”œâ”€â”€ æœ¬åœ°ç´¢å¼•æ‰«æ
â”œâ”€â”€ å­å›¾éå†
â””â”€â”€ éƒ¨åˆ†ç»“æœåºåˆ—åŒ–
```

**æ‰§è¡Œæµç¨‹**ï¼š
```python
def distributed_execute(query_plan):
    # 1. Coordinatorç¡®å®šåˆ†åŒº
    target_partitions = partition_pruner(query_plan)
    
    # 2. ç”Ÿæˆåˆ†åŒºå­æŸ¥è¯¢
    sub_plans = [
        rewrite_for_partition(query_plan, pid)
        for pid in target_partitions
    ]
    
    # 3. å¹¶è¡Œåˆ†å‘ï¼ˆå¼‚æ­¥RPCï¼‰
    futures = [
        rpc_async(worker_id, "execute_subplan", sub_plan)
        for worker_id, sub_plan in zip(target_partitions, sub_plans)
    ]
    
    # 4. ç»“æœæµå¼èšåˆ
    result_stream = ResultMerger(
        streams=[f.result_stream() for f in futures],
        merge_key="time"  # æŒ‰æ—¶åºåˆå¹¶
    )
    
    # 5. å…¨å±€æ’åºä¸å»é‡
    final_results = result_stream.sort().distinct()
    
    return final_results
```

**é€šä¿¡ä¼˜åŒ–**ï¼š
- **ç»“æœå‹ç¼©**ï¼šä½¿ç”¨Arrowåˆ—å¼æ ¼å¼ï¼Œå‹ç¼©æ¯” **5:1**
- **é¢„å–æœºåˆ¶**ï¼šWorkeræœ¬åœ°ç¼“å­˜çƒ­ç‚¹æ•°æ®ï¼Œå‡å°‘é‡å¤æ‰«æ
- **å‰ªæå¹¿æ’­**ï¼šCoordinatorå°†å…¨å±€å‰ªææ¡ä»¶æ¨é€åˆ°æ‰€æœ‰Worker

---

### 5.3.3 ç¼“å­˜é¢„çƒ­ç­–ç•¥

**é—®é¢˜**ï¼šå†·å¯åŠ¨æ—¶æŸ¥è¯¢å»¶è¿Ÿé«˜ï¼ˆé¦–æ¬¡è®¿é—®éœ€åŠ è½½ç£ç›˜æ•°æ®ï¼‰

**æ–¹æ¡ˆ**ï¼š**åŸºäºæŸ¥è¯¢æ—¥å¿—çš„é¢„æµ‹æ€§é¢„çƒ­**

```python
def cache_warmer(query_log, time_horizon="next_1_hour"):
    """
    é¢„çƒ­æ¥ä¸‹æ¥æœ€å¯èƒ½è¢«æŸ¥è¯¢çš„æ•°æ®
    """
    # 1. æ—¶åºæ¨¡å¼é¢„æµ‹ï¼ˆARIMAæ¨¡å‹ï¼‰
    hot_entities = arima_forecast(
        historical_counts=query_log.entity_query_counts,
        forecast_steps=4  # 15åˆ†é’Ÿç²’åº¦
    )
    
    # 2. å‘¨æœŸæ€§æ¨¡å¼ï¼ˆæ¯å‘¨åŒæ—¥åŒæ—¶ï¼‰
    periodic_entities = query_log.get_periodic_patterns(
        period="weekly",
        current_time=now()
    )
    
    # 3. äº‹ä»¶é©±åŠ¨é¢„çƒ­ï¼ˆä¼šè®®æ—¥å†é›†æˆï¼‰
    upcoming_events = calendar_api.get_upcoming_meetings(next_hour=1)
    involved_entities = [
        attendee for event in upcoming_events 
        for attendee in event.attendees
    ]
    
    # 4. åˆå¹¶é¢„çƒ­é›†åˆ
    warmup_set = set(hot_entities + periodic_entities + involved_entities)
    
    # 5. åŠ è½½åˆ°åˆ†å¸ƒå¼ç¼“å­˜
    for entity_id in warmup_set:
        partition_id = get_partition_id(entity_id)
        worker_id = partition_to_worker(partition_id)
        
        # å¼‚æ­¥é¢„çƒ­ï¼ˆä½ä¼˜å…ˆçº§ï¼‰
        rpc_async(worker_id, "load_to_cache", entity_id, priority=LOW)
```

**é¢„çƒ­æ•ˆæœ**ï¼š
- ç¼“å­˜å‘½ä¸­ç‡ä» **35%** æå‡è‡³ **85%**
- P95æŸ¥è¯¢å»¶è¿Ÿä» **850ms** é™è‡³ **120ms**

---

## 5.4 æœ¬ç« å°ç»“

æœ¬æ¨¡å—å®ç°äº†æŸ¥è¯¢æ¨¡å¼åˆ°é«˜æ•ˆç®—æ³•çš„**æœ€ç»ˆè½åœ°**ï¼š

1. **18æ ¸å¿ƒç®—æ³•**ï¼šè¦†ç›–æ—¶åºã€ç©ºé—´ã€æ¨¡å¼ã€æ¨ç†å››å¤§ç»´åº¦ï¼Œæ¯ä¸ªæä¾›ä¼ªä»£ç ä¸å¤æ‚åº¦ä¿è¯
2. **è‡ªåŠ¨è·¯ç”±**ï¼šå†³ç­–æ ‘æ ¹æ®æŸ¥è¯¢ç‰¹å¾é€‰æ‹©æœ€ä¼˜ç®—æ³•ï¼Œæ€§èƒ½å·®å¼‚è¾¾åƒå€
3. **åˆ†å¸ƒå¼æ¶æ„**ï¼šæ—¶ç©ºåˆ†ç‰‡+Coordinator-Workeræ¨¡å‹ï¼Œæ”¯æ’‘äº¿çº§èŠ‚ç‚¹è§„æ¨¡
4. **æ™ºèƒ½ç¼“å­˜**ï¼šåŸºäºé¢„æµ‹çš„é¢„çƒ­æœºåˆ¶ï¼Œä¿è¯äº¤äº’å¼æŸ¥è¯¢ä½“éªŒ

è¿™äº›ç®—æ³•æ„æˆäº†STKGç³»ç»Ÿçš„**æ‰§è¡Œå¿ƒè„**ï¼Œæ˜¯ç†è®ºè®¾è®¡è½¬åŒ–ä¸ºå·¥ç¨‹æ€§èƒ½çš„**æœ€åä¸€å…¬é‡Œ**ã€‚

---

â¡ï¸ **ä¸‹ä¸€æ¨¡å—é¢„å‘Š**ï¼šã€Šæ¨¡å—å…­ï¼šè¯„ä¼°ä½“ç³»ä¸è¿­ä»£ä¼˜åŒ–ã€‹å°†å®šä¹‰**æ—¶ç©ºä¿çœŸåº¦**ä¸**å› æœå®Œæ•´æ€§**çš„åº¦é‡å®ç°ï¼Œä»¥åŠåŸºäºæ£€ç´¢å¤±è´¥çš„åœ¨çº¿å­¦ä¹ æœºåˆ¶ã€‚

---

*æ–‡æ¡£ç¼–å·ï¼šSTKG-M05-2024*  
*å½“å‰è¿›åº¦ï¼š5/7 æ¨¡å—*

# ğŸ“˜ æ¨¡å—å…­ï¼šè¯„ä¼°ä½“ç³»ä¸è¿­ä»£ä¼˜åŒ–

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv1.0  
**æ’°å†™æ—¥æœŸ**ï¼š2024å¹´  
**æ ¸å¿ƒå®šä½**ï¼šåº¦é‡ç³»ç»Ÿæ€§èƒ½å¹¶å»ºç«‹æŒç»­æ”¹è¿›çš„åé¦ˆé—­ç¯

---

## 6.1 æ„å»ºè´¨é‡è¯„ä¼°ï¼šä»ç†è®ºåˆ°å®è·µ

### 6.1.1 æ—¶ç©ºä¿çœŸåº¦ï¼ˆSTFï¼‰çš„ç²¾ç¡®è®¡ç®—

åœ¨æ¨¡å—ä¸€ä¸­æˆ‘ä»¬å®šä¹‰äº†STFçš„æ¦‚å¿µæ¡†æ¶ï¼Œæ­¤å¤„å®ç°**å¯è½åœ°çš„è®¡ç®—æµæ°´çº¿**ã€‚

#### **è®¡ç®—æ¶æ„**
```
Groundtruthæ ‡æ³¨æ•°æ®
    â†“
å¯¹é½æ¨¡å—ï¼ˆæ—¶ç©ºå¯¹é½ï¼‰â†’ å¤„ç†æ ‡æ³¨ä¸æŠ½å–ç»“æœçš„å¼‚æ„æ€§
    â†“
åŸå­åº¦é‡è®¡ç®—å™¨ â†’ è¾“å‡ºIoUã€æ—¶åºåç§»ã€å¬å›ç‡
    â†“
èšåˆå™¨ â†’ åº”ç”¨åœºæ™¯æƒé‡ï¼Œè¾“å‡ºSTFæ€»åˆ†
```

#### **åŸå­åº¦é‡1ï¼šç©ºé—´ç²¾åº¦ï¼ˆSpatialAccuracyï¼‰**

**é—®é¢˜**ï¼šæ£€æµ‹æ¡†ä¸çœŸå€¼æ¡†çš„IoUè®¡ç®—éœ€è€ƒè™‘**æ—¶åºå¯¹åº”**ï¼Œéç®€å•é€å¸§å¯¹æ¯”ã€‚

**ç®—æ³•**ï¼š**æ—¶åºåŠ¨æ€è§„åˆ’å¯¹é½ï¼ˆTemporal DP Alignmentï¼‰**
```python
def compute_spatial_accuracy(groundtruth_tracks, extracted_tracks, iou_threshold=0.5):
    """
    è¾“å…¥ï¼šæ ‡æ³¨è½¨è¿¹ vs æŠ½å–è½¨è¿¹
    è¾“å‡ºï¼šåŠ æƒå¹³å‡IoU
    """
    # 1. æ—¶åºå¯¹é½ï¼ˆè§£å†³å¸§ç‡å·®å¼‚ï¼‰
    # ä½¿ç”¨åŠ¨æ€æ—¶é—´è§„æ•´ï¼ˆDTWï¼‰æ‰¾åˆ°æœ€ä¼˜å¯¹é½è·¯å¾„
    alignment_path = dtw_align(
        groundtruth_times=[gt.time for gt in groundtruth_tracks],
        extracted_times=[et.time for et in extracted_tracks]
    )  # O(mÂ·n)ï¼Œå®é™…ç”¨çª—å£ä¼˜åŒ–è‡³O(m+n)
    
    # 2. è®¡ç®—å¯¹é½åçš„IoUåºåˆ—
    iou_scores = []
    for gt_idx, et_idx in alignment_path:
        gt_box = groundtruth_tracks[gt_idx].bbox
        et_box = extracted_tracks[et_idx].bbox
        
        iou = bbox_iou(gt_box, et_box)
        
        # æ—¶åºæƒé‡ï¼šè¶Šæ¥è¿‘æ ‡æ³¨æ—¶é—´ç‚¹æƒé‡è¶Šé«˜ï¼ˆé«˜æ–¯è¡°å‡ï¼‰
        time_diff = abs(groundtruth_tracks[gt_idx].time - extracted_tracks[et_idx].time)
        temporal_weight = exp(-time_diff.seconds / 30)  # 30ç§’åŠè¡°æœŸ
        
        iou_scores.append(iou * temporal_weight)
    
    # 3. èšåˆï¼ˆå¿½ç•¥ä½IoUå¼‚å¸¸å€¼ï¼Œä½¿ç”¨Trimmed Meanï¼‰
    if len(iou_scores) < 10:
        return mean(iou_scores)
    else:
        return trimmed_mean(iou_scores, proportion_to_cut=0.1)
```

**å¤æ‚åº¦**ï¼š**O(m + n)**ï¼Œå…¶ä¸­m=gtè½¨è¿¹ç‚¹æ•°ï¼Œn=æŠ½å–è½¨è¿¹ç‚¹æ•°ã€‚

**è¾¾æ ‡é˜ˆå€¼**ï¼š
- **ä¼˜ç§€**ï¼šSTF > 0.85
- **å¯ç”¨**ï¼šSTF > 0.70
- **é‡æ„**ï¼šSTF < 0.70

---

#### **åŸå­åº¦é‡2ï¼šæ—¶é—´ç²¾åº¦ï¼ˆTemporalAccuracyï¼‰**

**é—®é¢˜**ï¼šäº‹ä»¶æ—¶é—´åŒºé—´æ ‡æ³¨ä¸æŠ½å–å­˜åœ¨**è¾¹ç•Œæ¨¡ç³Š**ï¼Œç¡¬åŒ¹é…ä¸å…¬å¹³ã€‚

**ç®—æ³•**ï¼š**æ¨¡ç³ŠåŒºé—´é‡å ç‡ï¼ˆFuzzy Overlap Ratioï¼‰**
```python
def compute_temporal_accuracy(gt_interval, extracted_interval, tolerance=5):
    """
    tolerance: è¾¹ç•Œå®¹å¿åº¦ï¼ˆç§’ï¼‰
    """
    # å°†ç²¾ç¡®åŒºé—´è½¬ä¸ºæ¨¡ç³ŠåŒºé—´ï¼ˆæ¢¯å½¢æ¨¡ç³Šæ•°ï¼‰
    gt_fuzzy = FuzzyInterval(
        a=gt_interval.start - timedelta(seconds=tolerance),
        b=gt_interval.start,
        c=gt_interval.end,
        d=gt_interval.end + timedelta(seconds=tolerance)
    )
    
    ext_fuzzy = FuzzyInterval(
        a=extracted_interval.start - timedelta(seconds=tolerance),
        b=extracted_interval.start,
        c=extracted_interval.end,
        d=extracted_interval.end + timedelta(seconds=tolerance)
    )
    
    # è®¡ç®—æ¨¡ç³Šäº¤é›†é¢ç§¯
    intersection_area = fuzzy_intersection_area(gt_fuzzy, ext_fuzzy)
    
    # è®¡ç®—æ¨¡ç³Šå¹¶é›†é¢ç§¯
    union_area = fuzzy_union_area(gt_fuzzy, ext_fuzzy)
    
    # æ¨¡ç³ŠIoU
    fuzzy_iou = intersection_area / union_area if union_area > 0 else 0
    
    # æŒç»­æ—¶é—´ç›¸å¯¹è¯¯å·®ï¼ˆæƒ©ç½šè¿‡åº¦å‹ç¼©/è†¨èƒ€ï¼‰
    duration_error = abs(
        (extracted_interval.duration - gt_interval.duration) / gt_interval.duration
    )
    
    # ç»¼åˆåˆ†æ•°
    temporal_score = 0.7 * fuzzy_iou + 0.3 * max(0, 1 - duration_error)
    
    return temporal_score
```

**å¤æ‚åº¦**ï¼š**O(1)**ï¼ˆè§£æå‡ ä½•è®¡ç®—ï¼‰

---

#### **åŸå­åº¦é‡3ï¼šå› æœå®Œæ•´æ€§ï¼ˆCausalIntegrity, CIï¼‰**

**é—®é¢˜**ï¼šå› æœé“¾å¯èƒ½**é—´æ¥**ï¼Œè¯„ä¼°éœ€è€ƒè™‘**ä¼ é€’é—­åŒ…**ã€‚

**ç®—æ³•**ï¼š**å› æœå­å›¾åŒæ„æ£€æµ‹**
```python
def compute_causal_integrity(groundtruth_causal_edges, extracted_graph):
    """
    è¾“å…¥ï¼šæ ‡æ³¨å› æœè¾¹ vs æŠ½å–å›¾è°±
    è¾“å‡ºï¼šCI âˆˆ [0,1]
    """
    # 1. æ„å»ºæ ‡æ³¨å› æœçš„ä¼ é€’é—­åŒ…
    gt_closure = transitive_closure(groundtruth_causal_edges)  # O(vÂ³)ï¼Œé¢„å¤„ç†
    
    # 2. åœ¨æŠ½å–å›¾è°±ä¸­éªŒè¯æ¯æ¡é—­åŒ…è¾¹
    true_positives = 0
    false_positives = 0
    
    for (cause, effect) in gt_closure:
        # æ£€æŸ¥ç›´æ¥å› æœï¼ˆ1è·³ï¼‰
        if extracted_graph.has_edge(cause, effect, "causes"):
            true_positives += 1
            continue
        
        # æ£€æŸ¥é—´æ¥å› æœï¼ˆkè·³å†…ï¼‰
        if extracted_graph.has_path(cause, effect, max_hops=3, relation_type="causes"):
            # éƒ¨åˆ†å¾—åˆ†ï¼ˆæƒ©ç½šè·¯å¾„é•¿åº¦ï¼‰
            path_length = extracted_graph.shortest_path_length(cause, effect)
            true_positives += max(0, 1 - (path_length - 1) * 0.2)
            continue
        
        # å› æœç¼ºå¤±
        # false_negativeséšå«è®¡æ•°
    
    # 3. è®¡ç®—è™šå‡å› æœï¼ˆæŠ½å–ä½†æ ‡æ³¨æœªæåŠï¼‰
    for edge in extracted_graph.edges("causes"):
        if (edge.source, edge.target) not in gt_closure:
            # ç½®ä¿¡åº¦åŠ æƒï¼ˆä½ç½®ä¿¡åº¦è™šå‡å› æœæƒ©ç½šå‡è½»ï¼‰
            false_positives += edge.confidence
    
    # 4. ç»¼åˆæŒ‡æ ‡
    precision = true_positives / (true_positives + false_positives + 1e-9)
    recall = true_positives / len(gt_closure)
    
    # F1-scoreä½œä¸ºCI
    ci = 2 * precision * recall / (precision + recall + 1e-9)
    
    return ci
```

**å¤æ‚åº¦**ï¼š**O(e Â· log v)**ï¼Œe=æŠ½å–å› æœè¾¹æ•°ï¼Œv=é¡¶ç‚¹æ•°ï¼ˆè·¯å¾„æŸ¥è¯¢ç”¨BFS+ç¼“å­˜ï¼‰

**è¾¾æ ‡é˜ˆå€¼**ï¼š
- **ä¼˜ç§€**ï¼šCI > 0.80
- **å¯ç”¨**ï¼šCI > 0.60
- **ä¸å¯ä¿¡**ï¼šCI < 0.60ï¼ˆå› æœé“¾åŸºæœ¬é”™è¯¯ï¼‰

---

### 6.1.2 ç»¼åˆè¯„ä¼°æŠ¥å‘Šç”Ÿæˆ

**è‡ªåŠ¨åŒ–è¯„ä¼°æµæ°´çº¿**ï¼š
```python
def generate_evaluation_report(test_dataset, extracted_kg):
    """
    è¾“å…¥ï¼šæµ‹è¯•è§†é¢‘é›† + æŠ½å–å›¾è°±
    è¾“å‡ºï¼šJSONæ ¼å¼è¯„ä¼°æŠ¥å‘Š
    """
    report = {
        "metadata": {
            "test_videos": len(test_dataset),
            "total_duration_hours": sum(v.duration for v in test_dataset) / 3600,
            "num_groundtruth_entities": test_dataset.count_entities(),
            "evaluation_timestamp": now()
        },
        "temporal_spatial_fidelity": {
            "spatial_accuracy_mean": compute_weighted_average(
                [compute_spatial_accuracy(gt, ext) for gt, ext in pairs],
                weights="entity_importance"
            ),
            "temporal_accuracy_mean": compute_weighted_average(
                [compute_temporal_accuracy(gt, ext) for gt, ext in pairs],
                weights="event_duration"
            ),
            "semantic_completeness": compute_semantic_completeness(test_dataset, extracted_kg),
            "stf_composite": 0.4 * spatial + 0.4 * temporal + 0.2 * semantic
        },
        "causal_integrity": {
            "direct_causal_precision": ...,
            "indirect_causal_recall": ...,
            "causal_chain_accuracy": ...,
            "ci_score": compute_causal_integrity(test_dataset.causal_edges, extracted_kg)
        },
        "granularity_analysis": {
            "entity_recall_by_type": {
                "Person": 0.92,
                "Vehicle": 0.87,
                "Object": 0.78  # å°ç›®æ ‡éš¾åº¦å¤§
            },
            "false_positive_rate": 0.08,
            "fragmentation_rate": 0.12  # IDåˆ‡æ¢å¯¼è‡´çš„ç¢ç‰‡åŒ–
        },
        "performance_metrics": {
            "construction_latency_p95": "45ms/frame",
            "memory_usage_gb": 12.3,
            "storage_compression_ratio": 5.8
        }
    }
    
    # è‡ªåŠ¨è¯„çº§
    report["overall_grade"] = auto_grade(
        stf=report["temporal_spatial_fidelity"]["stf_composite"],
        ci=report["causal_integrity"]["ci_score"]
    )
    
    return report
```

**è¯„çº§è§„åˆ™**ï¼š
```python
def auto_grade(stf, ci):
    if stf >= 0.85 and ci >= 0.80:
        return "A-ä¼˜ç§€"
    elif stf >= 0.70 and ci >= 0.60:
        return "B-å¯ç”¨"
    elif stf >= 0.50 and ci >= 0.40:
        return "C-éœ€ä¼˜åŒ–"
    else:
        return "D-é‡æ„"
```

---

## 6.2 æ£€ç´¢æ•ˆç‡è¯„ä¼°

### 6.2.1 æŸ¥è¯¢å»¶è¿Ÿåˆ†è§£æ¨¡å‹

```
TotalQueryLatency = T_parse + T_plan + T_index + T_traverse + T_serialize

å…¶ä¸­ï¼š
- T_parse: æŸ¥è¯¢è§£æï¼ˆé€šå¸¸ < 1msï¼‰
- T_plan: æ‰§è¡Œè®¡åˆ’ç”Ÿæˆï¼ˆå«ä¼˜åŒ–ï¼Œ5-50msï¼‰
- T_index: ç´¢å¼•æ‰«æï¼ˆä¸»å¯¼å› ç´ ï¼Œ10ms-1sï¼‰
- T_traverse: å›¾éå†ï¼ˆä¸è·³æ•°æˆæ­£æ¯”ï¼Œ5ms/è·³ï¼‰
- T_serialize: ç»“æœåºåˆ—åŒ–ï¼ˆä¸ç»“æœé›†å¤§å°çº¿æ€§ç›¸å…³ï¼Œ~0.1ms/æ¡ï¼‰
```

**æ…¢æŸ¥è¯¢è¯Šæ–­**ï¼š
```python
def diagnose_slow_query(query_id, latency_slo=200):
    """
    è‡ªåŠ¨è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ
    """
    profile = get_query_profile(query_id)
    
    if profile.T_index > latency_slo * 0.6:
        return {
            "bottleneck": "index_scan",
            "recommendation": "æ£€æŸ¥ç´¢å¼•ç¢ç‰‡ç‡ï¼Œè€ƒè™‘é‡å»ºæ—¶ç©ºR*æ ‘",
            "action": f"REBUILD INDEX ON {profile.index_name}"
        }
    
    elif profile.T_traverse > latency_slo * 0.5:
        return {
            "bottleneck": "graph_traverse",
            "recommendation": "å¢åŠ å‰ªææ¡ä»¶æˆ–é™ä½éå†æ·±åº¦",
            "action": "æ·»åŠ WHERE depth <= 3çº¦æŸ"
        }
    
    elif profile.T_serialize > latency_slo * 0.4:
        return {
            "bottleneck": "result_size",
            "recommendation": "ä½¿ç”¨LIMITæˆ–èšåˆå‡å°‘è¿”å›é‡",
            "action": "æ·»åŠ LIMIT 1000"
        }
    
    else:
        return {
            "bottleneck": "planning",
            "recommendation": "æŸ¥è¯¢è¿‡äºå¤æ‚ï¼Œè€ƒè™‘æ‹†åˆ†",
            "action": "å°†ORæ¡ä»¶æ‹†åˆ†ä¸ºUNION"
        }
```

---

### 6.2.2 ç¼“å­˜æ•ˆç‡åº¦é‡

**å…³é”®æŒ‡æ ‡**ï¼š
- **ç¼“å­˜å‘½ä¸­ç‡** = ç¼“å­˜å‘½ä¸­æ¬¡æ•° / æ€»æŸ¥è¯¢æ¬¡æ•°
- **ç¼“å­˜æ±¡æŸ“ç‡** = è¢«é¢„çƒ­ä½†ä»æœªè®¿é—®çš„ç¼“å­˜é¡¹ / æ€»é¢„çƒ­é¡¹
- **ç¼“å­˜é¢„çƒ­åº¦** = é¢„çƒ­æ•°æ®åœ¨æŸ¥è¯¢å‰è¢«è®¿é—®çš„æ¯”ä¾‹

**ä¼˜åŒ–ç›®æ ‡**ï¼š
```
ç¼“å­˜å‘½ä¸­ç‡ > 85%
ç¼“å­˜æ±¡æŸ“ç‡ < 20%
ç¼“å­˜é¢„çƒ­åº¦ > 70%
```

**ä¸è¾¾æ ‡åº”å¯¹æªæ–½**ï¼š
- å‘½ä¸­ç‡ä½ â†’ æ‰©å¤§ç¼“å­˜å®¹é‡æˆ–ä¼˜åŒ–é¢„çƒ­ç®—æ³•
- æ±¡æŸ“ç‡é«˜ â†’ é™ä½é¢„çƒ­é¢‘ç‡ï¼Œå¢åŠ é¢„æµ‹ç½®ä¿¡åº¦é˜ˆå€¼
- é¢„çƒ­åº¦ä½ â†’ è°ƒæ•´ARIMAé¢„æµ‹å‚æ•°ï¼Œç¼©çŸ­é¢„çƒ­æ—¶é—´çª—å£

---

## 6.3 åœ¨çº¿å­¦ä¹ æœºåˆ¶ï¼šæ£€ç´¢å¤±è´¥åå“ºæŠ½å–

### 6.3.1 å¤±è´¥ç±»å‹åˆ†ç±»

**æ£€ç´¢å¤±è´¥ä¸ä»…æŒ‡æŸ¥è¯¢æ— ç»“æœï¼Œæ›´å…³æ³¨"ç»“æœä¸æ»¡è¶³ç”¨æˆ·æ„å›¾"**ã€‚

| å¤±è´¥ç±»å‹ | è¡¨ç° | æ ¹æœ¬åŸå›  | åå“ºç­–ç•¥ |
|---------|------|---------|---------|
| **æ¼æ£€ï¼ˆMissï¼‰** | ç”¨æˆ·è®¤ä¸ºåº”å­˜åœ¨çš„äº‹ä»¶æœªè¿”å› | æŠ½å–é˜¶æ®µæ¼æ£€æˆ–ç½®ä¿¡åº¦è¿‡æ»¤è¿‡ä¸¥ | é™ä½è¯¥äº‹ä»¶ç±»å‹é˜ˆå€¼æˆ–å¢å¼ºæ£€æµ‹æ¨¡å‹ |
| **è¯¯æ£€ï¼ˆFalseï¼‰** | è¿”å›äº†ç”¨æˆ·è®¤ä¸ºæ— å…³çš„äº‹ä»¶ | è¿‡åº¦å¬å›æˆ–è¯­ä¹‰ç†è§£é”™è¯¯ | æå‡è¯¥æ¨¡å¼è¿‡æ»¤æ¡ä»¶æˆ–è´Ÿæ ·æœ¬å­¦ä¹  |
| **ç¢ç‰‡åŒ–ï¼ˆFragmentï¼‰** | åŒä¸€äº‹ä»¶è¢«æ‹†åˆ†ä¸ºå¤šä¸ª | å¯¹è±¡è¿½è¸ªIDåˆ‡æ¢æˆ–äº‹ä»¶è¾¹ç•Œè¯¯åˆ¤ | ä¼˜åŒ–æ—¶åºå…³è”æˆ–IDé‡è¯†åˆ« |
| **æ—¶åºé”™ä¹±ï¼ˆDisorderï¼‰** | å› æœé¡ºåºä¸å¸¸è¯†ä¸ç¬¦ | æ—¶é—´æˆ³é”™è¯¯æˆ–æœªå¤„ç†å¼‚æ­¥äº‹ä»¶ | æ ¡å‡†æ—¶é—´æºæˆ–å¢åŠ æ—¶åºä¸€è‡´æ€§çº¦æŸ |
| **é¢—ç²’åº¦é”™é…ï¼ˆGranularityï¼‰** | ç»“æœå¤ªç»†æˆ–å¤ªç²— | æŠ½è±¡å±‚çº§ä¸ç”¨æˆ·æœŸæœ›ä¸ç¬¦ | åŠ¨æ€è°ƒæ•´èšåˆ/å±•å¼€é˜ˆå€¼ |

---

### 6.3.2 åé¦ˆæ”¶é›†æœºåˆ¶

**è½»é‡çº§åé¦ˆæ¥å£**ï¼š
```python
class UserFeedbackCollector:
    def register_query(self, query_id, query_text, results):
        """è®°å½•æŸ¥è¯¢ä¸Šä¸‹æ–‡"""
        self.query_log[query_id] = {
            "text": query_text,
            "results": results,
            "timestamp": now()
        }
    
    def log_implicit_feedback(self, query_id, result_id, action):
        """
        éšå¼åé¦ˆï¼ˆæ— éœ€ç”¨æˆ·ä¸»åŠ¨æ ‡æ³¨ï¼‰
        action âˆˆ {click, hover_time>3s, export, forward}
        """
        feedback = {
            "query_id": query_id,
            "result_id": result_id,
            "action": action,
            "weight": self.action_weights[action]  # click=1.0, hover=0.3
        }
        self.feedback_queue.append(feedback)
    
    def log_explicit_feedback(self, query_id, result_id, rating, comment=""):
        """
        æ˜¾å¼åé¦ˆï¼ˆç”¨æˆ·æ‰“åˆ†ï¼‰
        rating âˆˆ {1: å®Œå…¨æ— å…³, 2: éƒ¨åˆ†ç›¸å…³, 3: ç›¸å…³, 4: é«˜åº¦ç›¸å…³, 5: å®Œç¾}
        """
        feedback = {
            "query_id": query_id,
            "result_id": result_id,
            "rating": rating,
            "comment": comment,
            "weight": 2.0  # æ˜¾å¼åé¦ˆæƒé‡æ›´é«˜
        }
        self.feedback_queue.append(feedback)
    
    def flush_to_learning_engine(self):
        """æ‰¹é‡å‘é€åé¦ˆåˆ°å­¦ä¹ å¼•æ“"""
        batch = self.feedback_queue.pop_all()
        learning_engine.ingest(batch)
```

---

### 6.3.3 åå“ºå­¦ä¹ å¾ªç¯

**æ ¸å¿ƒæœºåˆ¶**ï¼š**å¼ºåŒ–å­¦ä¹ **æ¡†æ¶ï¼Œæ£€ç´¢è´¨é‡ä½œä¸ºå¥–åŠ±ä¿¡å·ï¼Œè°ƒæ•´æŠ½å–ç­–ç•¥ã€‚

**çŠ¶æ€ç©ºé—´ï¼ˆStateï¼‰**ï¼š
```python
state = {
    "detection_thresholds": {"person": 0.5, "vehicle": 0.6, ...},
    "tracking_confidence": 0.7,
    "event_trigger_sensitivity": 0.8,
    "aggregation_granularity": "process",  # å½“å‰æŠ½è±¡å±‚çº§
    "cache_allocation": {"hot": 0.6, "warm": 0.3, "cold": 0.1}
}
```

**åŠ¨ä½œç©ºé—´ï¼ˆActionï¼‰**ï¼š
```python
actions = [
    "increase_person_threshold_0.05",
    "decrease_tracking_confidence_0.1",
    "switch_to_fine_grained_events",
    "expand_cache_hot_pool_10%",
    ...
]  # å…±32ä¸ªç¦»æ•£åŠ¨ä½œ
```

**å¥–åŠ±å‡½æ•°ï¼ˆRewardï¼‰**ï¼š
```python
def compute_reward(feedback_batch):
    """
    å¥–åŠ± = ç”¨æˆ·æ»¡æ„åº¦ - èµ„æºæˆæœ¬
    """
    # æ»¡æ„åº¦ï¼ˆæ¥è‡ªæ˜¾å¼/éšå¼åé¦ˆï¼‰
    satisfaction = sum(
        f.weight * (f.rating - 3) for f in feedback_batch if hasattr(f, 'rating')
    ) / len(feedback_batch)
    
    # æ£€ç´¢æˆåŠŸç‡ï¼ˆè‡³å°‘1ä¸ªç›¸å…³ç»“æœï¼‰
    success_rate = sum(
        1 for f in feedback_batch if f.rating >= 3
    ) / len(feedback_batch)
    
    # èµ„æºæˆæœ¬ï¼ˆæ„å»º+æŸ¥è¯¢å»¶è¿Ÿï¼‰
    construction_cost = metrics.construction_latency_p95 * 0.3
    query_cost = metrics.avg_query_latency * 0.7
    
    # ç»¼åˆå¥–åŠ±ï¼ˆå½’ä¸€åŒ–åˆ°[-1, 1]ï¼‰
    reward = 0.6 * satisfaction + 0.4 * success_rate - 0.1 * (construction_cost + query_cost) / 1000
    
    return clamp(reward, -1, 1)
```

**å­¦ä¹ ç®—æ³•**ï¼š**PPOï¼ˆProximal Policy Optimizationï¼‰**
```python
class RetrieverTrainer:
    def __init__(self):
        self.policy_network = PPONetwork(state_dim=64, action_dim=32)
        self.experience_buffer = deque(maxlen=10000)
    
    def train_step(self):
        # 1. é‡‡æ ·ç»éªŒ
        batch = self.experience_buffer.sample(batch_size=256)
        
        # 2. è®¡ç®—ä¼˜åŠ¿å‡½æ•°
        advantages = compute_gae(batch.rewards, batch.values)
        
        # 3. ç­–ç•¥æ›´æ–°ï¼ˆè£å‰ªé¿å…è¿‡å¤§æ›´æ–°ï¼‰
        for _ in range(epochs=4):
            loss = self.policy_network.update(batch, advantages, clip_epsilon=0.2)
        
        # 4. åº”ç”¨æ–°ç­–ç•¥åˆ°æŠ½å–ç®¡çº¿
        new_thresholds = self.policy_network.act(current_state())
        apply_to_extraction_pipeline(new_thresholds)
```

**è®­ç»ƒé¢‘ç‡**ï¼šæ¯**1000æ¡**åé¦ˆè¿›è¡Œä¸€æ¬¡æ¢¯åº¦æ›´æ–°ï¼Œæ¯**24å°æ—¶**åº”ç”¨æ–°ç­–ç•¥ã€‚

---

### 6.3.4 å†·å¯åŠ¨ä¸æ¢ç´¢-åˆ©ç”¨å¹³è¡¡

**å†·å¯åŠ¨é—®é¢˜**ï¼šç³»ç»Ÿä¸Šçº¿åˆæœŸæ— åé¦ˆæ•°æ®ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. **ä¸“å®¶å…ˆéªŒ**ï¼šåˆå§‹ç­–ç•¥æ¥è‡ªäººå·¥è°ƒä¼˜å‚æ•°ï¼ˆè§„åˆ™åŸºçº¿ï¼‰
2. **ä»¿çœŸç¯å¢ƒ**ï¼šåœ¨æ ‡æ³¨æ•°æ®é›†ä¸Šæ¨¡æ‹Ÿç”¨æˆ·åé¦ˆï¼Œé¢„è®­ç»ƒç­–ç•¥
3. **Îµ-è´ªå¿ƒæ¢ç´¢**ï¼šå‰7å¤©ä¿æŒÎµ=0.3çš„éšæœºæ¢ç´¢ç‡ï¼Œé€æ­¥è¡°å‡è‡³0.05

**æ¢ç´¢ä¿æŠ¤æœºåˆ¶**ï¼š
- éšæœºåŠ¨ä½œä»…åº”ç”¨äº5%çš„**éå…³é”®æŸ¥è¯¢**ï¼ˆå¦‚å†å²å›æ”¾ï¼‰
- å…³é”®æŸ¥è¯¢ï¼ˆå¦‚å®‰é˜²å‘Šè­¦ï¼‰**å¼ºåˆ¶ä½¿ç”¨ä¿å®ˆç­–ç•¥**

---

## 6.4 A/Bæµ‹è¯•æ¡†æ¶

### 6.4.1 åˆ†å±‚æµ‹è¯•è®¾è®¡

æ”¯æŒ**å¤šç»´åº¦å¹¶è¡Œå®éªŒ**ï¼Œé¿å…ç›¸äº’å¹²æ‰°ï¼š

```python
experiment_matrix = {
    "layer1:_extraction": {
        "control": "baseline_yolov8",
        "treatment_A": "yolov8 + StrongSORT",
        "treatment_B": "yolov9 + BotSORT"
    },
    "layer2:temporal_modeling": {
        "control": "fuzzy_interval",
        "treatment": "probabilistic_temporal"
    },
    "layer3:retrieval_ranking": {
        "control": "salience_ranker_v1",
        "treatment": "salience_ranker_v2 + LLM_rerank"
    }
}

# æ¯ä¸ªæŸ¥è¯¢æŒ‰å“ˆå¸Œåˆ†é…åˆ°å„å±‚çš„ä¸€ä¸ªæ¡¶
def assign_buckets(query_id):
    return {
        "extraction": hash(query_id + "layer1") % 3,
        "temporal": hash(query_id + "layer2") % 2,
        "ranking": hash(query_id + "layer3") % 2
    }
```

**éš”ç¦»ä¿éšœ**ï¼š
- å±‚å†…äº’æ–¥ï¼ˆæ¯ä¸ªæŸ¥è¯¢åªä½¿ç”¨ä¸€ä¸ªå˜ä½“ï¼‰
- å±‚é—´æ­£äº¤ï¼ˆå„å±‚å†³ç­–ç‹¬ç«‹ï¼Œå®éªŒæ•ˆæœå¯å åŠ ï¼‰

---

### 6.4.2 ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ

**æ ¸å¿ƒæŒ‡æ ‡**ï¼š**ä¼šè¯æˆåŠŸç‡ï¼ˆSession Success Rate, SSRï¼‰**

å®šä¹‰ï¼šç”¨æˆ·è¿ç»­æŸ¥è¯¢ä¸­ï¼Œè‡³å°‘ä¸€æ¬¡æ‰¾åˆ°æ»¡æ„ç»“æœçš„æ¯”ä¾‹ã€‚

**å‡è®¾æ£€éªŒ**ï¼š
```python
def ab_test_significance(control_ssr, treatment_ssr, n_control, n_treatment, alpha=0.05):
    """
    ä½¿ç”¨Zæ£€éªŒæ¯”è¾ƒä¸¤ä¸ªæ¯”ä¾‹
    """
    p_pool = (control_ssr * n_control + treatment_ssr * n_treatment) / (n_control + n_treatment)
    
    se = sqrt(p_pool * (1 - p_pool) * (1/n_control + 1/n_treatment))
    
    z_stat = (treatment_ssr - control_ssr) / se
    
    p_value = 2 * (1 - norm.cdf(abs(z_stat)))
    
    is_significant = p_value < alpha
    
    # æœ€å°å¯æ£€æµ‹æ•ˆåº”ï¼ˆMDEï¼‰
    mde = sqrt(p_pool * (1 - p_pool)) * (norm.ppf(1-alpha/2) + norm.ppf(0.8)) * sqrt(2/n)
    
    return {
        "significant": is_significant,
        "p_value": p_value,
        "z_statistic": z_stat,
        "mde": mde,
        "effect_size": treatment_ssr - control_ssr,
        "recommendation": "launch" if is_significant and (treatment_ssr - control_ssr) > mde else "hold"
    }
```

**æ ·æœ¬é‡è¦æ±‚**ï¼šæ¯ä¸ªå˜ä½“è‡³å°‘ **5000æ¬¡** æŸ¥è¯¢ï¼Œç¡®ä¿ç»Ÿè®¡åŠŸæ•ˆ **>80%**ã€‚

---

## 6.5 å®¡è®¡ä¸å¯è§£é‡Šæ€§

### 6.5.1 å†³ç­–è¿½æº¯æ—¥å¿—

**æ¯æ¡æ£€ç´¢ç»“æœå¿…é¡»é™„å¸¦"å†³ç­–é“¾"**ï¼Œè§£é‡Šä¸ºä½•è¿”å›è¯¥ç»“æœï¼š

```json
{
  "result_id": "evt_20240115_143022_001",
  "decision_chain": [
    {
      "step": 1,
      "action": "IndexScan",
      "details": "ä½¿ç”¨ST-R*æ ‘æ‰«ææ—¶é—´åŒºé—´[2024-01-15 14:00, 2024-01-15 15:00]ï¼Œå‘½ä¸­3ä¸ªTimeSlice",
      "latency_ms": 8
    },
    {
      "step": 2,
      "action": "EntityFilter",
      "details": "åœ¨å€’æ’ç´¢å¼•ä¸­æŸ¥æ‰¾entity_id='person_001'ï¼ŒåŒ¹é…åˆ°2ä¸ªäº‹ä»¶",
      "latency_ms": 3
    },
    {
      "step": 3,
      "action": "SalienceScoring",
      "details": "å› æœä¸­å¿ƒæ€§=0.72, æ—¶é—´æ–°é¢–æ€§=0.85, ç»¼åˆå¾—åˆ†=0.78 > é˜ˆå€¼0.6",
      "latency_ms": 12
    },
    {
      "step": 4,
      "action": "ResultRanking",
      "details": "åœ¨Top-Kæ’åºä¸­ä½åˆ—ç¬¬3ï¼Œå› ç”¨æˆ·æœªæŒ‡å®šLIMIT 10è€Œè¿”å›"
    }
  ],
  "confidence": 0.78,
  "alternative_considered": [
    {
      "event_id": "evt_20240115_143022_002",
      "rejection_reason": "å‚ä¸è€…ç½®ä¿¡åº¦0.45 < é˜ˆå€¼0.7"
    }
  ]
}
```

**å®¡è®¡ä»·å€¼**ï¼š
- **åˆè§„**ï¼šå¸æ³•å–è¯æ—¶è¯æ˜æ£€ç´¢è¿‡ç¨‹çš„å®¢è§‚æ€§
- **è°ƒè¯•**ï¼šç”¨æˆ·è´¨ç–‘ç»“æœæ—¶å¯å¿«é€Ÿå®šä½é—®é¢˜ç¯èŠ‚
- **å­¦ä¹ **ï¼šåˆ†æ"è¯¯æ‹’"æ¡ˆä¾‹ï¼Œä¼˜åŒ–æ’åºç®—æ³•

---

### 6.5.2 åäº‹å®è§£é‡Š

**ä¸ä»…è§£é‡Š"ä¸ºä½•è¿”å›A"ï¼Œè¿˜è¦è§£é‡Š"ä¸ºä½•ä¸è¿”å›B"**ã€‚

**å®ç°**ï¼š**åäº‹å®æ¨ç†å¼•æ“**
```python
def generate_counterfactual_explanation(query, returned_results, missing_result_id):
    """
    ç”Ÿæˆ"ä¸ºä½•ç»“æœXæœªè¿”å›"çš„è§£é‡Š
    """
    missing_event = graph.load_node(missing_result_id)
    
    # æ£€æŸ¥æ¯ä¸ªå†³ç­–ç¯èŠ‚
    explanations = []
    
    # 1. ç´¢å¼•ç¯èŠ‚
    if not index_covers(missing_event, query.time_range, query.space_range):
        explanations.append(
            f"äº‹ä»¶{missing_event.id}ä¸åœ¨æŸ¥è¯¢çš„æ—¶ç©ºèŒƒå›´å†…ï¼ˆå‘ç”Ÿåœ¨{missing_event.time}ï¼Œ"
            f"è€ŒæŸ¥è¯¢åªè¦†ç›–{query.time_range}ï¼‰"
        )
    
    # 2. ç½®ä¿¡åº¦ç¯èŠ‚
    if missing_event.confidence < query.min_confidence:
        explanations.append(
            f"äº‹ä»¶{missing_event.id}çš„ç½®ä¿¡åº¦({missing_event.confidence})ä½äºæŸ¥è¯¢é˜ˆå€¼"
            f"({query.min_confidence})"
        )
    
    # 3. æ’åºç¯èŠ‚
    if missing_event.salience_score < returned_results[-1].salience_score:
        explanations.append(
            f"äº‹ä»¶{missing_event.id}çš„æ˜¾è‘—æ€§å¾—åˆ†({missing_event.salience_score:.2f})ä½äº"
            f"è¿”å›ç»“æœä¸­æœ€ä½åˆ†({returned_results[-1].salience_score:.2f})"
        )
    
    # 4. å› æœç¯èŠ‚ï¼ˆå¦‚æœæ˜¯å› æœæŸ¥è¯¢ï¼‰
    if query.pattern_type == "P4":
        if not graph.has_path(missing_event, query.effect_event, max_hops=5):
            explanations.append(
                f"äº‹ä»¶{missing_event.id}ä¸æŸ¥è¯¢ç»“æœ{query.effect_event}ä¹‹é—´"
                f"æœªå‘ç°å¯ä¿¡çš„å› æœè·¯å¾„"
            )
    
    return {
        "missing_event_id": missing_result_id,
        "explanations": explanations,
        "remediation_suggestion": "å°è¯•æ‰©å¤§æ—¶é—´èŒƒå›´æˆ–é™ä½ç½®ä¿¡åº¦é˜ˆå€¼"
    }
```

---

## 6.6 æœ¬ç« å°ç»“

æœ¬æ¨¡å—æ„å»ºäº†**åº¦é‡-åé¦ˆ-æ”¹è¿›**çš„å®Œæ•´é—­ç¯ï¼š

1. **å®šé‡è¯„ä¼°**ï¼šSTFä¸CIçš„ç²¾ç¡®è®¡ç®—ï¼Œä»ç†è®ºèµ°å‘å¯æµ‹
2. **æ•ˆç‡ç›‘æ§**ï¼šæŸ¥è¯¢å»¶è¿Ÿåˆ†è§£ä¸ç¼“å­˜å‘½ä¸­ç‡ï¼Œä¿éšœç”¨æˆ·ä½“éªŒ
3. **åœ¨çº¿å­¦ä¹ **ï¼šå¼ºåŒ–å­¦ä¹ æ¡†æ¶å°†ç”¨æˆ·åé¦ˆè‡ªåŠ¨è½¬ä¸ºç­–ç•¥ä¼˜åŒ–
4. **ç§‘å­¦è¿­ä»£**ï¼šA/Bæµ‹è¯•ç¡®ä¿æ¯æ¬¡æ”¹è¿›å¯é‡åŒ–ã€å¯å›æ»š
5. **å¯è§£é‡Šæ€§**ï¼šå†³ç­–é“¾ä¸åäº‹å®è§£é‡Šå»ºç«‹ç”¨æˆ·ä¿¡ä»»

è¿™å¥—ä½“ç³»ä½¿STKGç³»ç»Ÿå…·å¤‡**è‡ªæˆ‘è¿›åŒ–**èƒ½åŠ›ï¼Œè¶Šç”¨è¶Šèªæ˜ã€‚

---

â¡ï¸ **ä¸‹ä¸€æ¨¡å—é¢„å‘Š**ï¼šã€Šæ¨¡å—ä¸ƒï¼šå®æ–½è·¯çº¿å›¾ä¸å·¥å…·é“¾ã€‹å°†æä¾›**åˆ†é˜¶æ®µè½åœ°è®¡åˆ’**ã€æŠ€æœ¯é€‰å‹å»ºè®®ä¸SDKè®¾è®¡ï¼Œæ˜¯å·¥ç¨‹å®è·µçš„æ”¶å®˜ä¹‹ä½œã€‚

---

*æ–‡æ¡£ç¼–å·ï¼šSTKG-M06-2024*  
*å½“å‰è¿›åº¦ï¼š6/7 æ¨¡å—*