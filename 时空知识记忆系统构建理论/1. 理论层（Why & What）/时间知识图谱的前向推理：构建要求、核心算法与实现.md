# 时间知识图谱的前向推理：构建要求、核心算法与实现





## 摘要



本报告对用于前向推理（即事件外推）的时间知识图谱 (Temporal Knowledge Graphs, TKG) 的构建要求、核心算法和实现资源进行了全面而深入的分析。基于对领域内高影响力研究（按引用数排序）的系统性回顾，我们首先阐明了 TKG 构建（问题一）与推理算法（问题二）之间密不可分的依赖关系。报告详细剖析了 TKG 的基础数据模型（时间点四元组 vs. 时间区间）、时间表示（连续 vs. 离散快照）以及动态模式（序列、演化）的捕获要求。接着，本报告深度解析了支持前向推理的几类关键算法范式，包括：(a) 基于时间点过程的奠基性模型 (如 `Know-Evolve`)；(b) 基于几何嵌入的模型 (如 `HyTE`)；(c) 基于序列和自回归的模型 (如 `RE-Net`)；(d) 基于图神经网络的模型 (如 `TeMP`)；以及 (e) 先进的、可解释的推理范式，如强化学习 (如 `TimeTraveler`) 和时间逻辑规则 (如 `TLogic`)。对于每种算法，我们都详述了其核心机制、假设、优势和局限性。最后，本报告（问题三）梳理了这些关键模型的官方代码库以及用于大规模时间图学习的综合性框架（如 `TGL`, `DGL`）。报告最后总结了关键权衡，并展望了 2024-2025 年的新兴趋势，特别是因果推理和大型语言模型 (LLM) 与 TKG 的融合。

------



## 第一部分：支持前向推理的 TKG 构建：基础要求与模型依赖性





### 1.1 引言：构建要求 (Q1) 与推理算法 (Q2) 的共生关系



在探讨构建时间知识图谱 (TKG) 以支持前向推理（即事件外推）的要求时，一个核心的观点是：**TKG 的构建要求（问题一）并非独立存在，而是由所选用的推理算法（问题二）反向定义的。**

这种共生关系意味着，选择何种算法范式，将直接决定了数据必须如何被建模和表示。例如：

1. 如果选用**强化学习 (RL)** 方法（如 `TimeTraveler`），其核心机制是智能体 (Agent) 在图的“历史快照”上“行走”。这就要求 TKG 必须被构建为一系列离散的时间图快照（$G^1, G^2, \ldots, G^t$）1。
2. 相反，如果选用**时间点过程 (Temporal Point Process)** 方法（如 `Know-Evolve`），其核心是对事件的连续强度函数 $\lambda(t)$ 进行建模。这就要求 TKG 必须保留高精度、连续的时间戳 $t \in \mathbb{R}^+$ 3。

因此，在着手构建 TKG 之前，必须首先理解可用的推理范式（见第二部分），并根据应用需求（例如，需要预测“什么”vs. 预测“何时”）预先选择一个算法家族。本部分将详细阐述这些构建块。



### 1.2 数据模型：事实的表示



TKG 中事实的表示方式主要分为两大类：时间点和时间区间。



#### 1.2.1 时间点四元组 (Timestamped Quadruples): $(s, r, o, t)$



这是 TKG 中最通用、最基础的表示法。它将一个事实（fact）或“事件”（event）表示为主体 $s$ (subject)、关系 $r$ (relation)、客体 $o$ (object) 和一个单一的时间点 $t$ (timestamp) 3。

- **适用算法：** 这种表示法是绝大多数 TKG 推理模型的基础，特别是那些处理瞬时事件流的模型，如 `Know-Evolve` 3, `RE-Net` 6, 和 `TLogic` 5。
- **构建要求：** 它要求上游的数据处理流程（例如，事件抽取）能够精确地识别事件发生的具体时间点。



#### 1.2.2 时间区间 (Time Intervals): $(s, r, o, [t_{start}, t_{end}])$



这种模型更适用于表示具有持续时间的“状态”（states），而非瞬时“事件”。例如，一个事实如 (Cristiano Ronaldo, *playsFor*, Manchester United, ) 7。

- **适用算法：** 少数模型（如 `HyTE` 的概念 7）或逻辑规则模型（如 `TLogic` 5 的扩展）可以处理时间区间。
- **构建挑战：** 对于前向推理而言，预测一个未来区间的开始 $t_{start}$ 和结束 $t_{end}$，在数学上比预测一个单一的未来事件点 $t$ 要困难得多。因此，绝大多数“事件预测”任务都集中在时间点四元组上。



### 1.3 时间表示：数学建模



如何将时间 $t$ 整合到数学模型中，是 TKG 构建的另一个核心要求。



#### 1.3.1 离散时间（快照序列）(Discrete Time - Snapshot Sequences)



这种方法将 TKG 建模为一系列离散的图快照 $G = \{G^1, G^2, \ldots, G^T\}$ 1。

- **构建要求：** 这种方法牺牲了时间粒度（例如，将一天内所有事件聚合到 $G^{day}$），但极大地简化了问题。它允许将成熟的静态图神经网络 (GNN) 架构与循环神经网络 (RNN) 结合使用——GNN 在每个 $G^t$内部聚合空间信息，RNN 在 $t, t+1, \ldots$ 之间传递时间信息。
- **适用算法：**
  - `TimeTraveler` 1 显式地在其历史快照上行走。
  - `TeMP` 8 在快照内使用 GNN 并在快照间使用时间模型。
  - `RE-Net` 6 也依赖于事件序列，这在本质上是离散的。



#### 1.3.2 连续时间 (Continuous Time)



这种方法将时间 $t$ 视为一个连续的实数变量 $t \in \mathbb{R}^+$。这允许模型学习实体和关系随时间*平滑演变*的动态函数。

- **构建要求：** 数据必须保留高精度的时间戳。
- **适用算法：**
  - `Know-Evolve` 3：使用时间点过程，其强度函数 $\lambda(t)$ 是连续的。
  - `Neural Ordinary Equations (NODE)` 9：一个更高级的概念，其中实体/关系的演变被建模为常微分方程 (ODE) 的解，从而在时间上实现连续模型。

一个关键的区别在于：连续时间模型（如 `Know-Evolve`）在理论上更具表现力，因为它们可以预测 *何时*(when) 事件会发生（即预测 $t$）11。相比之下，大多数离散模型只能在给定的未来时间戳 $\tau$ 预测 *什么*(what) 事件会发生（即预测 $o$ for $(s, r,?, \tau)$）。



### 1.4 动态模式的捕获：构建要求



前向推理算法依赖于从历史数据中捕获特定的动态模式。TKG 的构建必须支持这些模式的提取。

- 序列依赖性 (Sequential Dependency) -> 自回归模型

  许多模型（如 RE-Net 6）假设事件的发生具有自回归 (autoregressive) 性质，即当前事件依赖于历史事件序列。Learning Sequence Encoders 14 也使用 RNN 来捕获这种时序依赖性。

- 结构依赖性 (Structural Dependency) -> GNN 模型

  预测未来的链接不仅取决于该实体的历史，还取决于其邻居的当前/历史状态。TeMP 8 引入了时间消息传递 (Temporal Message Passing)，TKG 的构建必须支持这种邻域聚合。

- 周期性与重复性 (Periodicity and Repetition) -> 规则与拷贝模型

  许多真实世界事件是周期性或重复的（例如，经济危机、外交活动）15。TLogic 5 通过随机游走发现这些重复模式并将其提炼为时间逻辑规则。CyGNet 15（一个相关模型）引入了拷贝机制 (copy-generation mechanism)，明确地从历史中“拷贝”事实到未来。

------



## 第二部分：基于 TKG 的前向推理算法深度解析



本部分将按照研究材料中反映的影响力（即引用数）排序，系统地回顾和解析关键的前向推理算法范式。

**影响力排序 (基于研究材料):** `Know-Evolve` (~710) 17 > `HyTE` (~602) 18 > `RE-Net` (~597) 13 > `Diachronic Embedding` (~488) 19 > `Learning Sequence Encoders` (~449) 14 > `TimeTraveler` (~229) 20 > `TeMP` (~203) 21 > `TLogic` (~200) 20。



### 2.1 范式一：连续时间与演化过程 (奠基性工作)





#### 2.1.1 Know-Evolve (Trivedi et al., 2017)



`Know-Evolve` 是一项高影响力的奠基性工作，它引入了一种**深度进化知识网络 (deep evolutionary knowledge network)** 4。

- **核心算法：** 该模型的核心是**时间点过程 (Temporal Point Process)** 3。
- **推理机制：** `Know-Evolve` 不直接预测四元组，而是为每个潜在事实 $(s,r,o)$ 计算一个随时间 $t$ 变化的**强度函数 (intensity function) $\lambda_{s,r,o}(t)$** 4。这个函数的值越高，意味着该事实在时间 $t$ 发生的瞬时概率越大。
- **演化：** 实体表示 (entity representations) 会随着时间的推移**非线性地演化 (non-linearly evolving)** 3。当一个事件（事实）在 $t$ 时刻实际发生时，它会触发一个**深度循环网络 (deep recurrent network)** 来更新所涉及实体（$s$ 和 $o$）的潜在表示 3。
- **前向推理：** 预测 $(s, r,?, t_{future})$ 变为：计算在 $t_{future}$ 时刻，所有可能的 $o_i$ 中哪一个使得 $\lambda_{s,r,o_i}(t_{future})$ 最大。如前所述，该模型还能够预测事件的*发生时间* 11。



### 2.2 范式二：几何嵌入





#### 2.2.1 HyTE (Dasgupta et al., 2018)



`HyTE` 18 是一种基于**超平面 (Hyperplane-based)** 的时间感知嵌入方法。

- **核心算法：** `HyTE` 明确地将时间纳入实体-关系空间 23。它**将每个时间戳 $t$ 与一个对应的超平面 $H_t$相关联** 7。
- **推理机制：** 实体和关系被投影到这些随时间变化的超平面上。一个事实 $(s, r, o)$ 在时间 $t$ 成立，当且仅当它们在 $H_t$ 上的投影满足某种几何约束（例如，类似于 TransE 的 $s_t + r_t \approx o_t$）。
- **前向推理：** 预测 $(s, r,?, t_{future})$ 意味着首先确定 $t_{future}$ 对应的超平面 $H_{future}$（通常通过插值或外推学习到的时间超平面函数），然后在该超平面上找到最能满足约束的实体 $o_i$。



#### 2.2.2 基于旋转的模型 (Rotation-based Models) (e.g., TeRo, ChronoR)



作为几何范式的补充，`TeRo` 25 和 `ChronoR` 27 将时间演化定义为**复数向量空间 (complex vector space) 中的旋转 (Rotation)**。实体在 $t_0$ 时刻有一个基础嵌入 $e$，在 $t$ 时刻的嵌入 $e_t$ 是 $e$ 经过某个与 $(r, t)$ 相关的旋转函数得到的。这种方法将时间建模为一种固有的“流动”或“演化”，相比 `HyTE` 为每个时间戳学习单独的参数化（超平面），这种方式通常更节省参数且能更平滑地处理时间。



### 2.3 范式三：序列与自回归模型



这种范式的出现，标志着研究界认识到 TKG 推理不仅是一个*图*问题，更是一个*序列*问题。



#### 2.3.1 Recurrent Event Network (RE-Net) (Jin et al., 2019/20)



`RE-Net` 13 是一个专为预测未来交互而设计的**自回归 (autoregressive) 架构** 6。

- **核心算法：** 将事实的发生建模为基于*历史知识图序列*的条件概率分布 6。
- **推理机制：** `RE-Net` 依赖两个关键组件 6：
  1. **循环事件编码器 (Recurrent Event Encoder):** 用于编码*过去*的事实序列（时间维度）。
  2. **邻域聚合器 (Neighborhood Aggregator):** 用于在*同一时间戳*对事实之间的联系进行建模（空间维度）。
- **前向推理：** 该模型以**序列化 (sequential manner)** 的方式推断未来事实 6。它的一个关键优势是能够进行**多步推断 (multi-step inference)** 6，使其非常适合“前向推理”的需求。



#### 2.3.2 Learning Sequence Encoders (García-Durán et al., 2018)



这是一个更早的相关工作 14，它利用**循环神经网络 (RNNs)** 作为序列编码器来学习时间感知的表示 31。它将关系的*历史*编码为一个时间感知的表示，然后使用这个表示来预测链接。



### 2.4 范式四：图神经网络 (GNNs)



GNN 范式解决了 `Know-Evolve` 和 `RE-Net` 的一个隐含问题：`Know-Evolve` 关注实体自身的演化，`RE-Net` 关注实体事件的*序列*。而 GNN 则认为，实体 $s$ 在 $t$ 时刻的演化不仅取决于 $s$ 在 $t-1$ 的状态，还取决于 $s$的**邻居**在 $t-1$ 或 $t$ 时刻的状态。



#### 2.4.1 TeMP (Wu et al., 2020)



`TeMP` 21 的核心是**时间消息传递 (Temporal Message Passing)** 8。

- **核心算法：** `TeMP` 解决了先前模型未能明确利用*多跳结构信息*和*最近时间步的结构*的弱点 8。
- **推理机制：** 它结合了 GNN（在每个时间步 $t$ 的图快照 $G^t$ 内部聚合空间信息）和时间动态模型（如 GRU 或自注意力，在 $G^t, G^{t+1}, \ldots$ 之间聚合时间信息）。它还使用数据插补 (Data Imputation) 和门控 (Gating) 机制来处理时间稀疏性 8。



#### 2.4.2 EvoKG (Park et al., 2022)



`EvoKG` 26 是一个较新的 GNN 模型，它**联合建模事件时间与网络结构 (Jointly modeling event time and network structure)** 33，进一步强化了 GNN 在 TKG 推理中的应用。



### 2.5 范式五：高级推理策略 (强化学习与逻辑规则)



近期的研究转向了更复杂、更可解释的推理范式。



#### 2.5.1 强化学习 (Reinforcement Learning): TimeTraveler (Sun et al., 2021)



`TimeTraveler` 1 是首个将强化学习用于 TKG 预测的方法 2。

- **核心算法：** 将前向推理（预测）表述为**马尔可夫决策过程 (Markov Decision Process, MDP)** 1。
- **构建要求 (Q1):** 该方法有非常具体的构建要求 1：
  1. **历史快照：** 数据必须被构建为一系列图快照 $G^t$。
  2. **图增强：** 必须在图上添加三类特殊的边：**反向边 (Reversed Edges)**（用于预测主语）、**自循环边 (Self-loop Edges)**（用于“停止”动作）和**时间边 (Temporal Edges)**（允许智能体在不同时间的同一实体间“跳跃”）。
- **推理机制 (Q2):**
  1. **智能体 (Agent)：** 一个 RL 智能体在增强的历史图快照上“行走” (travels) 以寻找答案 1。
  2. **时间外推：** 为了处理*未来*时间戳 $\tau_q$（在训练中未见过），`TimeTraveler` 引入了**相对时间编码 (Relative Time Encoding)**，即 $\phi(\Delta) = \phi(\tau_q - t_{fact})$ 1。
  3. **奖励机制：** 设计了一个新颖的**时间奖励 (time-shaped reward)**，该奖励基于**狄利克雷分布 (Dirichlet distribution)**，用于指导模型学习哪些历史快照更可能包含答案 1。
  4. **归纳推理：** `TimeTraveler` 还提出了一种**归纳均值 (Inductive Mean, IM)** 表示法，以处理*未见过的实体*(unseen entities)，这是前向推理中的一个关键挑战 1。



#### 2.5.2 逻辑规则 (Logical Rules): TLogic (Liu et al., 2022)



`TLogic` 35 是一种基于**可解释的时间逻辑规则 (Explainable temporal logical rules)** 的框架 35。

- **核心算法：** 通过数据挖掘提取规则，并使用规则进行推理。
- **构建要求 (Q1):** 需要 $(e_s, r, e_o, t)$ 格式的数据，并需要在 TKG 中定义和添加反向关系 $r^{-1}$，以允许随机游走器在两个方向上移动 5。
- **推理机制 (Q2):**
  1. **规则提取：** 通过在 TKG 上进行**时序随机游走 (temporal random walks)** 来提取**循环时间逻辑规则 (cyclic temporal logical rules)** 5。
  2. **规则格式：** 规则形如 $((E_1, r_h, E_{l+1}, T_{l+1}) \leftarrow \bigwedge_{i=1}^l (E_i, r_i, E_{i+1}, T_i))$，并带有严格的时间约束 $T_1 \leq T_2 \leq \cdots \leq T_l < T_{l+1}$ 5。
  3. **前向推理：** 对于一个查询 $(e_q, r_q,?, t_q)$，模型在 $t_q$ 之前的历史图 $SG$ 中寻找这些规则“主体”(body) 的“接地”(groundings) 5。
  4. **答案评分：** 结合规则的置信度 (confidence) 和一个时间衰减函数（越近的事实越相关），使用 **noisy-OR** 聚合来对候选答案进行评分 5。
- **独特优势：** 1. **可解释性 (Explainability)**：预测结果可以被人类理解的逻辑规则所解释 35。 2. **归纳能力 (Inductive Setting)**：规则是通用的，可以很好地转移到具有相同词汇表的相关数据集 5。



### 表 1：关键 TKG 前向推理模型对比



| **论文 (影响力排名)** | **核心方法论**                        | **时间表示**                      | **数据模型要求**                    | **关键优势**                             |
| --------------------- | ------------------------------------- | --------------------------------- | ----------------------------------- | ---------------------------------------- |
| **Know-Evolve**17     | 时间点过程 (Temporal Point Process)   | 连续时间 $t \in \mathbb{R}^+$     | 高精度时间戳 $(s,r,o,t)$            | 预测*何时* (when) 发生事件；非线性演化 3 |
| **HyTE** 18           | 几何嵌入 (Geometric Embedding)        | 离散时间戳 $t$ 映射到超平面 $H_t$ | $(s,r,o,t)$ 或 $(s,r,o,[t_s, t_e])$ | 参数高效；将时间纳入嵌入空间 [7, 23]     |
| **RE-Net** 13         | 自回归序列模型 (Autoregressive)       | 离散事件序列                      | 事件序列 $(s,r,o,t)_i$              | 专为多步 (multi-step) 未来预测设计 6     |
| **TeMP** 21           | 图神经网络 (GNN)                      | 离散快照 $G^t$                    | 快照序列 $\{G^t\}$                  | 融合了多跳结构信息和时间动态 8           |
| **TimeTraveler**20    | 强化学习 (Reinforcement Learning)     | 离散快照 $G^t$                    | 增强的快照图（含反向/时间边）1      | 可处理未见实体（归纳）；性能强 2         |
| **TLogic** 20         | 时间逻辑规则 (Temporal Logical Rules) | 离散时间戳 $t$                    | $(s,r,o,t)$ 及 $r^{-1}$             | 完全可解释；强大的归纳能力 [5, 35]       |



------



## 第三部分：实用资源：算法库与代码实现



本部分将梳理研究材料中提到的、可用于实现 TKG 前向推理的“开箱即用”的算法库和代码。



### 3.1 关键模型的官方实现



对于第二部分中讨论的许多高影响力模型，研究人员已公开发布了其官方实现代码，这为复现和基准测试提供了基础。

- **Know-Evolve** (Trivedi et al., 2017): `github.com/rstriv/Know-Evolve` 40
- **HyTE** (Dasgupta et al., 2018): `github.com/malllabiisc/HyTE` 23 或 `github.com/SwayambhuNathRay/HyTE-EMNLP-2018` 43
- **Recurrent Event Network (RE-Net)** (Jin et al., 2020): `github.com/INK-USC/RE-Net` 44
- **TeMP** (Wu et al., 2020): `github.com/JiapengWu/TeMP` 44
- **TimeTraveler** (Sun et al., 2021): `github.com/JHL-HUST/TITer` 45
- **TLogic** (Liu et al., 2022): 在 `github.com/DaoSword/Time-Series-Forecasting-and-Deep-Learning` 资源列表中被索引 46
- **EvoKG** (Park et al., 2022): 在 GitHub `temporal-reasoning` 主题中被索引 33



### 3.2 综合性（时间）图学习框架



这些是更通用的“开箱即用”库，它们提供了构建 TKG 推理流程所需的基础设施和工具。



#### 3.2.1 TGL: A General Framework for Temporal GNN Training



这是一个高度契合需求的框架。

- **来源：** 亚马逊 (Amazon Research) 47。
- **功能：** 这是一个用于**十亿规模 (billion-scale)** 时间图训练的通用框架 47。
- **支持的模型：** 它提供了多种时间 GNN 方法的实现，如 `JODIE`, `DySAT`, `TGAT`, `TGN` 47。
- **与查询的契合度：** 极高。该框架明确支持**外推设置 (extrapolation setting)**（即前向推理）47。它要求自定义数据集必须按时间升序排序 47，这符合第一部分中的构建要求。



#### 3.2.2 Deep Graph Library (DGL)



`DGL` 48 是一个通用的 GNN 库。虽然其核心不*仅*针对时间图，但它是许多更高级 TKG 库（如 `TGL` 48 和 `OpenHGNN` 48）的底层依赖和构建块。



#### 3.2.3 PyKeen (Python Knowledge Em-bed-dings)



`PyKeen` 49 是一个用于知识图谱嵌入的流行 Python 库。尽管功能强大，但其主要关注点是*静态* KGE，在 TKG 方面的功能不如 `TGL` 等专用库丰富。



#### 3.2.4 Graphiti



`Graphiti` 50 是一个开源图框架。与 `Zep`（一个完整的 AI 记忆平台）50 相比，`Graphiti` 更多是一个“自己动手 (Build your own)”的框架，需要用户进行大量自定义实现 50。



### 3.3 资源索引 (Resource Compilations)



对于持续跟踪该领域的研究，元资源 (meta-resource) 列表非常有价值。

- **Awesome-Knowledge-Graph-Reasoning** 44
  - **价值：** 这是一个包含 TKG 领域论文、代码和数据集的综合集合 44。
  - **关键结构：** 它对 TKG 推理模型进行了有价值的分类 44：RNN-based, Quadruple-based, Path-based, Graph-based, RNN-agnostic, Time-Vector Guided, Time-Operation Guided。这为研究者提供了一个持续更新的学习路径。



### 表 2：TKG 推理的开源资源



| **资源名称**     | **类别** | **关键支持模型 / 功能**                              | **GitHub (或索引)**                                         |
| ---------------- | -------- | ---------------------------------------------------- | ----------------------------------------------------------- |
| **TGL**          | 综合框架 | 支持十亿规模时间图；支持外推；`JODIE`, `TGAT`, `TGN` | `github.com/amazon-research/tgl` 47                         |
| **DGL**          | 综合框架 | 通用 GNN 框架；TKG 功能的底层依赖                    | `github.com/dmlc/dgl` 48                                    |
| **Awesome-KGR**  | 资源索引 | TKG 论文、代码、数据集的元列表                       | `github.com/LIANGKE23/Awesome-Knowledge-Graph-Reasoning` 44 |
| **TimeTraveler** | 特定模型 | 强化学习 (RL) 进行 TKG 预测                          | `github.com/JHL-HUST/TITer` 45                              |
| **Know-Evolve**  | 特定模型 | 时间点过程 (Temporal Point Process)                  | `github.com/rstriv/Know-Evolve` [40]                        |
| **HyTE**         | 特定模型 | 超平面几何嵌入 (Hyperplane Embedding)                | `github.com/malllabiisc/HyTE` 23                            |
| **RE-Net**       | 特定模型 | 自回归事件网络 (Autoregressive Event Network)        | `github.com/INK-USC/RE-Net` 44                              |
| **TLogic**       | 特定模型 | 时间逻辑规则 (Temporal Logical Rules)                | 索引于 46                                                   |



------



## 第四部分：综合洞察与未来展望





### 4.1 核心权衡与专家建议



在选择 TKG 构建方法和推理算法时，必须考虑几个核心的权衡：

- 性能 vs. 可解释性 (Performance vs. Explainability)

  存在一个明显的权衡。TimeTraveler 2 和 RE-Net 6 等复杂的深度模型（基于 RL 和自回归网络）通常在基准测试（如 Hits@10）上表现最佳。然而，TLogic 35 提供了基于人类可读规则的完全可解释性，这在金融 51、医疗 52 等高风险、需要审计的领域中可能更为重要。

- 连续 vs. 离散时间 (Continuous vs. Discrete Time)

  绝大多数模型（RE-Net, TimeTraveler, TeMP）都将时间离散化为事件序列或快照 1，这在计算上更易于处理。然而，Know-Evolve 3 和 NODE 10 等连续时间模型是唯一能够真正回答“何时” (when) 发生下一事件的模型，而不仅仅是“在 t 时刻会发生什么” (what)。

- 归纳能力 (Inductive Capability)

  “前向推理”的一个核心挑战是处理未见过的实体 (unseen entities) 2。这在现实世界中（例如，新用户、新产品）是常态。TimeTraveler 1 通过其 "Inductive Mean" 表示法显式处理了这个问题。TLogic 5 通过学习抽象的、可转移的规则也具备归纳能力。在选择模型时，必须验证其是否支持归纳设置 (inductive setting)。



### 4.2 2024-2025 年及以后的新兴趋势



基于 2024 年和 2025 年的最新研究预印本，TKG 推理领域正在向两个明确的前沿方向发展：

- 趋势一：因果推理 (Causal Reasoning)

  2024 年的研究 53 提出了一个尖锐的批评：现有的 TKG 推理模型（即第二部分中的所有模型）倾向于学习“有偏见的数据表示 (biased data representations)”和“虚假的（统计）相关性 (spurious correlations)” 53。例如，模型可能会错误地学习到“警报A”和“故障B”总是同时发生，而未能发现它们都是由未观察到的“根本原因C”引起的。

  未来的方向（例如，`CEGRL-TKGR` 53）是解耦 (disentangle) 实体和关系的表示，将其分为**“因果表示 (causal representations)”**和**“混杂表示 (confounding representations)”**，并利用因果干预 (causal intervention) 理论来减轻错误相关的影响 53。

- 趋势二：大型语言模型 (LLM) 与 TKG 的融合

  2024-2025 年的论文 51 表明，研究热点正迅速转向 LLM 与 TKG 的结合。LLM 擅长于非结构化知识和常识推理，但难以处理动态演化的事实（例如，LLM 不知道今天谁是某公司的 CEO）51。TKG 则相反。

  `EvoReasoner` 51 提出了一种时间感知的多跳推理算法 (temporal-aware multi-hop reasoning)，它将 TKG 作为 LLM 的外部、动态更新的知识库。`EvoKG` 51 模块甚至可以从非结构化文档中增量更新 TKG。这可能在未来几年内彻底改变 TKG 领域：构建 TKG (Q1) 的要求可能会转变为“构建一个 LLM 可查询、可增量更新的 TKG” 51，而推理 (Q2) 可能会从 GNN 或 RL 算法转变为由 LLM 指导的“思考-图谱 (Think-on-Graph)” 51 过程。



## 结论



本报告系统性地回答了关于 TKG 前向推理的三个核心问题。

1. **关于构建 (Q1)：** 核心要求是“算法驱动的”。数据模型（时间点 vs. 区间）和时间表示（连续 vs. 离散）的选择必须与所选的推理算法（Q2）相匹配。
2. **关于推理 (Q2)：** 存在多种成熟的算法范式。`Know-Evolve` 17 适用于连续时间预测；`RE-Net` 13 适用于多步序列预测；`TeMP` 21 适用于需要深度结构信息的场景；`TimeTraveler` 20 在归纳性能上表现出色；`TLogic` 20提供了宝贵的可解释性。
3. **关于实现 (Q3)：** 该领域拥有丰富的开源生态系统，包括上述所有关键模型的官方代码库（如 `github.com/JHL-HUST/TITer` 45），以及如 `TGL` 47 这样专为大规模时间图外推而设计的“开箱即用”框架。

最终，我们认为，该领域的未来将由因果推理 53 和大型语言模型 51 重新定义，这将为时间感知的人工智能开辟新的可能性。