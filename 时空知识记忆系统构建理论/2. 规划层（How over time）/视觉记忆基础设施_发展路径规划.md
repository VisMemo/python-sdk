# 视觉记忆基础设施发展路径规划

**版本**：v0.1  
**日期**：2025-11-14  
**目标**：从当前单体实验系统，逐步演进为一个通用的、多租户、安全可运维的「记忆基础设施」（Memory Infrastructure）：  
- 同时支持视觉、文本等多模态长期记忆；  
- 对租户提供记忆托管服务；  
- 对开发者提供稳定、可组合的记忆层 API（HTTP / MCP / SDK）；  
- 支撑未来 Agent / 应用把“记忆”当成底座能力来使用。

> 配套参考文档：  
> - 理论基础：`docs/时空知识记忆系统构建理论/时空知识图谱的本体论与信息论基础.md`  
> - 当前差异与需求总结：`docs/时空知识记忆系统构建理论/系统讨论_需求与方案总结.md`  
> - 视觉路线设计：`docs/时空知识记忆系统构建理论/视觉记忆的三条路线.md`

---

## 0. 总体演进视图

按「从内到外、从理论到工程」分为六个阶段（可并行推进，但优先级如图）：

1. **阶段 1：物理时间轴与时空标注落地**（Time Axis v1）  
2. **阶段 2：多租户隔离与安全托管**（Multi-tenant & Auth）  
3. **阶段 3：智能图构建与结构化回想**（Graph & Episodic APIs）  
4. **阶段 4：CI/CD、容器化与可运维化**（CI/CD & Containerization）  
5. **阶段 5：通用文本记忆/知识抽取管线**（Text Memory & KG）  
6. **阶段 6：SaaS 化与生态化闭环**（SaaS & Ecosystem）  
7. **阶段 7：时间知识图谱与前向预测推理**（Temporal KG & Forward Inference）

大致时间预估（以“连续演进”方式，非硬性）：
- 阶段 1–2：T0–T+3 个月（高优先级，打牢“时间+租户”基础）。  
- 阶段 3：T+2–T+6 个月（图结构与智能回想对齐理论）。  
- 阶段 4：T+3–T+6 个月（与阶段 3 部分并行）。  
- 阶段 5：T+5–T+9 个月（统一视觉/文本记忆能力）。  
- 阶段 6：T+8 个月之后（产品化与生态扩展）。  
- 阶段 7：T+9 个月之后（在稳定记忆图之上引入前向预测能力，可作为可选增强模块）。

---

## 1. 阶段 1：物理时间轴与时空标注落地（Time Axis v1）

**目标**：把“物理世界时间”明确写进数据模型与 API，使任一记忆条目都能在时间轴上被定位，并区分物理时间 vs 媒体内部时间。

### 1.1 核心设计

- 媒体级时间（Media Time）：  
  - 为每个视频/音频/流对象添加并强制存储：  
    - `recorded_at`: UTC 录制起始时间（可为空）。  
    - `duration_seconds`: 时长。  
    - `has_physical_time: bool`: 是否可信锚定物理时间。  
- 事件/记忆级时间（Event Time）：  
  - 在 `MemoryEntry.metadata` 中规范字段：  
    - `t_media_start`, `t_media_end`: 相对媒体起点的时间偏移。  
    - `t_abs_start`, `t_abs_end`: 若 `has_physical_time=true` 则 = `recorded_at + t_media_*`。  
  - 增加 `time_origin`: `'physical' | 'media' | 'ingestion'`，辅助查询与审计；可选增加 `time_source`（设备时间/人工标注/服务端时间）与 `time_confidence`（0–1）以便未来扩展对齐与不确定性建模。  
  - 注意区分：  
    - `MemoryEntry` 上的时间字段视为“证据时间”（具体帧/utterance 的时间定位）；  
    - `EVENT` 节点上的时间区间视为“规范化事件时间”，用于图查询、STFTemporal 评估与 TKG 前向推理。
- 搜索语义约定：  
  - `SearchFilters.time_range` 默认作用在 **绝对时间**（`t_abs_*`），仅对 `has_physical_time=true` 条目有效；  
  - 保留扩展位：`time_range_kind = 'absolute' | 'media'`（后续版本可加入）。

### 1.2 关键工作项

1. **模型层修改**  
   - 在 `MemoryEntry.metadata` 约定上述字段，并在写入路径统一规范：  
     - `modules/memorization_agent` 在构建 episodic 记忆时，写入 `t_media_start/end` 与 `clip_id`。  
     - 视频 ingest 层负责写 `recorded_at / duration / has_physical_time`。  
     - 在构建 `EVENT` 节点的步骤中，从一组相关 `MemoryEntry` 的证据时间聚合得到事件级 `t_media_start/end`，并在 `has_physical_time=true` 时计算事件级 `t_abs_*`。  
2. **搜索与 API 层对齐**  
   - 调整 `MemoryService.search()` 与 `timeline_summary()`：  
     - 在构造 `SearchFilters` 时，明确解析时间语义。  
     - `timeline_summary` 输出中显式包含 `t_media_*` 与 `t_abs_*`。  
3. **迁移与兼容**  
   - 对已有数据：  
     - 若无 `recorded_at`，则 `has_physical_time=false`，保留原有行为。  
   - 确保 `/search`、`/timeline_summary` 的旧调用不会因为新字段而破坏兼容。

### 1.3 阶段目标 & 检验标准

   - 要么被明确标记为逻辑时间/内部时间。  
- **/timeline_summary** 能可靠回答“某段物理时间窗口内发生了什么”。  
- **防御性时间清洗**：所有入库数据经过“时间戳清洗器”，处理设备时钟漂移（Drift）与异常回退（Fallback to Server Time）。
- 所有新写入的视频类记忆都带上时间元信息。
 - 在带标注的测试集上，对采样事件计算时间区间 IoU（`STFTemporal`）的均值和分布，作为时序保真度基线指标。

---

## 2. 阶段 2：多租户隔离与记忆托管（Multi-tenant & Auth）

**目标**：以“用户=租户”为隔离单位，实现安全的 API Key 访问控制与数据层隔离，铺路给 SaaS 化与 Agent 接入。

### 2.1 身份模型设计

- `tenant_id`（内部）：  
  - 每个最终用户一个 `tenant_id`，仅存在于服务端。  
- `api_key`（外部凭证）：  
  - 随机字符串（仅存 hash）；  
  - 映射关系：`api_key → { tenant_id, scopes, integration_id?, expires_at }`。  
- `user_id` / `memory_domain` / `run_id`：  
  - 作为租户内部的子命名空间，不得跨越 `tenant_id`。

### 2.2 数据层隔离

- Qdrant：  
  - **逻辑隔离**：利用 Payload Partitioning，将 `tenant_id` 作为 Payload 索引字段，实现低成本高性能隔离。  
  - 所有 `search_vectors` / `upsert` / `delete` 封装在 adapter 中，自动注入 `tenant_id` 过滤。  
- Neo4j：  
  - **逻辑隔离（标准版）**：所有节点/边带 `tenant_id` 属性 + **强制复合索引** `(tenant_id, label)`；代码层封装 Query Rewriter 自动注入 `WHERE` 子句。  
  - **物理隔离（企业版/VIP）**：预留 Multi-Database 或独立实例架构，供高付费/高合规客户使用。

### 2.3 API 与 MCP 集成

- HTTP 层：  
  - 统一采用 `Authorization: Bearer <api-key>` 或自定义 header；  
  - FastAPI 中加入认证中间件：  
    - 解析 API Key → 查表 → 注入 `tenant_id` 到上下文。  
  - `/write`、`/update`、`/delete`、`/search` 等接口内部严格使用上下文 `tenant_id`，忽略客户端传入的任何 `tenant` 信息。  
- MCP / Agent 工具：  
  - Tool 配置中让最终用户填 `MOYAN_API_KEY`；  
  - MCP 侧仅负责把 Key 放到请求头，不感知 `tenant_id` 细节。

### 2.4 阶段目标 & 检验标准

- 不同 API Key 的用户无法通过 API 访问到任何对方的记录（包含向量与图节点）。  
- 单个 tenant 的数据可以被完整导入/导出，便于备份与迁移。  
- MCP/Agent 能在不改代码的情况下，以“填入 Key”方式挂接记忆服务。

---

## 3. 阶段 3：智能图构建与结构化回想（Graph & Episodic APIs）

**目标**：在现有 `MemoryService` 能力之上，把“图”从搜索增强工具升级为“事件-角色时空世界模型”的骨架，让所有情节回想 API 都围绕统一的事件/角色异构图工作，对齐《时空知识图谱的本体论与信息论基础》中 STH 的抽象。

### 3.0 现状与动机

- 现状：  
  - 图中的节点基本对齐 `MemoryEntry` 条目本身，缺少独立的 `EVENT` / `CHARACTER` 等一等公民节点。  
  - 边多为启发式（`APPEARS_IN`、`SAID_BY`、`LOCATED_IN` 等），主要用于 `search()` 时的邻居加分和简单解释。  
  - `/timeline_summary`、`/object_search`、`/entity_event_anchor`、`/speech_search` 等 API 各自用不同的局部逻辑处理“情节/时间线”，难以统一为“在一张事件图上查询”。  
- 问题：  
  - 很难直接基于图回答“谁在什么时间段经历了哪些事件”“事件与事件之间有什么链条/因果关系”；  
  - 理论中提出的时空超图 STH、STF/CI 指标难以直接落地度量。  
- 方向：  
  - 将图建模调整为以 **事件（Event）+ 角色（Character）+ 场所/物体 + 时空边** 为中心的异构时空图；  
  - 把所有“回想 API（timeline/object/entity/speech）”统一视为对这张图的不同视角查询。

### 3.1 图建模强化

- 事件-角色异构图作为骨架：  
  - 节点类型（至少）：  
    - `CHARACTER`：长期稳定身份（由 face/voice/name 等融合），每人一个 `character_id`；  
    - `EVENT`：情节单位，具有时间区间与参与者；  
    - `PLACE` / `OBJECT`：重要场所与物体；  
    - `MEDIA_SEGMENT` / `UTTERANCE`：证据层（关键帧/clip/语句等）；  
    - `KNOWLEDGE`：长期事实/偏好（语义记忆）。  
  - 边类型（示意）：  
    - `INVOLVES (EVENT → CHARACTER/OBJECT)`：谁/什么参与了事件；  
    - `OCCURS_AT (EVENT → PLACE)`：事件发生场所；  
    - `TEMPORAL_NEXT` / `CAUSES? (EVENT → EVENT)`：时间先后/潜在因果；  
    - `DESCRIBES (KNOWLEDGE → EVENT)`：语义总结指向事件；  
    - `FACE_OF` / `VOICE_OF` / `EQUIV (FACE/VOICE → CHARACTER)`：多模态身份归一。  
- 统一 `Event` schema：  
  - 为 `timeline_summary` / `entity_event_anchor` 等 API 定义统一 `Event` 结构：  
    - `Event = { id, t_media_start/end, t_abs_start/end?, actors[character_id], objects[object_id], place_id?, description, source_entries[] }`。  
  - 在 Neo4j 中显式引入 `EVENT` 标签节点，并保证从 `memorization_agent` 输出的“事实表”能构造出这些节点和相关边。
 - Event ↔ MemoryEntry 关系：  
   - `MemoryEntry` 仍作为唯一的存储与证据单元（向量、原文、关键帧等全部挂在这里）；  
   - `EVENT` 节点是从一组相关 `MemoryEntry` 聚合出的“规范化情节视图”，通过 `EVIDENCE (EVENT → MemoryEntry)` 边与证据绑定；  
   - 情节回想 API 面向 `EVENT` 图查询，只有在需要细节时才沿 `EVIDENCE` 回溯到 `MemoryEntry`，避免双写/双查。

### 3.2 回想 API 梳理与增强

- `/timeline_summary`：  
  - 从“clip 分段 + 文本拼接”演进成真正的 `Event` 序列输出；  
  - 支持按 `character_id`、`object`、`location` 子过滤。  
- `/object_search`：  
  - 规范输入输出，使其返回“轨迹点 + 轨迹段”结构（利用时间 + 位置 + EVENT / MEDIA_SEGMENT 节点），可视为以物体/场所节点为起点的事件轨迹查询。  
- `/entity_event_anchor`：  
  - 扩展为返回多条 `(entity, action, time_range, evidence[], event_id)`，与事件节点打通，可视为从 `CHARACTER` 节点出发的事件锚点查询。  
- `/speech_search`：  
  - 从 `UTTERANCE` 证据节点跳转到所属 `EVENT` 与 `CHARACTER`，返回“谁在何时说了什么”的锚点。  
- 增加 graph-first API：  
  - 例如 `/event_chain_search`：从一个事件种子沿 `TEMPORAL_NEXT/CAUSES` 扩展若干 hop，输出候选事件链路，用于因果/剧情分析。

### 3.3 智能图构建（LLM/VLM 加持）

- 在 `memorization_agent` 中引入“时间窗口 + 事实表 → LLM 语义提升”的步骤：  
  - 输入：结构化检测结果（谁/在哪/做什么）+ 代表帧/clip + ASR 片段；  
  - 输出：候选事件、关系（人际/因果/语义标签），以“建议边”形式写入图（带置信度、来源）。  
- 保持低层启发式边（co-occurs, appears_in, located_in）作为“硬事实”，LLM 生成的边作为“高阶推理”层。
 - CHARACTER 稳定性协议：  
   - `FaceNode` / `VoiceNode` / 文本提到的名字只作为“证据节点”，`CHARACTER` 由这些证据通过聚类+投票+等价审核生成；  
   - 冲突证据（face/voice/LLM 名称不一致）不直接创建多个 CHARACTER，而是进入 `EQUIV_PENDING` 工作流，由更高阈值模型或人工确认；  
   - 周期性抽样评估 `CharacterPurity`（同一 CHARACTER 内混入不同真人的概率），用来调节合并策略的激进程度。
 - 因果边安全约束：  
   - `CAUSES` 等因果关系一律标记为“预测/假设性边”，必须带上 `source`、`confidence ∈ (0,1)` 与 `time_origin='predicted'`，与观测到的 `TEMPORAL_NEXT` 严格区分；  
   - `/event_chain_search` 返回的每条事件链需给出链路整体置信度（例如边置信度乘积或最小值），支持按最大跳数与最小置信度阈值过滤；  
   - 在高风险场景（司法/合规）默认仅使用观测型边（`TEMPORAL_NEXT` 等），`CAUSES` 必须显式 opt-in。
 - 语义标注职责划分（检测 vs VLM）：  
   - 检测/追踪（如 YOLO/InsightFace）主要承担**实例几何与筛选**：给出人/物体的 bbox、轨迹与关键帧，生成**结构化检测表（JSON）**。  
   - **VLM 语义提升（Visual Prompting）**：  
     - **输入**：  
       1. **画面**：关键帧/Clip（可选在原图绘制 BBox + ID）；  
       2. **结构化事实**：CV 模型生成的 JSON（含 `track_id`, `bbox`, `type`），作为“硬约束”；  
       3. **文本上下文**：ASR / 历史对话。  
     - **输出**：结构化的 `Event` 描述（如“H1 拿起 O1”），仅负责语义组织与高层命名，不负责定位。  
   - 在图中：  
     - `scene` 字段映射/对齐到 `PLACE` 节点及其标签；  
     - `objects` 字段映射到 `OBJECT` 节点集合，并通过 `INVOLVES` 连接到对应 `EVENT`；  
     - `actions/interactions` 用于补充 `EVENT.description` 和附加语义边（如人物关系、角色行为标签）。  
   - 这样高层语义由 VLM 统一管理，避免传统物体/场景分类与 VLM 各说一套语义真相，同时保留检测层作为 VLM 与图谱的几何“骨架”。

### 3.4 阶段目标 & 检验标准

- 对一段视频，系统能给出：  
  - 稳定的主要角色列表（`character_id`），  
  - 有时间顺序的事件链（Event 节点序列），  
  - 对指定角色，给出其时间-行为轨迹（结合 `/entity_event_anchor` 与 `/timeline_summary`）。  
- 结构性指标：图中孤立节点比例显著下降（配合现有演进文档中的指标）。  
- 质量指标（基于标注/抽样集）：  
  - **EventRecall**：在标注的真实事件中，图中对应 `EVENT` 节点的召回率达到约定基线；  
  - **CharacterPurity**：抽样 CHARACTER 节点的身份纯度高于约定阈值（碎片化率低于阈值）；  
  - **CausalPrecision**：抽样验证 `CAUSES` 边的人为准确率达到基线，否则在 API 中降低其权重或默认禁用；  
  - **STFTemporal**：事件时间区间与标注时间区间的 IoU 均值达到基线（时序保真度）。

---

## 4. 阶段 4：CI/CD、容器化与可运维化（CI/CD & Containerization）

**目标**：把当前实验工程演化为可部署、可测试、可观测的服务形态，为 SaaS 化打基础。

### 4.1 容器化与部署

- 制作基础镜像：  
  - `memory-service`（FastAPI + Qdrant/Neo4j 客户端）。  
  - 可选：`memorization-agent` Worker 镜像（用于离线/异步结构化处理）。  
- 提供标准部署模板：  
  - Docker Compose / K8s YAML：  
    - memory-service + Qdrant + Neo4j + 监控组件（Prometheus/Grafana）。  
  - 环境变量与配置文件规范（`.env` + `config/*.yaml`）。

### 4.2 CI/CD 与质量门禁

- 基础 CI：  
  - 单元测试 / 核心集成测试（memory.search、timeline_summary 等）；  
  - 类型检查（mypy/pyright）、lint（ruff）、格式化（black）。  
- CD：  
  - 预留 GitHub Actions / GitLab CI pipeline 模板，支持：  
    - 构建镜像 → 推送到 Registry；  
    - 部署到测试环境 → 运行 smoke tests。  

### 4.3 可观测性与运维接口

- 在已有 `/metrics` / `/metrics_prom` 基础上：  
  - 补充关键业务指标：  
    - 单租户 QPS、延迟、错误率；  
    - 写入/查询体量、索引命中率；  
    - Timeline / Object / Speech / Entity APIs 的成功率与平均结果大小。  
  - 添加简单健康自检：外部服务（Qdrant/Neo4j）连通性检查。

### 4.4 阶段目标 & 检验标准

- 一个新环境可以通过“一条命令”（docker compose 或 helm install）启动完整记忆服务。  
- PR 合并前默认跑过测试与静态检查。  
- 可在监控面板上看到 per-tenant 与 per-API 的基本运行指标。

---

## 5. 阶段 5：通用文本记忆与知识抽取（Text Memory & KG）

**目标**：在视觉记忆之外，以“会话结束记一次”的方式，把通用文本记忆（对话、日志等）压缩为结构化长期记忆条目，纳入同一 Memory 体系；前期以向量检索 + 时间权重为主，后期可逐步提炼为事件/知识图。

### 5.1 文本记忆管线（写入方式）

- 会话级记忆单元：  
  - 不对每条消息建图，只在“对话/任务结束”时，对整段 messages 做一次 LLM 抽取：  
    - 输出会话摘要 `dialog_summary`；  
    - 输出按桶分组的事实 `facts`。  
- Session Summary 作为 `MemoryEntry`：  
  - **存储形态**：**Fact 向量库**（不强行拆解为图节点）。  
  - `kind="semantic"`，`modality="structured"` 或 `"text"`；  
  - `contents`:  
    - 一段自然语言 `dialog_summary`；  
    - 以及压缩后的 facts JSON 文本（可选单独字段）。  
  - `metadata` 包含：  
    - `timestamp` / `t_abs_start/end`: 会话结束时间（或首尾消息时间）；  
    - `time_origin`: `"physical"` 或 `"logical"`；  
    - `category`: `"dialog_session_summary"`；  
    - `facts`:  
      ```json
      {
        "schema_version": "v1",
        "buckets_meta": [
          {"name": "preference", "retention": "long"},
          {"name": "schedule", "retention": "long"},
          {"name": "personal_info", "retention": "long"}
        ],
        "data": {
          "preference": [...],
          "schedule": [...],
          "personal_info": [...]
        }
      }
      ```  
    - `source_agent`, `channel`, `tenant_id` 等。
- UtteranceEvidence 审计约束：  
  - 单条消息（utterance）可作为短 TTL 的 `MemoryEntry`/向量存在于“热层”，用于近期回放；  
  - 超过 TTL 后，从热索引中剔除，但压缩文本存入冷存（如 S3/LZ4），仅在审计/解释时拉取，不物理删除，保证可追溯性。

### 5.2 向量匹配、时间相关性与遗忘

- 向量匹配：  
  - 对 `dialog_summary`（或 summary+简化 facts）做 embedding，写入 Qdrant；  
  - 使用现有 `search()` 混合打分逻辑（向量 +BM25 +recency），在文本记忆场景可暂不使用图得分。  
- 时间相关性：  
  - Session Summary 挂在绝对时间轴上（`t_abs_*`），与视觉事件共用 τ；  
  - `time_origin` 区分物理 vs 逻辑时间，保证后续可扩展 TimeSlice/对齐机制。  
- 遗忘策略：  
  - 会话 summary 的 TTL 通过 `importance` 决定：  
    - 含长期偏好/身份/规则的对话 → importance 高 → TTL 长或 0；  
    - 纯闲聊 → importance 低 → TTL 短，仅短期可检索。  
  - 周期性跑 `/admin/run_ttl` 做 soft delete，仅对 summary 生效；  
  - UtteranceEvidence 仅从热索引移除，不物理删除，满足审计需求。

### 5.3 开发者与 MCP 用法（API & Tool）

- HTTP API：  
  - 写入：`POST /dialog/commit`  
    - 由 Agent/应用在会话或任务结束时调用，payload 包含：`session_id`、`messages[]`、`context{agent_name,channel,...}`、`commit_trigger`（如 `"manual" | "auto_time_gap" | "auto_size"`）等；  
    - 服务端执行一次 LLM 抽取 → 生成 `dialog_summary + facts` → 写入 MemoryEntry + 向量；  
    - 返回：`memory_id`、`summary_preview`、`importance_score`、`compression_ratio`、`reasons[]`（为何提交）。  
  - 检索：复用 `/search`，通过 `filters.category=["dialog_session_summary"]`、`time_range` 等限定文本记忆；必要时可封装 `/dialog/search` 作为语义友好入口。  
- SDK 建议：  
  - 提供 `memory.dialog_session()` 上下文管理器/类，由 SDK 负责监控消息数、时间间隔、话题切换，并自动选择合适的 `commit_trigger` 调用 `/dialog/commit`，降低开发者决策负担。  
- MCP Tool：  
  - `memory.commit_dialog_session`：  
    - 输入：`session_id`、`messages[]`、`priority`（low/medium/high）、`trigger_reason`（user_manual/topic_end/time_gap）；  
    - 输出：`memory_id`、`summary`、`importance`、`facts_extracted[]`。  
  - `memory.search_dialog`：  
    - 输入：`query`、可选 `time_range`、`slot_filter`（如 `"preference" | "schedule" | "all"`）；  
    - 输出：若干会话 summary 和对应 facts、confidence、timestamp。  
  - Agent 可以依赖 `importance`/`confidence` 决定是否直接使用某条事实，或先向用户复述确认。

### 5.4 与视觉图的融合（后续演进）

- 短期：文本记忆主要以 Session Summary + 向量形式参与检索，与视觉 Event 通过统一时间轴和 `CHARACTER` 节点在语义层融合（例如同一 tenant 的偏好/日程）。  
- 中长期：  
  - 可在后台 Worker 上对历史 Session Summary 再做“二次抽取”，生成 `DialogEvent` / `Knowledge` 节点及其与 `CHARACTER/PLACE` 的关系边，纳入事件-角色图；  
  - 跨模态对齐通过共享 `CHARACTER` 和 TimeSlice（会话时间段）实现，保证“某次对话期间发生的视觉事件”可被检索。

### 5.5 阶段目标 & 检验标准

- 给定一个用户（tenant）：  
  - 在同时 ingest 其视频、对话后，可以通过统一 API（`/search`、`/dialog/search`）回答“跨模态的记忆问题”（如“我上周说过要早起，并且那天早上我在哪个房间？”）。  
- 文本记忆质量指标：  
  - 会话级摘要的语义覆盖度和正确性达到预期（人工抽样或用 STF 的语义部分评估）；  
  - Facts 分桶在新增 bucket 时无需迁移旧数据（通过 `schema_version` + `buckets_meta` 验证）；  
  - UtteranceEvidence 在 TTL 过期后仍可通过冷存恢复，用于审计和解释。  
- 开发者体验：  
  - 使用官方 SDK 的默认策略时，无需手动调优 commit 时机即可获得稳定质量的会话记忆；  
  - MCP Tool 集成后，Agent 能在 few-shot 示例下学会何时 commit、如何 search，并根据 importance/confidence 合理使用记忆。

---

## 6. 阶段 6：SaaS 化与生态闭环（SaaS & Ecosystem）

**目标**：把记忆系统对外封装为“记忆云服务”，形成租户付费、开发者接入、Agent/应用生态的闭环。

### 6.1 服务化产品形态

- 多租户控制平面：  
  - 控制台/后台：创建/禁用 API Key，查看用量、配额、账单。  
  - 不同套餐：  
    - 免费层（限 QPS/存储）、  
    - 专业层（更大配额 + 更多 API）、  
    - 企业层（专用 deployment / VPC）。  
- SLA 与限流：  
  - 为关键 API 设置速率限制与配额策略，避免单租户冲垮系统。

### 6.2 开发者生态

- SDK / Client：  
  - Python / JS 客户端，封装 `/search`、`/write`、时间线、对象搜索、文本 ingest 等常用操作。  
- 模板与示例：  
  - 常见场景 demo：  
    - “个人视频记忆助手”；  
    - “团队知识记忆库”；  
    - “机器人/Agent 的长期记忆插件”。  
- MCP 与主流 Agent 框架集成：  
  - 提供现成的 ToolSpec / 插件配置，开发者只需填入 API Key 即可使用。

### 6.3 连续学习与 CI/CL（Continuous Improvement / Continuous Learning）

- 在保证隐私与隔离前提下：  
  - 对匿名化、聚合后的使用数据进行分析，优化默认检索权重、缓存策略等；  
  - 可选：为愿意 opt-in 的租户提供“模型持续微调”能力（如专属嵌入/抽取器）。

### 6.4 最终闭环图景

- 租户：托管自己的多模态记忆（视频 + 文本），享受跨模态回想与知识服务。  
- 开发者：用统一 API/SDK 把记忆服务接入自己的 Agent / 应用，不必自建复杂存储与图谱。  
- 平台：通过稳定的时间轴、多租户隔离、智能图构建与运维能力，成为“记忆基础设施”的事实标准之一。

---

## 7. 建议的推进节奏（总结）

1. **先做“基础护栏”：时间轴 + 多租户**（阶段 1–2）。  
2. **再做“记忆质量”：智能图构建 + 回想 API 强化**（阶段 3）。  
3. **并行补齐“工程地基”：容器化 + CI/CD + 监控**（阶段 4）。  
4. **扩展到文本领域：统一文本记忆与知识图**（阶段 5）。  
5. **打磨为对外服务：SaaS 化、SDK 与生态**（阶段 6）。  
6. **在稳定记忆图基础上，引入前向预测：时间知识图谱推理模块**（阶段 7，可选但建议作为“进攻型能力”）。

以上路径尽量保证每一阶段都是“可用的一个小闭环”，在不破坏现有能力的前提下，逐步逼近“通用记忆基础设施”的最终愿景。 

---

## 8. 阶段 7：时间知识图谱与前向预测推理（Temporal KG & Forward Inference）

**目标**：在已经成型的时空记忆图之上，引入“前向预测推理”能力：  
- 不仅能“回忆过去发生了什么”，还能在一定概率意义上预测“未来可能发生什么”；  
- 在不重构现有系统的前提下，利用已有事件/关系/时间轴构建 TKG 视图，并挂载标准的 TKG 模型（Know-Evolve / RE-Net / TeMP / TimeTraveler / TLogic 等）作为可选推理模块。

### 8.1 数据视图与构建要求

- 基于阶段 1 + 3 的成果，我们已经具备：  
  - 事件节点：`Event`（具有 `id, actors[], objects[], t_media_*/t_abs_*` 等）。  
  - 关系边：`INVOLVES, OCCURS_AT, NEXT_EVENT, (CAUSED_BY?)` 等。  
  - 物理时间轴：`t_abs_*` + `time_origin`。  
- 在此基础上，为 TKG 前向推理定义两类视图（无需改动底层存储，只是投影）：  
  1. **时间四元组流视图**：  
     - `(s, r, o, t)`：  
       - `s/o`：实体或事件（`character_id` / `Event.id` / 其它 Entity）；  
       - `r`：关系类型（例如 `INVOLVES`, `LOCATED_IN`, `NEXT_EVENT`）；  
       - `t`：可以选 `t_abs_start` 或离散化时间步（例如按分钟/小时/clip）。  
  2. **快照序列视图**：  
     - 一系列离散时间片 `G^1, G^2, …, G^T`，每个 `G^t` 是在时间区间 `[τ_t, τ_{t+1})` 内激活的子图。  
     - 适配 TeMP、TimeTraveler 这类“在历史快照上行走”的模型。

### 8.2 算法范式选择与集成方式

根据应用需求，选择一条主线（其他作为扩展）：

- 若更关心“下一步会发生什么事件/关系”：  
  - 优先考虑 **离散时间序列/快照模型**：  
    - 自回归事件模型（如 RE-Net）；  
    - 时序 GNN（如 TeMP）；  
    - RL 型路径搜索（如 TimeTraveler）。  
- 若关心“何时发生”（时间点预测）：  
  - 可研究时间点过程模型（如 Know-Evolve），但工程成本更高，可放在后续。  
- 若看重可解释性与规则迁移：  
  - 可引入时间逻辑规则（TLogic）作为一个独立的“规则挖掘 + 前向推理”模块。

集成策略：

- 定义一个统一的 TKG 训练用导出接口：  
  - 例如：`/admin/export_tkg_view?tenant_id=...&time_window=...` → 输出 `(s,r,o,t)` 序列或快照序列；  
  - 供离线训练脚本或 TGL/DGL 等框架直接使用。  
- 前向预测服务作为**旁路模块**挂到 MemoryService 旁：  
  - `tkg_predict_service` 接收 `(query_type, seed_entities/events, horizon, tenant_id)`，基于训练好的模型做预测：  
    - 输出候选未来事件/边：`{ (s,r,o,t_pred), score }`。  
  - MemoryService 提供轻量包装 API：  
    - 例如 `/event_forecast`、`/relation_forecast`，内部转发到 TKG 模块，并把结果写成“未来候选事件节点/边 + 置信度”回到记忆图中（带 `time_origin='predicted'` 标记）。

### 8.3 与现有规划的衔接

- **不改底层，只加视图与模块**：  
  - 阶段 1 的时间轴、阶段 3 的事件/关系建模已经满足 TKG 构建要求，无需重构；  
  - 只需在图上定义“如何抽取 (s,r,o,t)”与“如何离散化时间”的规则。  
- **预测结果是“二等公民”**：  
  - 以 `predicted` 标记写入图中，带置信度和模型版本；  
  - 查询时可配置是否使用预测结果（例如只在探索/推荐场景使用）。  
- **训练闭环与 CI/CL 的关系**：  
  - 利用阶段 6 中的 CI/CL 能力，对前向预测模块做版本管理与评估（通过历史回放验证预测质量）；  
  - 可对单租户或特定业务场景训练专用 TKG 模型。

### 8.4 阶段目标 & 检验标准

- 最少在一个典型场景下实现 PoC：  
  - 例如“家庭机器人场景”：  
    - 在已有视频记忆中，能预测“某人未来最可能在哪个房间出现”、“接下来可能发生哪些活动”。  
- 保证：  
  - 不破坏现有检索与回想 API 的行为；  
  - 即使关闭 TKG 模块，记忆系统仍完整可用。  
- 将 TKG 前向推理能力作为“增强包”对外发布，明确说明适用场景与资源成本。  
