# 记忆生命周期：遗忘曲线与增强机制设计

**版本**：v0.3 (Production Ready)  
**日期**：2025-11-30  
**状态**：Approved

---

## 1. 核心理念：工程化的“时间管理”

本方案旨在通过一套低成本、高效率的机制，模拟人类记忆的“遗忘”与“巩固”过程。核心思想是将复杂的数学模型拆解为四个具体的工程动作，并辅以严格的性能优化策略：

1.  **Lazy Decay (读时降权)**：解决“排序”问题。不搞全库更新，只在查询时计算当前分值。
2.  **Soft TTL (逻辑过期)**：解决“可见性”问题。通过 `expires_at` 字段，让过期记忆立即对用户不可见。
3.  **Reinforcement (写时延寿)**：解决“巩固”问题。被命中的记忆，自动推迟其 `expires_at` 并增加强度。
4.  **The Reaper (物理清理)**：解决“存储”问题。后台低频批量删除已过期的垃圾数据。

---

## 2. 数学模型：艾宾浩斯遗忘曲线

我们使用以下公式来衡量记忆的**当前留存率 (Retention, $R$)**，用于检索排序：

$$ R(t) = I \cdot e^{-\frac{t - t_{last}}{S}} $$

其中：
- **$I$ (Importance)**: 基础重要性 (0.0 - 1.0)。
- **$S$ (Strength)**: 记忆强度 (半衰期，单位：天)。$S$ 越大，忘得越慢。
- **$t - t_{last}$**: 距上次访问的时间间隔。

---

## 3. 详细工程实现

### 3.1 Schema 扩展 (Database Layer)

在 `contracts/graph_models.py` 的 `Provenanced` 基类中增加以下字段：

| 字段                | 类型     | 默认值     | 说明                                                           |
| :------------------ | :------- | :--------- | :------------------------------------------------------------- |
| `importance`        | float    | 0.5        | 基础重要性 (I)。                                               |
| `memory_strength`   | float    | 1.0        | 当前强度/半衰期 (S)，单位：天。                                |
| `last_accessed_at`  | datetime | now        | 上次访问时间 ($t_{last}$)。                                    |
| `expires_at`        | datetime | calculated | **逻辑过期时间**。超过此时间视为“已遗忘”。                     |
| `forgetting_policy` | enum     | 'normal'   | 'normal' (默认), 'persistent' (永不过期), 'ephemeral' (短时)。 |

**`expires_at` 计算逻辑**：
写入时根据 $(I, S)$ 预估一个“死亡时间”：
$$ \Delta t_{dead} = -S \cdot \ln(T_{delete} / I) $$
其中 $T_{delete}$ 是删除阈值 (e.g., 0.05)。
*例如：I=0.5, S=7天, T=0.05 -> expires_at ≈ now + 16天*

### 3.2 读路径：Lazy Decay & Soft TTL

**目标**：用户查不到“过期”记忆，且“旧”记忆排名靠后。

**实现**：
1.  **Soft TTL (过滤)**：
    *   **Qdrant**: Filter `expires_at > now` (或 `expires_at` is null)。
    *   **Neo4j**: Cypher `WHERE n.expires_at IS NULL OR n.expires_at > datetime()`。
    *   *效果*：过期数据逻辑上消失，无需等待物理删除。

2.  **Lazy Decay (排序 - Two-Stage)**：
    *   **Stage 1 (Recall)**: 数据库层仅做 `Soft TTL` 过滤，按向量相似度取 Top-N (e.g., 200)。
    *   **Stage 2 (Rerank)**: **应用层 (Python)** 内存计算 Decay Score。
    *   `Final Score = Vector Similarity * (Importance * exp(-(now - last_accessed) / Strength))`
    *   *效果*：避免在数据库层对全量数据执行昂贵的数学运算，保证毫秒级延迟。

### 3.3 写路径：Reinforcement (记忆增强)

**目标**：常用的记忆不应被遗忘。

**实现**：
当某条记忆被检索并**采纳**（用于回答问题/Agent决策）时，调用 `MemoryService.touch(ids)`。

**关键优化：Touch Throttling (防抖)**
*   **策略**：在内存/Redis 记录 `last_touched_at`。
*   **逻辑**：仅当 `now - last_touched_at > 1 hour` 时，才真正发起 DB 写操作。
*   *效果*：防止热点数据导致数据库写锁雪崩。

**关键优化：Cascading Touch (级联)**
*   **策略**：当 `Event` 被 Touch 时，异步 Touch 其关联的 `Evidence`。
*   *效果*：防止“事件还在，证据却被删了”的数据不一致僵尸图谱。

### 3.4 后台路径：The Reaper (物理清理)

**目标**：释放存储空间，保持图谱精简。

**实现**：
一个低频运行的后台任务 (CronJob / Worker)，按 `tenant_id` 分批处理。

1.  **扫描**：查找 `expires_at < now - buffer_time` 的条目。
    *   *buffer_time (e.g., 24h)*：留一段缓冲期，防止误删刚过期的边缘数据。
2.  **分级动作**：
    *   **Level 1 (Pruning)**: 对 `importance` 较低的，删除向量和原始 Evidence，只留 Event 骨架（省空间）。
    *   **Level 2 (Delete)**: 对极低价值或已 Pruned 很久的，物理删除节点与边。
3.  **归档 (可选)**: 删除前将摘要写入冷存储 (S3/Blob) 用于审计。

---

## 4. 风险控制与边界

1.  **热点记忆防“永生”**：
    *   设置 `MAX_STRENGTH` (e.g., 365天)。即使天天查，半衰期也有上限。
2.  **关键证据保护**：
    *   被 `SUPPORTED_BY` 引用、或处于 `EQUIV` 关系中的节点，默认应用 `persistent` 策略或极长的 TTL，防止破坏图结构。
3.  **多租户隔离**：
    *   Reaper 必须严格按 `tenant_id` 隔离运行，统计数据互不干扰。

---

## 5. 总结

| 机制              | 作用阶段  | 核心逻辑                       | 解决问题                          |
| :---------------- | :-------- | :----------------------------- | :-------------------------------- |
| **Soft TTL**      | 写入/查询 | `expires_at` 字段 + 查询过滤   | 立即让过期记忆“不可见”            |
| **Lazy Decay**    | 查询排序  | **Two-Stage Rerank**           | 让旧记忆排名自然下降，且不拖慢 DB |
| **Reinforcement** | 命中反馈  | **Throttling** + **Cascading** | 常用记忆自动延寿，防写崩，防僵尸  |
| **The Reaper**    | 后台维护  | `DELETE WHERE expires < now`   | 物理释放磁盘空间                  |

这套方案在不引入复杂后台计算的前提下，实现了符合直觉且成本可控的记忆生命周期管理。
