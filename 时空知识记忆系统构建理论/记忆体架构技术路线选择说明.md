# 记忆体架构技术路线选择说明  

**版本**：v0.1  
**作者视角**：技术负责人给业务/合作方的一份“路线选择说明书”  

---

## 1. 我们到底在做一件什么事？

一句话：  
**我们在给 AI 做一套“能长期记事、能解释清楚”的大脑，用来记住谁在什么时候、在哪儿、做了什么——同时看得懂视频，也看得懂文本。**

更具体一点：

- 它不是普通的“向量数据库”——不仅能模糊记住“看起来像什么”，还能回答结构化问题：  
  - 某个用户/人物过去一周出现在哪些场景？  
  - 某天说过的承诺/规则是什么？  
  - 某个事件发生时，现场是什么样子、有哪些人？  
- 它也不是“只会讲故事的 GPT”——不是给出一段漂亮的话就完了，而是：  
  - 每一个回答都能指回**具体哪段视频、哪一句话、哪条记录**，形成证据链。  
- 它是后面所有 Agent / 应用的“长期记忆底座”，而不是某个单点功能。

这件事如果做对了，未来任何 Agent 想要“记忆”，就不需要重复造轮子——直接接到这套基础设施上即可。

---

## 2. 我们选的是哪条技术路线？

我们现在选的核心路线可以概括为四个关键词：

> **“向量 + 时空特征融合 + 知识图谱 + 审计能力”**

拆开来看：

1. **向量层（Vector Layer）**  
   - 用 embedding / 向量搜索处理大规模原始数据（视频帧、文本片段、日志等），负责**模糊召回**：  
     - “给我找跟这个场景类似的片段”；  
     - “找和这段对话语义相近的历史对话”。

2. **时空特征融合层（多模态结构化感知 + 身份统一）**  
   - 用一系列视觉/语音/文本模型，把原始流变成“谁在什么时候、在哪儿、做了什么 / 说了什么”的结构化证据：  
     1. **身份统一（Who）**  
        - 视觉侧：人脸检测 + 跟踪 + re-ID，把同一个人跨帧、跨片段、甚至跨视频统一成同一个 `Entity`；  
        - 语音侧：ASR 的说话人信息与视觉轨迹/人脸对齐，辅助判断“是谁在说话”；  
        - 文本侧：从对话中抽取名字/指代（“我”“他”“张三”），和视觉/账号信息一起，用于强化身份聚类。  
     2. **视觉识别（What / Where in 画面）**  
        - 检测：识别人、物体、场景类别（人、车、桌子、厨房……）；  
        - 轨迹：跟踪物体/人物在时间轴上的移动（进入/离开/停留），得到时空轨迹；  
        - 位置：通过 bbox/区域标记在画面中的位置，后续再映射到语义地点 `Place`（房间/区域等）。  
     3. **语音 + 文本理解（What is said）**  
        - ASR：把音频转成文本，并精确对齐到时间段（哪一秒说了哪句）；  
        - 文本解析：从对话/日志中抽取偏好、计划、规则、事实等片段，形成 `TextEvidence`，挂在对应时间片段上。  
     4. **时间窗口内的事件候选（When + 简单 What）**  
        - 按时间窗口（例如几秒、一段对话）把上述多模态证据聚合起来：  
          - “这一小段时间里，有哪些人、在什么场景、做了/说了什么”；  
        - 得到的是一批“候选事件片段”，为后续 `Event` 节点构建提供原料。  
   - 这一层的职责是“看懂 + 结构化 + 压缩”：  
     - 看懂：把原始像素/音频/字符变成“谁/何时/何地/做了什么”的中间表示；  
     - 结构化：整理为统一格式的 Evidence / Segment / 初步事件候选；  
     - 压缩：只把对后续记忆/查询有价值的信息传给图谱层，本身不做长期存储。

3. **知识图谱层（结构化长期记忆 + 查询接口）**  
   - 把上一层抽出来的“谁/何时/何地/做了什么”用**节点 + 关系**的形式固定下来：  
     1. **节点：长期记忆里的“角色表”和“事件表”**  
        - `Entity`：人物/物体/地点等稳定身份（谁），跨视频、跨对话复用；  
        - `Event`：发生过的事情（做了什么），可以是视觉事件，也可以是文本事件/事实；  
        - `MediaSegment/TimeSlice`：时间片段（什么时候），承担物理时间轴/会话时间轴的骨架。  
     2. **关系（边）：长期记忆里的“关系表”**  
        - `INVOLVES`：谁参与了哪个事件（人-事关系）；  
        - `OCCURS_AT`：事件发生在哪个地点（事-地关系）；  
        - `NEXT_EVENT`：事件之间的先后顺序（事-事时间关系）；  
        - `CO_OCCURS_WITH`：哪些实体经常一起出现（“关系网”）。  
   - 图谱层解决的是：  
     - **“把要长期记住的核心事实整理成一个结构化的世界”**，方便后面高效提问和统计；  
     - 避免每次都从原始视频/文本重新扫一遍、在业务代码里“临时造图”。

4. **审计与可解释层（证据链 + 溯源信息）**  
   - 这一层的要求很简单也很严格：**任何结论都必须能找到“哪来的”**。  
     1. **证据链（SUPPORTED_BY）**  
        - 每个 `Event` / 重要关系（比如某个因果边、共现边），都需要挂回具体证据：  
          - 哪几帧视频（关键帧、轨迹）；  
          - 哪几条检测结果（bbox、识别标签）；  
          - 哪几句对话/文本（TextEvidence）。  
        - 通过 `SUPPORTED_BY` 链路，可以从“抽象结论”一路点回到“具体画面/具体句子”。  
     2. **溯源信息（Provenance）**  
        - 对所有由模型/算法生成的结论，记录：  
          - `source`：是哪条算法/哪个模块产出的（规则、VLM、RE-Net…）；  
          - `model_version`：具体模型版本；  
          - `confidence`：置信度；  
          - `time_origin` / `layer`：是观测事实、语义抽象还是预测假设。  
   - 这一层保证：  
     - 我们不仅有“答案”，还有**“答案是怎么来的”**；  
     - 在高风险场景里（监控、司法、合规），可以给出完整的证据链和版本说明，而不是“模型说的算”。

这四层叠在一起，就是我们所谓的**“神经-符号融合记忆体”**：

- 底层神经模型负责“看懂、联想”；  
- 上层符号（图谱）负责“记住、检索、解释”；  
- 中间用清晰的数据契约打通。

---

## 3. 这个选择背后，我们其实纠结过什么？

真实情况是：我们不是一开始就拍脑袋决定“必须用图谱”，中间经历过几轮犹豫和对比，大致有这些疑惑：

1. **是不是只要向量就够了？**  
   - 把所有东西 embed 到向量库里，看起来简单、酷，市面上也很多这样做的。  
   - 疑问：向量能不能独立承担“记忆”？

2. **是不是直接用大模型做“世界模型”就够了？**  
   - 视频/文本喂给大模型，让它自己“理解 + 记住 + 总结”，我们只要问问题。  
   - 疑问：我们真的要把长期记忆和解释权交给一个黑盒吗？

3. **是不是只要一个“物理时间轴 + 事件列表”就够了？**  
   - 所有事件按时间排成一条线，看起来对人类最直觉。  
   - 疑问：一条轴能撑得住跨模态、跨身份、跨地点的复杂查询吗？

我们一路问下去，才收敛到现在的混合方案。下面逐条解释。

---

## 4. 为什么“只用向量”不够？

只用向量的典型做法是：  
**“把所有视频/文本都转换成向量，然后做相似度搜索”**。

优势很明显：

- 检索简单直接，工程门槛低；  
- 模糊匹配能力很强（相似场景、相似语义）。

但它有几个致命短板，非常不适合作为“长期记忆体”的核心：

1. **没有明确的“人”“物”“事件”概念**  
   - 向量库知道“这两段很像”，但不知道这两段里是不是同一个人。  
   - 所有“谁做了什么”的问题，最后都要在业务代码里重新拼一次结构。

2. **时间和空间语义很弱**  
   - 向量库可以过滤时间区间，但对“先后关系”“跨场景轨迹”“联合统计”非常不友好。  
   - 比如“这个人过去三个月在不同地点的停留时长分布”，会非常难做。

3. **几乎没有可解释性和审计能力**  
   - 检索结果只能说“相似度高”，不能说“因为这几帧 + 这几句对话，所以得出这条结论”。  
   - 在高风险场景（司法、安防、金融）很难站得住。

因此，向量库**非常适合作为“感知+模糊召回层”**，但**无法独立承担“长期记忆+结构化查询+可审计”这三个职责**。

---

## 5. 为什么“只靠大模型世界观”也不行？

所谓“世界模型路线”，本质上是期待一个足够强的大模型：

- 直接从多模态输入中学出一个内部世界观（latent world state）；  
- 负责所有的理解、记忆和预测。

短期来看，这条路在 Demo/科研上非常亮眼，但对我们要做的“记忆基础设施”有几个大问题：

1. **记忆是隐变量，不是结构化资产**  
   - 模型内部“觉得自己记得”，但我们拿不到一个稳定、可操作的“记忆表”。  
   - 很难对外暴露清晰的 API，更别提多租户、权限、统计和审计。

2. **版本漂移不可控**  
   - 换一个模型版本、微调一次权重，模型的“记忆”可能会变。  
   - 这对需要长期稳定的业务来说是不可接受的。

3. **可解释性几乎为零**  
   - 模型说“那天发生了 X”，我们问：“证据呢？”——拉不出一条清晰的证据链。  
   - 对企业来说，这就变成了“信不信我”，不具备工程上的可靠性。

所以，大模型的“世界模型”非常适合作为**“推理与预测模块”**，但我们更愿意让它站在我们的记忆体之上，而不是取代记忆体本身。

---

## 6. 为什么“只有时间轴 + 事件列表”不够？

“一条时间轴 + 事件列表”是非常直观的人类视角：

- 每条记录写成 `时间 + 描述 + 若干标签`；  
- 按时间排序，一眼就能看出某天发生了什么。

这对于单用户、单模态、数据量不大时非常容易实现，也足够用。但一旦我们要：  
**“多用户、多模态、大规模、跨维度查询”**，它马上就开始吃力：

1. **跨时间、跨场景的关联会变得极其笨重**  
   - 想要查“这个人过去 3 个月在所有地点出现的分布”，要不断扫描整条时间轴。  
   - 想要查“这两个用户的交集事件”，要多次 join。

2. **文本和视频的统一表达会越来越乱**  
   - 视频和文本的结构差异很大，全部塞进一条时间表，标签会变得五花八门，不利于后续扩展和维护。

3. **一旦要做图级问题，又退回到“代码里临时造图”**  
   - 比如“谁和谁经常一起出现”“谁是某个关键节点的二度关系”，本质上就是图问题。  
   - 不如承认这是图，把图正儿八经建出来。

因此，纯时间轴方案适合作为**一维视角**，但无法承担**高维、多模态、长期演进**的记忆需求。

---

## 7. 我们选的“图 + 向量 + 时空模型”路线，优势在哪里？

综合前面的对比，我们的路线可以看成是：

> **在时间轴上，铺一层可解释的图谱；在图谱下面，用向量和神经模型做高效的感知和压缩。**

优势主要体现在四个方面：

1. **统一多模态，统一身份与事件**  
   - 视频的一段、对话的一段，都先成为 `MediaSegment`（带物理时间和媒体时间）；  
   - 视觉检测、文本抽取都变成 `Evidence`；  
   - 人/物/地点集中到 `Entity`，行为集中到 `Event`。  
   - 所有后续问题，统一从“某个 Entity / Event 在时间轴上的分布和关系”来提。

2. **图负责结构，向量负责规模，模型负责理解**  
   - 向量层：压住规模，做初筛；  
   - 模型层：在局部窗口内精读，做时空特征融合（轨迹、动作、语义）；  
   - 图层：只接收“已经足够结构化、足够有价值”的信息，保持稀疏和清晰。

3. **天生具备可解释性和审计能力**  
   - 每个结论（事件、关系）都必须能通过 `SUPPORTED_BY` 找回具体证据（哪帧、哪句话）；  
   - 每条边/节点都有 `source`、`model_version`、`confidence`，可以做回归测试和版本管理。  
   - 这对需要长期信任和合规的场景，是决定性的优势。

4. **与未来的“更强世界模型”天然兼容**  
   - 未来无论用什么样的 VideoMamba、JEPA、世界模型，它们都可以：  
     - 从我们的记忆图里读历史状态；  
     - 把预测/抽象写回图里作为增强信息；  
     - 而我们的图依然是对外的稳定接口，不绑死在某个模型上。

---

## 8. 为什么我们可以对这条路“有底气”？

从三个维度讲“底气”：

1. **理论上：**  
   - 我们没有选择极端（全黑盒 / 全手工规则），而是承认“神经 + 符号 + 时间轴”三者必须共存：  
     - 神经层解决“感知/压缩”；  
     - 符号层解决“结构/解释”；  
     - 时间轴解决“物理约束与对齐”。  
   - 这符合当前关于世界模型、时空知识图谱和记忆经济学的主流研究结论。

2. **工程上：**  
   - 所有核心设计都已经在 Schema 文档里被具体化，并有明确的验收标准；  
   - 多租户、安全、TTL、可观测性都已经考虑进去，是一条可以**从 PoC 推到生产**的路线，而不是 PPT 架构。

3. **实践上：**  
   - 市面上的“只向量”“只文本”“只模型”方案，在真正落地到需要审计/长期记忆的业务时，都在补这几层东西：  
     - 加时间轴索引；  
     - 加实体/事件的结构；  
     - 加日志和证据链。  
   - 我们只是选择从一开始就承认这几点，把它们做干净，而不是等出问题再补。

---

## 9. 未来我们怎么演进，而不是停在 v1.0？

我们当前的路线不是终点，而是一个“稳健的起跑线”：

- **v1.x：**  
  - 把多模态记忆、结构化回想和基本分析做扎实；  
  - 让每一个核心 API 在真实业务场景下跑起来，并有审计和监控。

- **v2.x：**  
  - 引入更强的时空模型/世界模型（SSM、JEPA、RE-Net 等）；  
  - 让模型在“看懂”和“预测”上承担更大的责任，但结果仍然写回图中，保持可解释性。

- **更长期：**  
  - 让记忆体不仅是“客观记录者”，还是“会主动整理和优化记忆的智能系统”：  
    - 自动发现模式和规则；  
    - 自动归纳和压缩低价值记忆；  
    - 不断自我评估和修正。

但无论如何演进，有两条底线不变：

1. **Never break userspace**：  
   - 对已有的 API 和数据结构，保持向后兼容，不让现有业务因架构追求“完美”而被迫重写。

2. **任何智能都必须可解释、可追溯**：  
   - 我们可以错，但不能瞎；  
   - 任何结论都必须能回到证据链，而不是一句“模型说的”。

这就是我们选择当前这条技术路线，并且敢说“这是当下最优解”的根本原因。  
不是因为它完美，而是因为在今天的技术条件下，它在**能力、成本、风险和长期治理**四个维度上给出了一个最平衡的答案。  
