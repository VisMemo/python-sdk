# 视觉记忆基础设施发展路径规划

**版本**：v0.1  
**日期**：2025-11-14  
**目标**：从当前单体实验系统，逐步演进为一个通用的、多租户、安全可运维的「记忆基础设施」（Memory Infrastructure）：  
- 同时支持视觉、文本等多模态长期记忆；  
- 对租户提供记忆托管服务；  
- 对开发者提供稳定、可组合的记忆层 API（HTTP / MCP / SDK）；  
- 支撑未来 Agent / 应用把“记忆”当成底座能力来使用。

> 配套参考文档：  
> - 理论基础：`docs/时空知识记忆系统构建理论/时空知识图谱的本体论与信息论基础.md`  
> - 当前差异与需求总结：`docs/时空知识记忆系统构建理论/系统讨论_需求与方案总结.md`  
> - 视觉路线设计：`docs/时空知识记忆系统构建理论/视觉记忆的三条路线.md`

---

## 0. 总体演进视图

按「从内到外、从理论到工程」分为六个阶段（可并行推进，但优先级如图）：

1. **阶段 1：物理时间轴与时空标注落地**（Time Axis v1）  
2. **阶段 2：多租户隔离与安全托管**（Multi-tenant & Auth）  
3. **阶段 3：智能图构建与结构化回想**（Graph & Episodic APIs）  
4. **阶段 4：CI/CD、容器化与可运维化**（CI/CD & Containerization）  
5. **阶段 5：通用文本记忆/知识抽取管线**（Text Memory & KG）  
6. **阶段 6：SaaS 化与生态化闭环**（SaaS & Ecosystem）  
7. **阶段 7：时间知识图谱与前向预测推理**（Temporal KG & Forward Inference）

大致时间预估（以“连续演进”方式，非硬性）：
- 阶段 1–2：T0–T+3 个月（高优先级，打牢“时间+租户”基础）。  
- 阶段 3：T+2–T+6 个月（图结构与智能回想对齐理论）。  
- 阶段 4：T+3–T+6 个月（与阶段 3 部分并行）。  
- 阶段 5：T+5–T+9 个月（统一视觉/文本记忆能力）。  
- 阶段 6：T+8 个月之后（产品化与生态扩展）。  
- 阶段 7：T+9 个月之后（在稳定记忆图之上引入前向预测能力，可作为可选增强模块）。

---

## 1. 阶段 1：物理时间轴与时空标注落地（Time Axis v1）

**目标**：把“物理世界时间”明确写进数据模型与 API，使任一记忆条目都能在时间轴上被定位，并区分物理时间 vs 媒体内部时间。

### 1.1 核心设计

- 媒体级时间（Media Time）：  
  - 为每个视频/音频/流对象添加并强制存储：  
    - `recorded_at`: UTC 录制起始时间（可为空）。  
    - `duration_seconds`: 时长。  
    - `has_physical_time: bool`: 是否可信锚定物理时间。  
- 事件/记忆级时间（Event Time）：  
  - 在 `MemoryEntry.metadata` 中规范字段：  
    - `t_media_start`, `t_media_end`: 相对媒体起点的时间偏移。  
    - `t_abs_start`, `t_abs_end`: 若 `has_physical_time=true` 则 = `recorded_at + t_media_*`。  
  - 增加 `time_origin`: `'physical' | 'media' | 'ingestion'`，辅助查询与审计。  
- 搜索语义约定：  
  - `SearchFilters.time_range` 默认作用在 **绝对时间**（`t_abs_*`），仅对 `has_physical_time=true` 条目有效；  
  - 保留扩展位：`time_range_kind = 'absolute' | 'media'`（后续版本可加入）。

### 1.2 关键工作项

1. **模型层修改**  
   - 在 `MemoryEntry.metadata` 约定上述字段，并在写入路径统一规范：  
     - `modules/memorization_agent` 在构建 episodic 记忆时，写入 `t_media_start/end` 与 `clip_id`。  
     - 视频 ingest 层负责写 `recorded_at / duration / has_physical_time`。  
2. **搜索与 API 层对齐**  
   - 调整 `MemoryService.search()` 与 `timeline_summary()`：  
     - 在构造 `SearchFilters` 时，明确解析时间语义。  
     - `timeline_summary` 输出中显式包含 `t_media_*` 与 `t_abs_*`。  
3. **迁移与兼容**  
   - 对已有数据：  
     - 若无 `recorded_at`，则 `has_physical_time=false`，保留原有行为。  
   - 确保 `/search`、`/timeline_summary` 的旧调用不会因为新字段而破坏兼容。

### 1.3 阶段目标 & 检验标准

- 任一 `MemoryEntry` 均满足：  
  - 要么 `has_physical_time=true` 且 `t_abs_*` 可求；  
  - 要么被明确标记为逻辑时间/内部时间。  
- `/timeline_summary` 能可靠回答“某段物理时间窗口内发生了什么”。  
- 所有新写入的视频类记忆都带上时间元信息。

---

## 2. 阶段 2：多租户隔离与记忆托管（Multi-tenant & Auth）

**目标**：以“用户=租户”为隔离单位，实现安全的 API Key 访问控制与数据层隔离，铺路给 SaaS 化与 Agent 接入。

### 2.1 身份模型设计

- `tenant_id`（内部）：  
  - 每个最终用户一个 `tenant_id`，仅存在于服务端。  
- `api_key`（外部凭证）：  
  - 随机字符串（仅存 hash）；  
  - 映射关系：`api_key → { tenant_id, scopes, integration_id?, expires_at }`。  
- `user_id` / `memory_domain` / `run_id`：  
  - 作为租户内部的子命名空间，不得跨越 `tenant_id`。

### 2.2 数据层隔离

- Qdrant：  
  - 在 payload 中统一写入 `tenant_id`；  
  - 所有 `search_vectors` / `upsert` / `delete` 封装在 adapter 中，自动注入 `tenant_id` 过滤。  
- Neo4j：  
  - 所有节点、边带 `tenant_id` 属性 + 索引；  
  - 只允许通过 `MemoryGraphStore` 访问，内部统一追加 `WHERE n.tenant_id = $tenant_id` 等条件。

### 2.3 API 与 MCP 集成

- HTTP 层：  
  - 统一采用 `Authorization: Bearer <api-key>` 或自定义 header；  
  - FastAPI 中加入认证中间件：  
    - 解析 API Key → 查表 → 注入 `tenant_id` 到上下文。  
  - `/write`、`/update`、`/delete`、`/search` 等接口内部严格使用上下文 `tenant_id`，忽略客户端传入的任何 `tenant` 信息。  
- MCP / Agent 工具：  
  - Tool 配置中让最终用户填 `MOYAN_API_KEY`；  
  - MCP 侧仅负责把 Key 放到请求头，不感知 `tenant_id` 细节。

### 2.4 阶段目标 & 检验标准

- 不同 API Key 的用户无法通过 API 访问到任何对方的记录（包含向量与图节点）。  
- 单个 tenant 的数据可以被完整导入/导出，便于备份与迁移。  
- MCP/Agent 能在不改代码的情况下，以“填入 Key”方式挂接记忆服务。

---

## 3. 阶段 3：智能图构建与结构化回想（Graph & Episodic APIs）

**目标**：在现有 `MemoryService` 能力之上，把“情节回想”系列 API 真正对齐理论中的时空本体与事件/关系建模，减少硬编码启发式，提升图的连通性与可解释性。

### 3.1 图建模强化

- Identity/角色建模：  
  - 将 face / voice / re-ID 聚类输出统一抽象为 `character_id`：  
    - 节点：`FaceNode`, `VoiceNode`, `CharacterNode`；  
    - 边：`FACE_OF`, `VOICE_OF`, `EQUIV`；  
  - 在 episodic/semantic 文本中用 `<char_1>`、`<char_2>` 统一引用。  
- 事件节点规范：  
  - 为 `timeline_summary` / `entity_event_anchor` 等 API 确定统一的 `Event` schema：  
    - `{ id, t_media_start/end, t_abs_start/end?, actors[], objects[], location, description, source_entries[] }`。  
  - 图中引入 `EVENT` 节点类型，边包括：`INVOLVES`, `OCCURS_AT`, `NEXT_EVENT`, `CAUSES?`。

### 3.2 回想 API 梳理与增强

- `/timeline_summary`：  
  - 从“clip 分段 +文本拼接”演进成真正的 `Event` 序列输出；  
  - 支持按 `character_id`、`object`、`location` 子过滤。  
- `/object_search`：  
  - 规范输入输出，使其返回“轨迹点 + 轨迹段”结构（利用时间 + 位置 + EVENT / MEDIA_SEGMENT 节点）。  
- `/entity_event_anchor`：  
  - 扩展为返回多条 `(entity, action, time_range, evidence[], event_id)`，与事件节点打通。  
- 增加 graph-first API：  
  - 例如 `/event_chain_search`：从一个事件种子沿 `NEXT_EVENT/CAUSES` 扩展若干 hop，输出候选链路。

### 3.3 智能图构建（LLM/VLM 加持）

- 在 `memorization_agent` 中引入“时间窗口 + 事实表 → LLM 语义提升”的步骤：  
  - 输入：结构化检测结果（谁/在哪/做什么）+ 代表帧/clip + ASR 片段；  
  - 输出：候选事件、关系（人际/因果/语义标签），以“建议边”形式写入图（带置信度、来源）。  
- 保持低层启发式边（co-occurs, appears_in, located_in）作为“硬事实”，LLM 生成的边作为“高阶推理”层。

### 3.4 阶段目标 & 检验标准

- 对一段视频，系统能给出：  
  - 稳定的主要角色列表（`character_id`），  
  - 有时间顺序的事件链（Event 节点序列），  
  - 对指定角色，给出其时间-行为轨迹（结合 `/entity_event_anchor` 与 `/timeline_summary`）。  
- 图中孤立节点比例显著下降（配合现有演进文档中的指标）。

---

## 4. 阶段 4：CI/CD、容器化与可运维化（CI/CD & Containerization）

**目标**：把当前实验工程演化为可部署、可测试、可观测的服务形态，为 SaaS 化打基础。

### 4.1 容器化与部署

- 制作基础镜像：  
  - `memory-service`（FastAPI + Qdrant/Neo4j 客户端）。  
  - 可选：`memorization-agent` Worker 镜像（用于离线/异步结构化处理）。  
- 提供标准部署模板：  
  - Docker Compose / K8s YAML：  
    - memory-service + Qdrant + Neo4j + 监控组件（Prometheus/Grafana）。  
  - 环境变量与配置文件规范（`.env` + `config/*.yaml`）。

### 4.2 CI/CD 与质量门禁

- 基础 CI：  
  - 单元测试 / 核心集成测试（memory.search、timeline_summary 等）；  
  - 类型检查（mypy/pyright）、lint（ruff）、格式化（black）。  
- CD：  
  - 预留 GitHub Actions / GitLab CI pipeline 模板，支持：  
    - 构建镜像 → 推送到 Registry；  
    - 部署到测试环境 → 运行 smoke tests。  

### 4.3 可观测性与运维接口

- 在已有 `/metrics` / `/metrics_prom` 基础上：  
  - 补充关键业务指标：  
    - 单租户 QPS、延迟、错误率；  
    - 写入/查询体量、索引命中率；  
    - Timeline / Object / Speech / Entity APIs 的成功率与平均结果大小。  
  - 添加简单健康自检：外部服务（Qdrant/Neo4j）连通性检查。

### 4.4 阶段目标 & 检验标准

- 一个新环境可以通过“一条命令”（docker compose 或 helm install）启动完整记忆服务。  
- PR 合并前默认跑过测试与静态检查。  
- 可在监控面板上看到 per-tenant 与 per-API 的基本运行指标。

---

## 5. 阶段 5：通用文本记忆与知识抽取（Text Memory & KG）

**目标**：在视觉记忆之外，把通用文本记忆（对话、文档、日志）纳入同一 Memory/Graph 体系，实现统一的“知识抽取与图构建”能力。

### 5.1 文本记忆管线

- 增强 `MemoryEntry`：  
  - 对 `modality="text"` 的条目，细化 `kind`：`episodic`（对话片段）、`semantic`（事实/知识）、`structured` 等。  
- 文本 ingest：  
  - 提供标准化 API：`/text_ingest` 或通过 `/write` 约定 metadata 字段（source=chat/file/log 等）。  
  - 对长文档/对话进行分段、窗口化；  
  - 生成向量（文本 encoder）并写入 Qdrant。

### 5.2 知识抽取与图构建

- 文本 → 事实 → 图：  
  - 基于 LLM 的信息抽取：三元组（subject, relation, object）、事件、属性；  
  - 把抽取结果映射到通用图模式：  
    - `Entity` / `Concept` 节点；  
    - `RELATION`, `IS_A`, `PART_OF`, `CAUSED_BY` 等边。  
- 与视觉图的融合：  
  - 利用统一的实体/角色 ID（例如同一个人、同一个地点）把视觉事件与文本知识挂在一棵更大的图上：  
    - “Alice 喜欢早上喝咖啡”既有视觉证据（视频里的行为），也有文本证据（聊天记录）。

### 5.3 通用记忆 API

- 在现有 `/search` 基础上扩展：  
  - 支持基于“事实/三元组”的查询（例如 `/fact_search`）：返回知识层节点与证据。  
- 对 Agent 提供高层接口：  
  - 如 `memory.query_semantic({ question, scope, topk })`，内部自动 orchestrate 文本/视觉/图检索，并输出统一的记忆片段列表 + 证据链。

### 5.4 阶段目标 & 检验标准

- 给定一个用户（tenant）：  
  - 同时 ingest 其视频、对话、文档后，能在统一 API 下回答“跨模态的记忆问题”（例如“我上周在聊哪本书，并且当时在哪个房间？”）。  
- 图中存在跨模态实体融合（同一角色/地点在视觉与文本中统一）。

---

## 6. 阶段 6：SaaS 化与生态闭环（SaaS & Ecosystem）

**目标**：把记忆系统对外封装为“记忆云服务”，形成租户付费、开发者接入、Agent/应用生态的闭环。

### 6.1 服务化产品形态

- 多租户控制平面：  
  - 控制台/后台：创建/禁用 API Key，查看用量、配额、账单。  
  - 不同套餐：  
    - 免费层（限 QPS/存储）、  
    - 专业层（更大配额 + 更多 API）、  
    - 企业层（专用 deployment / VPC）。  
- SLA 与限流：  
  - 为关键 API 设置速率限制与配额策略，避免单租户冲垮系统。

### 6.2 开发者生态

- SDK / Client：  
  - Python / JS 客户端，封装 `/search`、`/write`、时间线、对象搜索、文本 ingest 等常用操作。  
- 模板与示例：  
  - 常见场景 demo：  
    - “个人视频记忆助手”；  
    - “团队知识记忆库”；  
    - “机器人/Agent 的长期记忆插件”。  
- MCP 与主流 Agent 框架集成：  
  - 提供现成的 ToolSpec / 插件配置，开发者只需填入 API Key 即可使用。

### 6.3 连续学习与 CI/CL（Continuous Improvement / Continuous Learning）

- 在保证隐私与隔离前提下：  
  - 对匿名化、聚合后的使用数据进行分析，优化默认检索权重、缓存策略等；  
  - 可选：为愿意 opt-in 的租户提供“模型持续微调”能力（如专属嵌入/抽取器）。

### 6.4 最终闭环图景

- 租户：托管自己的多模态记忆（视频 + 文本），享受跨模态回想与知识服务。  
- 开发者：用统一 API/SDK 把记忆服务接入自己的 Agent / 应用，不必自建复杂存储与图谱。  
- 平台：通过稳定的时间轴、多租户隔离、智能图构建与运维能力，成为“记忆基础设施”的事实标准之一。

---

## 7. 建议的推进节奏（总结）

1. **先做“基础护栏”：时间轴 + 多租户**（阶段 1–2）。  
2. **再做“记忆质量”：智能图构建 + 回想 API 强化**（阶段 3）。  
3. **并行补齐“工程地基”：容器化 + CI/CD + 监控**（阶段 4）。  
4. **扩展到文本领域：统一文本记忆与知识图**（阶段 5）。  
5. **打磨为对外服务：SaaS 化、SDK 与生态**（阶段 6）。  
6. **在稳定记忆图基础上，引入前向预测：时间知识图谱推理模块**（阶段 7，可选但建议作为“进攻型能力”）。

以上路径尽量保证每一阶段都是“可用的一个小闭环”，在不破坏现有能力的前提下，逐步逼近“通用记忆基础设施”的最终愿景。 

---

## 8. 阶段 7：时间知识图谱与前向预测推理（Temporal KG & Forward Inference）

**目标**：在已经成型的时空记忆图之上，引入“前向预测推理”能力：  
- 不仅能“回忆过去发生了什么”，还能在一定概率意义上预测“未来可能发生什么”；  
- 在不重构现有系统的前提下，利用已有事件/关系/时间轴构建 TKG 视图，并挂载标准的 TKG 模型（Know-Evolve / RE-Net / TeMP / TimeTraveler / TLogic 等）作为可选推理模块。

### 8.1 数据视图与构建要求

- 基于阶段 1 + 3 的成果，我们已经具备：  
  - 事件节点：`Event`（具有 `id, actors[], objects[], t_media_*/t_abs_*` 等）。  
  - 关系边：`INVOLVES, OCCURS_AT, NEXT_EVENT, (CAUSED_BY?)` 等。  
  - 物理时间轴：`t_abs_*` + `time_origin`。  
- 在此基础上，为 TKG 前向推理定义两类视图（无需改动底层存储，只是投影）：  
  1. **时间四元组流视图**：  
     - `(s, r, o, t)`：  
       - `s/o`：实体或事件（`character_id` / `Event.id` / 其它 Entity）；  
       - `r`：关系类型（例如 `INVOLVES`, `LOCATED_IN`, `NEXT_EVENT`）；  
       - `t`：可以选 `t_abs_start` 或离散化时间步（例如按分钟/小时/clip）。  
  2. **快照序列视图**：  
     - 一系列离散时间片 `G^1, G^2, …, G^T`，每个 `G^t` 是在时间区间 `[τ_t, τ_{t+1})` 内激活的子图。  
     - 适配 TeMP、TimeTraveler 这类“在历史快照上行走”的模型。

### 8.2 算法范式选择与集成方式

根据应用需求，选择一条主线（其他作为扩展）：

- 若更关心“下一步会发生什么事件/关系”：  
  - 优先考虑 **离散时间序列/快照模型**：  
    - 自回归事件模型（如 RE-Net）；  
    - 时序 GNN（如 TeMP）；  
    - RL 型路径搜索（如 TimeTraveler）。  
- 若关心“何时发生”（时间点预测）：  
  - 可研究时间点过程模型（如 Know-Evolve），但工程成本更高，可放在后续。  
- 若看重可解释性与规则迁移：  
  - 可引入时间逻辑规则（TLogic）作为一个独立的“规则挖掘 + 前向推理”模块。

集成策略：

- 定义一个统一的 TKG 训练用导出接口：  
  - 例如：`/admin/export_tkg_view?tenant_id=...&time_window=...` → 输出 `(s,r,o,t)` 序列或快照序列；  
  - 供离线训练脚本或 TGL/DGL 等框架直接使用。  
- 前向预测服务作为**旁路模块**挂到 MemoryService 旁：  
  - `tkg_predict_service` 接收 `(query_type, seed_entities/events, horizon, tenant_id)`，基于训练好的模型做预测：  
    - 输出候选未来事件/边：`{ (s,r,o,t_pred), score }`。  
  - MemoryService 提供轻量包装 API：  
    - 例如 `/event_forecast`、`/relation_forecast`，内部转发到 TKG 模块，并把结果写成“未来候选事件节点/边 + 置信度”回到记忆图中（带 `time_origin='predicted'` 标记）。

### 8.3 与现有规划的衔接

- **不改底层，只加视图与模块**：  
  - 阶段 1 的时间轴、阶段 3 的事件/关系建模已经满足 TKG 构建要求，无需重构；  
  - 只需在图上定义“如何抽取 (s,r,o,t)”与“如何离散化时间”的规则。  
- **预测结果是“二等公民”**：  
  - 以 `predicted` 标记写入图中，带置信度和模型版本；  
  - 查询时可配置是否使用预测结果（例如只在探索/推荐场景使用）。  
- **训练闭环与 CI/CL 的关系**：  
  - 利用阶段 6 中的 CI/CL 能力，对前向预测模块做版本管理与评估（通过历史回放验证预测质量）；  
  - 可对单租户或特定业务场景训练专用 TKG 模型。

### 8.4 阶段目标 & 检验标准

- 最少在一个典型场景下实现 PoC：  
  - 例如“家庭机器人场景”：  
    - 在已有视频记忆中，能预测“某人未来最可能在哪个房间出现”、“接下来可能发生哪些活动”。  
- 保证：  
  - 不破坏现有检索与回想 API 的行为；  
  - 即使关闭 TKG 模块，记忆系统仍完整可用。  
- 将 TKG 前向推理能力作为“增强包”对外发布，明确说明适用场景与资源成本。  
